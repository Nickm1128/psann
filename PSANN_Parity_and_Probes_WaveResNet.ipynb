{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d6a743",
   "metadata": {
    "id": "f3d6a743"
   },
   "source": [
    "# ResPSANN Compute-Parity Experiments (Colab Runner)\n",
    "\n",
    "This notebook orchestrates the experiments described in `plan.txt` using the datasets summarised in `data_descriptions.txt`. Execute it inside Google Colab (GPU runtime recommended).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740b594",
   "metadata": {
    "id": "4740b594"
   },
   "source": [
    "## Run Checklist\n",
    "- Prefer Google Colab with a GPU runtime (recommended) before running any experiments.\n",
    "- Let the setup cell install the latest published `psann` package via `pip`; no repository clone is required.\n",
    "- Upload or mount the dataset directory so that `DATA_ROOT` points to it (defaults to `<working dir>/datasets`).\n",
    "- Adjust `GLOBAL_CONFIG` and the experiment toggles before launching training to stay within the Colab budget.\n",
    "- Keep the heavy training cells disabled until you are ready to execute them in Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b559b11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b559b11",
    "outputId": "639af6cc-ade9-425d-f1d1-bd59fb6165d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab runtime         : True\n",
      "Project root          : /content\n",
      "Dataset root          : /content/datasets\n",
      "Results directory     : /content/colab_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "DEFAULT_PROJECT_ROOT = Path(\"/content\") if COLAB else Path.cwd()\n",
    "PROJECT_ROOT = Path(os.getenv(\"PSANN_PROJECT_ROOT\", DEFAULT_PROJECT_ROOT)).resolve()\n",
    "\n",
    "DATA_ROOT = Path(os.getenv(\"PSANN_DATA_ROOT\", PROJECT_ROOT / \"datasets\")).resolve()\n",
    "RESULTS_ROOT = Path(os.getenv(\"PSANN_RESULTS_ROOT\", PROJECT_ROOT / \"colab_results\")).resolve()\n",
    "FIGURE_ROOT = RESULTS_ROOT / \"figures\"\n",
    "\n",
    "RESULTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "FIGURE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    print(f\"[WARN] DATA_ROOT {DATA_ROOT} does not exist yet. Upload datasets or update PSANN_DATA_ROOT.\")\n",
    "\n",
    "print(f\"Colab runtime         : {COLAB}\")\n",
    "print(f\"Project root          : {PROJECT_ROOT}\")\n",
    "print(f\"Dataset root          : {DATA_ROOT}\")\n",
    "print(f\"Results directory     : {RESULTS_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c824d6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c824d6c",
    "outputId": "5e7b7a76-8aac-4f25-e6d4-c3c6ae8de937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets already present at /content/datasets\n"
     ]
    }
   ],
   "source": [
    "# --- Robust extraction for your datasets.zip layout ---\n",
    "import zipfile\n",
    "import shutil\n",
    "import re\n",
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "# Fallbacks if not already defined in your notebook\n",
    "try:\n",
    "    PROJECT_ROOT\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path(\"/content\")\n",
    "try:\n",
    "    DATA_ROOT\n",
    "except NameError:\n",
    "    DATA_ROOT = PROJECT_ROOT / \"datasets\"\n",
    "\n",
    "zip_path = PROJECT_ROOT / \"datasets.zip\"\n",
    "\n",
    "# Canonical names your code expects\n",
    "EXPECTED_FOLDERS = [\n",
    "    \"Industrial Data from the Electric Arc Furnace\",\n",
    "    \"Beijing Air Quality\",\n",
    "    \"Human Activity Recognition\",\n",
    "    \"Jena Climate 2009-2016\",  # we'll normalize any en/em/Unicode minus to a hyphen\n",
    "    \"Kaggle Rossmann Store Sales\",\n",
    "]\n",
    "\n",
    "def _normalize_name(s: str) -> str:\n",
    "    # unify hyphen-like chars, collapse whitespace, lowercase\n",
    "    s = (s.replace(\"\\u2013\", \"-\")  # en dash\n",
    "           .replace(\"\\u2014\", \"-\")  # em dash\n",
    "           .replace(\"\\u2212\", \"-\")  # minus\n",
    "           .replace(\"\\xa0\", \" \"))   # non-breaking space\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "def _safe_mkdir(path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Create directory `path`, removing any FILE that blocks directory creation\n",
    "    at this path or any ancestor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        return\n",
    "    except NotADirectoryError:\n",
    "        # Find any ancestor that's a file and remove it.\n",
    "        # Include the path itself first, then walk upward.\n",
    "        for ancestor in [path, *path.parents]:\n",
    "            try:\n",
    "                if ancestor.exists() and ancestor.is_file():\n",
    "                    ancestor.unlink()\n",
    "            except Exception:\n",
    "                # If we can't remove, re-raise later when mkdir fails again\n",
    "                pass\n",
    "        # Try once more after clearing blockers\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _canonicalize_top_level_dirs(root: Path, expected_names: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    If top-level dirs exist with dash/space variants, rename them\n",
    "    to the canonical EXPECTED_FOLDERS names so downstream code works.\n",
    "    \"\"\"\n",
    "    if not root.exists():\n",
    "        return\n",
    "    # Map normalized->actual path for current top-level dirs\n",
    "    current = { _normalize_name(p.name): p for p in root.iterdir() if p.is_dir() }\n",
    "    for exp in expected_names:\n",
    "        canonical = root / exp\n",
    "        if canonical.exists():\n",
    "            continue\n",
    "        norm = _normalize_name(exp)\n",
    "        if norm in current and current[norm].exists():\n",
    "            src = current[norm]\n",
    "            # Avoid rename conflict: if a file with target name exists, remove it\n",
    "            if canonical.exists() and canonical.is_file():\n",
    "                canonical.unlink()\n",
    "            print(f\"[rename] {src.name} -> {exp}\")\n",
    "            src.rename(canonical)\n",
    "\n",
    "def extract_datasets(zip_path: Path, target_root: Path) -> None:\n",
    "    scratch_root = target_root.parent / \"_datasets_unpack_tmp\"\n",
    "    if scratch_root.exists():\n",
    "        shutil.rmtree(scratch_root)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        for entry in zf.infolist():\n",
    "            # Normalize path parts from the ZIP (handles both / and \\ separators)\n",
    "            parts = PureWindowsPath(entry.filename).parts\n",
    "            if not parts or parts[0].lower() != \"datasets\":\n",
    "                continue\n",
    "            rel_parts = parts[1:]\n",
    "            if not rel_parts:\n",
    "                continue\n",
    "\n",
    "            dest = scratch_root.joinpath(*rel_parts)\n",
    "\n",
    "            # Treat as directory if zip marks it so OR the path text ends with a slash/backslash\n",
    "            is_dir_entry = entry.is_dir() or entry.filename.endswith(\"/\") or entry.filename.endswith(\"\\\\\")\n",
    "            if is_dir_entry:\n",
    "                _safe_mkdir(dest)\n",
    "            else:\n",
    "                # Ensure parents exist, removing any file that blocks dir creation\n",
    "                _safe_mkdir(dest.parent)\n",
    "                # Extract the file\n",
    "                with zf.open(entry, \"r\") as src, open(dest, \"wb\") as dst:\n",
    "                    shutil.copyfileobj(src, dst)\n",
    "\n",
    "    # Replace/refresh target_root\n",
    "    if target_root.exists():\n",
    "        shutil.rmtree(target_root)\n",
    "    scratch_root.rename(target_root)\n",
    "\n",
    "    # Canonicalize top-level dir names (e.g., Jena dash variants)\n",
    "    _canonicalize_top_level_dirs(target_root, EXPECTED_FOLDERS)\n",
    "\n",
    "def datasets_ready(root: Path) -> bool:\n",
    "    if not root.exists():\n",
    "        return False\n",
    "    # Accept either exact or normalized matches for robustness\n",
    "    have = { _normalize_name(p.name) for p in root.iterdir() if p.is_dir() }\n",
    "    need = { _normalize_name(n) for n in EXPECTED_FOLDERS }\n",
    "    return need.issubset(have)\n",
    "\n",
    "# --- Clean up stray \"datasets\\...\" artefacts before extraction (from Windows zips) ---\n",
    "for leftover in PROJECT_ROOT.iterdir():\n",
    "    if \"\\\\\" in leftover.name and leftover.name.lower().startswith(\"datasets\"):\n",
    "        if leftover.is_dir():\n",
    "            shutil.rmtree(leftover)\n",
    "        else:\n",
    "            leftover.unlink()\n",
    "\n",
    "# --- Run ---\n",
    "if datasets_ready(DATA_ROOT):\n",
    "    print(f\"Datasets already present at {DATA_ROOT}\")\n",
    "elif zip_path.exists():\n",
    "    print(f\"Extracting {zip_path} (normalising Windows/Unicode paths)â€¦\")\n",
    "    extract_datasets(zip_path, DATA_ROOT)\n",
    "    if datasets_ready(DATA_ROOT):\n",
    "        print(f\"Extraction complete. DATA_ROOT now available at {DATA_ROOT}\")\n",
    "        # Optional: quick sanity peek\n",
    "        for p in sorted(DATA_ROOT.iterdir()):\n",
    "            if p.is_dir():\n",
    "                print(\" -\", p.name)\n",
    "    else:\n",
    "        print(\"[WARN] Extraction finished but expected folders are still missing.\")\n",
    "else:\n",
    "    print(f\"Archive {zip_path} not found. Upload datasets.zip or mount the datasets directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07209e39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07209e39",
    "outputId": "ccd2c29a-70c2-4eab-a5b1-f5aaeef26597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing psann and supporting packages...\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_dependencies():\n",
    "    base_packages = [\n",
    "        \"psann\",\n",
    "        \"pandas>=2.0\",\n",
    "        \"numpy>=1.24\",\n",
    "        \"scikit-learn>=1.3\",\n",
    "        \"torch>=2.1\",\n",
    "        \"torchvision>=0.16\",\n",
    "        \"torchaudio>=2.1\",\n",
    "        \"lightgbm>=4.0\",\n",
    "        \"xgboost>=1.7\",\n",
    "        \"catboost>=1.2\",\n",
    "        \"shap>=0.44\",\n",
    "        \"matplotlib>=3.7\",\n",
    "        \"seaborn>=0.13\",\n",
    "        \"plotly>=5.18\",\n",
    "        \"imbalanced-learn>=0.12\",\n",
    "        \"tqdm>=4.66\",\n",
    "        \"einops>=0.7\",\n",
    "        \"rich>=13.7\",\n",
    "    ]\n",
    "    print(\"Installing psann and supporting packages...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + base_packages)\n",
    "\n",
    "\n",
    "if COLAB:\n",
    "    install_dependencies()\n",
    "else:\n",
    "    print(\"Skipping dependency installation because we are not inside Colab.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c4441a6",
   "metadata": {
    "id": "8c4441a6"
   },
   "outputs": [],
   "source": [
    "# Core dependencies used across the notebook\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "772afbf3",
   "metadata": {
    "id": "772afbf3"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainConfig:\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    weight_decay: float = 0.0\n",
    "    max_minutes: Optional[float] = None\n",
    "    early_stopping: bool = True\n",
    "    patience: int = 10\n",
    "    gradient_clip: Optional[float] = None\n",
    "    scheduler: Optional[str] = None\n",
    "    scheduler_params: Optional[Dict[str, Any]] = None\n",
    "    warmup_steps: int = 0\n",
    "    max_batches_per_epoch: Optional[int] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelSpec:\n",
    "    name: str\n",
    "    builder: Callable[[Tuple[int, ...], int, Dict[str, Any]], nn.Module]\n",
    "    train_config: TrainConfig\n",
    "    task_type: Literal[\"regression\", \"classification\", \"multitask\"]\n",
    "    input_kind: Literal[\"tabular\", \"sequence\"]\n",
    "    group: str = \"baseline\"\n",
    "    extra: Dict[str, Any] = field(default_factory=dict)\n",
    "    param_target: Optional[int] = None\n",
    "    notes: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DatasetBundle:\n",
    "    name: str\n",
    "    task_type: Literal[\"regression\", \"classification\", \"multitask\"]\n",
    "    input_kind: Literal[\"tabular\", \"sequence\"]\n",
    "    feature_names: List[str]\n",
    "    target_names: List[str]\n",
    "    train: Dict[str, np.ndarray]\n",
    "    val: Dict[str, np.ndarray]\n",
    "    test: Dict[str, np.ndarray]\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    def summary(self) -> Dict[str, Any]:\n",
    "        info = {\n",
    "            \"name\": self.name,\n",
    "            \"task_type\": self.task_type,\n",
    "            \"input_kind\": self.input_kind,\n",
    "            \"n_train\": len(self.train[\"X\"]),\n",
    "            \"n_val\": len(self.val[\"X\"]),\n",
    "            \"n_test\": len(self.test[\"X\"]),\n",
    "            \"input_shape\": tuple(self.train[\"X\"].shape[1:]),\n",
    "            \"target_shape\": tuple(self.train[\"y\"].shape[1:]) if self.train[\"y\"].ndim > 1 else (),\n",
    "        }\n",
    "        info.update({f\"meta_{k}\": v for k, v in self.metadata.items() if isinstance(v, (int, float, str))})\n",
    "        return info\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    dataset: str\n",
    "    task: str\n",
    "    model: str\n",
    "    group: str\n",
    "    split: str\n",
    "    metrics: Dict[str, float]\n",
    "    params: int\n",
    "    train_wall_seconds: float\n",
    "    notes: str = \"\"\n",
    "\n",
    "\n",
    "class ResultLogger:\n",
    "    def __init__(self) -> None:\n",
    "        self._rows: List[ExperimentResult] = []\n",
    "\n",
    "    def append(self, row: ExperimentResult) -> None:\n",
    "        self._rows.append(row)\n",
    "\n",
    "    def to_frame(self) -> pd.DataFrame:\n",
    "        records = []\n",
    "        for row in self._rows:\n",
    "            rec = {\n",
    "                \"dataset\": row.dataset,\n",
    "                \"task\": row.task,\n",
    "                \"model\": row.model,\n",
    "                \"group\": row.group,\n",
    "                \"split\": row.split,\n",
    "                \"params\": row.params,\n",
    "                \"train_wall_seconds\": row.train_wall_seconds,\n",
    "                \"notes\": row.notes,\n",
    "            }\n",
    "            rec.update(row.metrics)\n",
    "            records.append(rec)\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "RESULT_LOGGER = ResultLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94828a93",
   "metadata": {
    "id": "94828a93"
   },
   "outputs": [],
   "source": [
    "def load_jena_climate(data_root: Path) -> pd.DataFrame:\n",
    "    path = data_root / \"Jena Climate 2009-2016\" / \"jena_climate_2009_2016.csv\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Jena climate CSV not found at {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"Date Time\"], dayfirst=True)\n",
    "    df = df.drop(columns=[\"Date Time\"])\n",
    "    numeric_cols = [col for col in df.columns if col != \"datetime\"]\n",
    "    df[numeric_cols] = df[numeric_cols].astype(np.float32)\n",
    "    df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_jena_bundle(\n",
    "    df: pd.DataFrame,\n",
    "    target: str = \"T (degC)\",\n",
    "    context_steps: int = 72,\n",
    "    horizon_steps: int = 36,\n",
    "    resample_factor: int = 1,\n",
    ") -> DatasetBundle:\n",
    "    df = df.copy()\n",
    "    if resample_factor > 1:\n",
    "        df = df.iloc[::resample_factor].reset_index(drop=True)\n",
    "    df = add_calendar_features(df, \"datetime\")\n",
    "    feature_cols = [c for c in df.columns if c not in (\"datetime\", target)]\n",
    "    df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    values = df[feature_cols].to_numpy(dtype=np.float32)\n",
    "    target_values = df[target].to_numpy(dtype=np.float32)\n",
    "    timestamps = df[\"datetime\"].to_numpy()\n",
    "\n",
    "    windows = []\n",
    "    targets = []\n",
    "    ts_list = []\n",
    "    for idx in range(context_steps, len(df) - horizon_steps):\n",
    "        window = values[idx - context_steps : idx]\n",
    "        target_value = target_values[idx + horizon_steps]\n",
    "        windows.append(window)\n",
    "        targets.append(target_value)\n",
    "        ts_list.append(timestamps[idx])\n",
    "    X = np.stack(windows)\n",
    "    y = np.asarray(targets, dtype=np.float32)[:, None]\n",
    "    ts = np.asarray(ts_list)\n",
    "\n",
    "    df_windows = pd.DataFrame({\"datetime\": ts})\n",
    "    train_df, val_df, test_df = train_val_test_split_by_time(\n",
    "        df_windows, \"datetime\", \"2015-01-01\", \"2016-01-01\"\n",
    "    )\n",
    "    train_idx = train_df.index.to_numpy()\n",
    "    val_idx = val_df.index.to_numpy()\n",
    "    test_idx = test_df.index.to_numpy()\n",
    "\n",
    "    target_slug = (\n",
    "        target.lower()\n",
    "        .replace(\" \", \"\")\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\"/\", \"\")\n",
    "    )\n",
    "    bundle_name = f\"Jena_{target_slug}_{context_steps}ctx_{horizon_steps}h\"\n",
    "\n",
    "    bundle = DatasetBundle(\n",
    "        name=bundle_name,\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"sequence\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=[target],\n",
    "        train={\"X\": X[train_idx], \"y\": y[train_idx]},\n",
    "        val={\"X\": X[val_idx], \"y\": y[val_idx]},\n",
    "        test={\"X\": X[test_idx], \"y\": y[test_idx]},\n",
    "        metadata={\n",
    "            \"context_steps\": context_steps,\n",
    "            \"horizon_steps\": horizon_steps,\n",
    "            \"resample_factor\": resample_factor,\n",
    "        },\n",
    "    )\n",
    "    return bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdf214b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdf214b6",
    "outputId": "5de1d4c3-fcd7-4601-b793-c5f25cc88e03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipython-input-2915871693.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  X_train = pd.read_csv(base / \"train\" / \"X_train.txt\", sep='\\s+', header=None)\n",
      "/tmp/ipython-input-2915871693.py:7: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  X_test = pd.read_csv(base / \"test\" / \"X_test.txt\", sep='\\s+', header=None)\n"
     ]
    }
   ],
   "source": [
    "def load_har_engineered(data_root: Path):\n",
    "    base = data_root / \"Human Activity Recognition\" / \"UCI HAR Dataset\"\n",
    "    X_train = pd.read_csv(base / \"train\" / \"X_train.txt\", sep='\\s+', header=None)\n",
    "    y_train = pd.read_csv(base / \"train\" / \"y_train.txt\", header=None).squeeze(\"columns\")\n",
    "    subject_train = pd.read_csv(base / \"train\" / \"subject_train.txt\", header=None).squeeze(\"columns\")\n",
    "\n",
    "    X_test = pd.read_csv(base / \"test\" / \"X_test.txt\", sep='\\s+', header=None)\n",
    "    y_test = pd.read_csv(base / \"test\" / \"y_test.txt\", header=None).squeeze(\"columns\")\n",
    "    subject_test = pd.read_csv(base / \"test\" / \"subject_test.txt\", header=None).squeeze(\"columns\")\n",
    "\n",
    "    y_train = y_train.values.astype(int) - 1\n",
    "    y_test = y_test.values.astype(int) - 1\n",
    "\n",
    "    features = (base / \"features.txt\").read_text().strip().splitlines()\n",
    "    feature_names = [line.split()[1] for line in features]\n",
    "\n",
    "    X_train.columns = feature_names\n",
    "    X_test.columns = feature_names\n",
    "\n",
    "    train_df = X_train.copy()\n",
    "    test_df = X_test.copy()\n",
    "    train_df[\"label\"] = y_train\n",
    "    train_df[\"subject\"] = subject_train.values\n",
    "    test_df[\"label\"] = y_test\n",
    "    test_df[\"subject\"] = subject_test.values\n",
    "\n",
    "    return train_df, test_df, feature_names\n",
    "\n",
    "\n",
    "def prepare_har_engineered_bundle(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    feature_names: List[str],\n",
    "    val_fraction: float = 0.15,\n",
    ") -> DatasetBundle:\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "    X = train_df[feature_names].to_numpy(dtype=np.float32)\n",
    "    y = train_df[\"label\"].to_numpy(dtype=np.int64)\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_fraction, random_state=GLOBAL_CONFIG[\"seed\"])\n",
    "    train_idx, val_idx = next(splitter.split(X, y))\n",
    "\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx][:, None]\n",
    "    X_val = X[val_idx]\n",
    "    y_val = y[val_idx][:, None]\n",
    "\n",
    "    X_test = test_df[feature_names].to_numpy(dtype=np.float32)\n",
    "    y_test = test_df[\"label\"].to_numpy(dtype=np.int64)[:, None]\n",
    "\n",
    "    bundle = DatasetBundle(\n",
    "        name=\"HAR_engineered\",\n",
    "        task_type=\"classification\",\n",
    "        input_kind=\"tabular\",\n",
    "        feature_names=feature_names,\n",
    "        target_names=[\"activity\"],\n",
    "        train={\"X\": X_train, \"y\": y_train},\n",
    "        val={\"X\": X_val, \"y\": y_val},\n",
    "        test={\"X\": X_test, \"y\": y_test},\n",
    "        metadata={\n",
    "            \"n_classes\": 6,\n",
    "            \"label_mapping\": {\n",
    "                0: \"WALKING\",\n",
    "                1: \"WALKING_UPSTAIRS\",\n",
    "                2: \"WALKING_DOWNSTAIRS\",\n",
    "                3: \"SITTING\",\n",
    "                4: \"STANDING\",\n",
    "                5: \"LAYING\",\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    return bundle\n",
    "\n",
    "\n",
    "def load_har_raw_sequences(data_root: Path):\n",
    "    base = data_root / \"Human Activity Recognition\" / \"UCI HAR Dataset\"\n",
    "    axes = [\n",
    "        \"body_acc_x\",\n",
    "        \"body_acc_y\",\n",
    "        \"body_acc_z\",\n",
    "        \"body_gyro_x\",\n",
    "        \"body_gyro_y\",\n",
    "        \"body_gyro_z\",\n",
    "        \"total_acc_x\",\n",
    "        \"total_acc_y\",\n",
    "        \"total_acc_z\",\n",
    "    ]\n",
    "\n",
    "    def load_split(split: str):\n",
    "        signals = []\n",
    "        for axis in axes:\n",
    "            path = base / split / \"Inertial Signals\" / f\"{axis}_{split}.txt\"\n",
    "            arr = np.loadtxt(path)\n",
    "            signals.append(arr[:, :, None])\n",
    "        X = np.concatenate(signals, axis=2).astype(np.float32)\n",
    "        y = np.loadtxt(base / split / f\"y_{split}.txt\").astype(int) - 1\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = load_split(\"train\")\n",
    "    X_test, y_test = load_split(\"test\")\n",
    "    return X_train, y_train, X_test, y_test, axes\n",
    "\n",
    "\n",
    "def prepare_har_raw_bundle(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    val_fraction: float = 0.15,\n",
    ") -> DatasetBundle:\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_fraction, random_state=GLOBAL_CONFIG[\"seed\"])\n",
    "    train_idx, val_idx = next(splitter.split(X_train, y_train))\n",
    "    bundle = DatasetBundle(\n",
    "        name=\"HAR_raw_sequence\",\n",
    "        task_type=\"classification\",\n",
    "        input_kind=\"sequence\",\n",
    "        feature_names=[f\"axis_{i}\" for i in range(X_train.shape[2])],\n",
    "        target_names=[\"activity\"],\n",
    "        train={\"X\": X_train[train_idx], \"y\": y_train[train_idx][:, None]},\n",
    "        val={\"X\": X_train[val_idx], \"y\": y_train[val_idx][:, None]},\n",
    "        test={\"X\": X_test, \"y\": y_test[:, None]},\n",
    "        metadata={\n",
    "            \"sequence_length\": X_train.shape[1],\n",
    "            \"n_channels\": X_train.shape[2],\n",
    "            \"n_classes\": 6,\n",
    "        },\n",
    "    )\n",
    "    return bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1da5943",
   "metadata": {
    "id": "b1da5943"
   },
   "outputs": [],
   "source": [
    "def load_rossmann_frames(data_root: Path):\n",
    "    base = data_root / \"Kaggle Rossmann Store Sales\" / \"rossmann-store-sales\"\n",
    "    train_path = base / \"train.csv\"\n",
    "    test_path = base / \"test.csv\"\n",
    "    store_path = base / \"store.csv\"\n",
    "    train = pd.read_csv(train_path, parse_dates=[\"Date\"])\n",
    "    test = pd.read_csv(test_path, parse_dates=[\"Date\"])\n",
    "    store = pd.read_csv(store_path)\n",
    "    return train, test, store\n",
    "\n",
    "\n",
    "def is_promo2_active(row: pd.Series) -> int:\n",
    "    if not row.get(\"Promo2\", 0):\n",
    "        return 0\n",
    "    month = row[\"Date\"].month\n",
    "    if isinstance(row[\"PromoInterval\"], str) and row[\"PromoInterval\"]:\n",
    "        month_map = {name: idx for idx, name in enumerate([\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"], start=1)}\n",
    "        promo_months = [month_map.get(m.strip(), 0) for m in row[\"PromoInterval\"].split(\",\")]\n",
    "        return int(month in promo_months)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def preprocess_rossmann(train: pd.DataFrame, store: pd.DataFrame) -> Tuple[pd.DataFrame, List[str], str]:\n",
    "    df = train.merge(store, on=\"Store\", how=\"left\")\n",
    "    df = df[df[\"Open\"] != 0].copy()\n",
    "\n",
    "    median_distance = df[\"CompetitionDistance\"].median()\n",
    "    df[\"CompetitionDistance\"] = df[\"CompetitionDistance\"].fillna(median_distance)\n",
    "    df[\"CompetitionOpenSinceYear\"] = df[\"CompetitionOpenSinceYear\"].fillna(df[\"CompetitionOpenSinceYear\"].median())\n",
    "    df[\"CompetitionOpenSinceMonth\"] = df[\"CompetitionOpenSinceMonth\"].fillna(df[\"CompetitionOpenSinceMonth\"].median())\n",
    "    df[\"Promo2SinceWeek\"] = df[\"Promo2SinceWeek\"].fillna(0)\n",
    "    df[\"Promo2SinceYear\"] = df[\"Promo2SinceYear\"].fillna(0)\n",
    "    df[\"PromoInterval\"] = df[\"PromoInterval\"].fillna(\"\")\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year\n",
    "    df[\"Month\"] = df[\"Date\"].dt.month\n",
    "    df[\"Day\"] = df[\"Date\"].dt.day\n",
    "    df[\"WeekOfYear\"] = df[\"Date\"].dt.isocalendar().week.astype(int)\n",
    "    df[\"DayOfWeek\"] = df[\"Date\"].dt.dayofweek\n",
    "\n",
    "    df[\"IsPromo2Month\"] = df.apply(is_promo2_active, axis=1)\n",
    "\n",
    "    state_holiday_map = {\"0\": \"None\", \"a\": \"PublicHoliday\", \"b\": \"EasterHoliday\", \"c\": \"Christmas\"}\n",
    "    df[\"StateHoliday\"] = df[\"StateHoliday\"].replace(state_holiday_map)\n",
    "\n",
    "    categorical_cols = [\"StoreType\", \"Assortment\", \"StateHoliday\", \"PromoInterval\"]\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    df[\"CustomersLag7\"] = df.groupby(\"Store\")[\"Customers\"].shift(7)\n",
    "    df[\"SalesLag7\"] = df.groupby(\"Store\")[\"Sales\"].shift(7)\n",
    "    df[\"SalesMA14\"] = df.groupby(\"Store\")[\"Sales\"].transform(lambda s: s.rolling(14, min_periods=1).mean())\n",
    "    df[\"PromoMovingAvg\"] = df.groupby(\"Store\")[\"Promo\"].transform(lambda s: s.rolling(30, min_periods=1).mean())\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in (\"Sales\", \"Date\")]\n",
    "    target_col = \"Sales\"\n",
    "    return df, feature_cols, target_col\n",
    "\n",
    "\n",
    "def prepare_rossmann_bundle(df: pd.DataFrame, feature_cols: List[str], target_col: str) -> DatasetBundle:\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "    unique_dates = np.sort(df[\"Date\"].unique())\n",
    "    if unique_dates.size < 3:\n",
    "        raise ValueError(\"Rossmann dataset requires at least three distinct dates to form train/val/test splits.\")\n",
    "\n",
    "    train_cut_idx = max(1, int(0.8 * unique_dates.size))\n",
    "    val_cut_idx = max(train_cut_idx + 1, int(0.9 * unique_dates.size))\n",
    "    if val_cut_idx >= unique_dates.size:\n",
    "        val_cut_idx = unique_dates.size - 1\n",
    "    train_end = unique_dates[train_cut_idx]\n",
    "    val_end = unique_dates[val_cut_idx]\n",
    "\n",
    "    train_mask = df[\"Date\"] < train_end\n",
    "    val_mask = (df[\"Date\"] >= train_end) & (df[\"Date\"] < val_end)\n",
    "    test_mask = df[\"Date\"] >= val_end\n",
    "\n",
    "    train_df = df[train_mask].copy()\n",
    "    val_df = df[val_mask].copy()\n",
    "    test_df = df[test_mask].copy()\n",
    "\n",
    "    if train_df.empty or val_df.empty or test_df.empty:\n",
    "        raise ValueError(\"Rossmann split produced an empty partition; adjust quantiles or check input data.\")\n",
    "\n",
    "    X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_train = train_df[target_col].to_numpy(dtype=np.float32)[:, None]\n",
    "    X_val = val_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_val = val_df[target_col].to_numpy(dtype=np.float32)[:, None]\n",
    "    X_test = test_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_test = test_df[target_col].to_numpy(dtype=np.float32)[:, None]\n",
    "\n",
    "    feature_mean = X_train.mean(axis=0, keepdims=True)\n",
    "    feature_std = X_train.std(axis=0, keepdims=True)\n",
    "    feature_std = np.where(feature_std < 1e-6, 1.0, feature_std)\n",
    "\n",
    "    target_mean = y_train.mean(axis=0, keepdims=True)\n",
    "    target_std = y_train.std(axis=0, keepdims=True)\n",
    "    target_std = np.where(target_std < 1e-6, 1.0, target_std)\n",
    "\n",
    "    def _normalize(arr: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "        return ((arr - mean) / std).astype(np.float32)\n",
    "\n",
    "    X_train = _normalize(X_train, feature_mean, feature_std)\n",
    "    X_val = _normalize(X_val, feature_mean, feature_std)\n",
    "    X_test = _normalize(X_test, feature_mean, feature_std)\n",
    "\n",
    "    y_train_norm = _normalize(y_train, target_mean, target_std)\n",
    "    y_val_norm = _normalize(y_val, target_mean, target_std)\n",
    "    y_test_norm = _normalize(y_test, target_mean, target_std)\n",
    "\n",
    "    bundle = DatasetBundle(\n",
    "        name=\"Rossmann_sales\",\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"tabular\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=[target_col],\n",
    "        train={\"X\": X_train, \"y\": y_train_norm},\n",
    "        val={\"X\": X_val, \"y\": y_val_norm},\n",
    "        test={\"X\": X_test, \"y\": y_test_norm},\n",
    "        metadata={\n",
    "            \"train_range\": [str(train_df[\"Date\"].min()), str(train_df[\"Date\"].max())],\n",
    "            \"val_range\": [str(val_df[\"Date\"].min()), str(val_df[\"Date\"].max())],\n",
    "            \"test_range\": [str(test_df[\"Date\"].min()), str(test_df[\"Date\"].max())],\n",
    "            \"feature_scaler\": {\n",
    "                \"mean\": feature_mean.flatten().astype(np.float32).tolist(),\n",
    "                \"std\": feature_std.flatten().astype(np.float32).tolist(),\n",
    "            },\n",
    "            \"target_scaler\": {\n",
    "                \"mean\": target_mean.flatten().astype(np.float32).tolist(),\n",
    "                \"std\": target_std.flatten().astype(np.float32).tolist(),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    return bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b83bcf91",
   "metadata": {
    "id": "b83bcf91"
   },
   "outputs": [],
   "source": [
    "def load_beijing_stations(data_root: Path) -> Dict[str, pd.DataFrame]:\n",
    "    base = data_root / \"Beijing Air Quality\"\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"Beijing Air Quality directory not found at {base}\")\n",
    "    stations: Dict[str, pd.DataFrame] = {}\n",
    "    for csv_path in base.glob(\"PRSA_Data_*.csv\"):\n",
    "        station_name = csv_path.stem.replace(\"PRSA_Data_\", \"\")\n",
    "        print(f\"Loading Beijing station {station_name}...\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"datetime\"] = pd.to_datetime(\n",
    "            df[[\"year\", \"month\", \"day\", \"hour\"]].rename(columns=str)\n",
    "        )\n",
    "        df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "        if \"No\" in df.columns:\n",
    "            df = df.drop(columns=[\"No\"])\n",
    "        stations[station_name] = df\n",
    "    return stations\n",
    "\n",
    "\n",
    "def preprocess_beijing_station(df: pd.DataFrame, target_col: str = \"PM2.5\") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = df.copy()\n",
    "    pollutant_cols = [\"PM2.5\", \"PM10\", \"SO2\", \"NO2\", \"CO\", \"O3\"]\n",
    "    meteorology_cols = [\"PRES\", \"DEWP\", \"TEMP\", \"RAIN\", \"WSPM\"]\n",
    "    for col in pollutant_cols + meteorology_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    mask = df[pollutant_cols + meteorology_cols].isna()\n",
    "    df[pollutant_cols + meteorology_cols] = df[pollutant_cols + meteorology_cols].interpolate(limit=6, limit_direction=\"both\")\n",
    "    df[pollutant_cols + meteorology_cols] = df[pollutant_cols + meteorology_cols].ffill().bfill()\n",
    "\n",
    "    calendar = pd.DataFrame(\n",
    "        {\n",
    "            \"hour\": df[\"datetime\"].dt.hour,\n",
    "            \"dow\": df[\"datetime\"].dt.dayofweek,\n",
    "            \"month\": df[\"datetime\"].dt.month,\n",
    "        }\n",
    "    )\n",
    "    calendar[\"hour_sin\"] = np.sin(2 * np.pi * calendar[\"hour\"] / 24.0)\n",
    "    calendar[\"hour_cos\"] = np.cos(2 * np.pi * calendar[\"hour\"] / 24.0)\n",
    "    calendar[\"dow_sin\"] = np.sin(2 * np.pi * calendar[\"dow\"] / 7.0)\n",
    "    calendar[\"dow_cos\"] = np.cos(2 * np.pi * calendar[\"dow\"] / 7.0)\n",
    "    calendar[\"month_sin\"] = np.sin(2 * np.pi * calendar[\"month\"] / 12.0)\n",
    "    calendar[\"month_cos\"] = np.cos(2 * np.pi * calendar[\"month\"] / 12.0)\n",
    "\n",
    "    feature_frame = pd.concat(\n",
    "        [df[[\"datetime\", target_col]], df[pollutant_cols + meteorology_cols], calendar],\n",
    "        axis=1,\n",
    "    )\n",
    "    mask_frame = mask.astype(np.float32)\n",
    "    mask_frame.columns = [f\"{col}_mask\" for col in mask_frame.columns]\n",
    "    feature_frame = pd.concat([feature_frame, mask_frame], axis=1)\n",
    "    return feature_frame, mask_frame\n",
    "\n",
    "\n",
    "def build_temporal_windows(frame, target_col, feature_cols, context, horizon, drop_na=True):\n",
    "    \"\"\"\n",
    "    Returns (windows, targets, indices) where:\n",
    "      - windows: list/array of shape (n_windows, context, n_features)\n",
    "      - targets: list/array of target values aligned at idx+horizon\n",
    "      - indices: original indices of the window end (optional)\n",
    "    This robustly handles scalar/array targets and missing values.\n",
    "    \"\"\"\n",
    "    values = frame[feature_cols].to_numpy(dtype=np.float32)\n",
    "    targets = frame[target_col].to_numpy(dtype=np.float32)\n",
    "    windows = []\n",
    "    target_list = []\n",
    "    idxs = []\n",
    "\n",
    "    n = len(values)\n",
    "    for idx in range(context, n - horizon):\n",
    "        window = values[idx - context : idx]\n",
    "        target = targets[idx + horizon]\n",
    "\n",
    "        if drop_na:\n",
    "            # Use pd.isna then np.any so this works if `target` is scalar or array-like\n",
    "            if np.any(pd.isna(window)) or np.any(pd.isna(target)):\n",
    "                continue\n",
    "\n",
    "        windows.append(window)\n",
    "        target_list.append(target)\n",
    "        idxs.append(idx)\n",
    "\n",
    "    X = np.stack(windows).astype(np.float32) if windows else np.empty((0, context, values.shape[1]), dtype=np.float32)\n",
    "    y = np.array(target_list, dtype=np.float32)\n",
    "    return X, y, np.array(idxs)\n",
    "\n",
    "\n",
    "def assemble_beijing_cross_station_bundle(\n",
    "    stations: Dict[str, pd.DataFrame],\n",
    "    train_stations: List[str],\n",
    "    val_station: str,\n",
    "    test_station: str,\n",
    "    target: str = \"PM2.5\",\n",
    "    context: int = 24,\n",
    "    horizon: int = 6,\n",
    ") -> DatasetBundle:\n",
    "    feature_frames: Dict[str, pd.DataFrame] = {}\n",
    "    feature_cols: Optional[List[str]] = None\n",
    "    for name, df in stations.items():\n",
    "        features, _ = preprocess_beijing_station(df, target_col=target)\n",
    "        feature_frames[name] = features\n",
    "        if feature_cols is None:\n",
    "            feature_cols = [col for col in features.columns if col not in (\"datetime\", target)]\n",
    "    assert feature_cols is not None\n",
    "\n",
    "    def collect(names: List[str]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        arrays = []\n",
    "        targets = []\n",
    "        for station_name in names:\n",
    "            frame = feature_frames[station_name]\n",
    "            X, y, _ = build_temporal_windows(frame, target, feature_cols, context, horizon)\n",
    "            arrays.append(X)\n",
    "            targets.append(y)\n",
    "        if arrays:\n",
    "            X_all = np.concatenate(arrays, axis=0).astype(np.float32)\n",
    "            y_all = np.concatenate(targets, axis=0)\n",
    "            if y_all.ndim == 1:\n",
    "                y_all = y_all[:, None]\n",
    "            else:\n",
    "                y_all = y_all.reshape(y_all.shape[0], -1)\n",
    "            y_all = y_all.astype(np.float32)\n",
    "        else:\n",
    "            X_all = np.empty((0, context, len(feature_cols)), dtype=np.float32)\n",
    "            y_all = np.empty((0, 1), dtype=np.float32)\n",
    "        return X_all, y_all\n",
    "\n",
    "    X_train, y_train = collect(train_stations)\n",
    "    X_val, y_val = collect([val_station])\n",
    "    X_test, y_test = collect([test_station])\n",
    "\n",
    "    bundle = DatasetBundle(\n",
    "        name=f\"Beijing_PM25_{context}h_ctx_{horizon}h_horizon\",\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"sequence\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=[target],\n",
    "        train={\"X\": X_train, \"y\": y_train},\n",
    "        val={\"X\": X_val, \"y\": y_val},\n",
    "        test={\"X\": X_test, \"y\": y_test},\n",
    "        metadata={\n",
    "            \"context_hours\": context,\n",
    "            \"horizon_hours\": horizon,\n",
    "            \"train_stations\": train_stations,\n",
    "            \"val_station\": val_station,\n",
    "            \"test_station\": test_station,\n",
    "        },\n",
    "    )\n",
    "    return bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5367c9e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5367c9e2",
    "outputId": "45deb62c-64a3-406c-ed6e-3d9e6e0d0b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device name: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "SEED = int(os.getenv(\"PSANN_GLOBAL_SEED\", \"2025\"))\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "GLOBAL_CONFIG: Dict[str, Any] = {\n",
    "    \"seed\": SEED,\n",
    "    \"device\": DEVICE,\n",
    "    \"default_epochs\": 100,\n",
    "    \"default_lr\": 1e-3,\n",
    "    \"default_weight_decay\": 0.0,\n",
    "    \"default_batch_size\": 256,\n",
    "    \"max_time_minutes\": 5.0,\n",
    "    \"num_workers\": 2 if DEVICE.type == \"cuda\" else 0,\n",
    "    \"label_smoothing\": 0.05,\n",
    "    \"results_root\": RESULTS_ROOT,\n",
    "    \"figure_root\": FIGURE_ROOT,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8025e56a",
   "metadata": {
    "id": "8025e56a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "\n",
    "def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "\n",
    "\n",
    "def mae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def smape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred) + 1e-8) / 2.0\n",
    "    return float(np.mean(np.abs(y_true - y_pred) / denom))\n",
    "\n",
    "\n",
    "def r2_score_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return float(1 - ss_res / ss_tot) if ss_tot != 0 else float('nan')\n",
    "\n",
    "\n",
    "def mase(y_true: np.ndarray, y_pred: np.ndarray, seasonal_period: int = 1) -> float:\n",
    "    if len(y_true) <= seasonal_period:\n",
    "        return float('nan')\n",
    "    naive = np.mean(np.abs(np.diff(y_true, n=seasonal_period)))\n",
    "    return float(np.mean(np.abs(y_true - y_pred)) / (naive + 1e-8))\n",
    "\n",
    "\n",
    "def expected_calibration_error(probs: np.ndarray, y_true: np.ndarray, n_bins: int = 15) -> float:\n",
    "    confidences = probs.max(axis=1)\n",
    "    predictions = probs.argmax(axis=1)\n",
    "    bin_edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences >= bin_edges[i]) & (confidences < bin_edges[i + 1])\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        bin_acc = np.mean(predictions[mask] == y_true[mask])\n",
    "        bin_conf = np.mean(confidences[mask])\n",
    "        ece += np.abs(bin_acc - bin_conf) * np.mean(mask)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def classification_metrics(y_true: np.ndarray, logits: np.ndarray, average: str = 'macro') -> Dict[str, float]:\n",
    "    probs = torch.softmax(torch.from_numpy(logits), dim=-1).numpy()\n",
    "    preds = probs.argmax(axis=1)\n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy_score(y_true, preds)),\n",
    "        'f1_macro': float(f1_score(y_true, preds, average=average)),\n",
    "        'nll': float(log_loss(y_true, probs, labels=list(range(probs.shape[1])))),\n",
    "    }\n",
    "    metrics['ece'] = expected_calibration_error(probs, y_true, n_bins=15)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _prepare_regression_arrays(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if y_true.ndim > 2:\n",
    "        y_true = y_true.reshape(y_true.shape[0], -1)\n",
    "    if y_pred.ndim > 2:\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], -1)\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = y_true[:, None]\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred[:, None]\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f'Regression metric shape mismatch: {y_true.shape} vs {y_pred.shape}')\n",
    "    return y_true.astype(np.float64), y_pred.astype(np.float64)\n",
    "\n",
    "\n",
    "def regression_metrics(y_true: np.ndarray, y_pred: np.ndarray, seasonal_period: int = 1) -> Dict[str, float]:\n",
    "    y_true, y_pred = _prepare_regression_arrays(y_true, y_pred)\n",
    "    rmse_vals = []\n",
    "    mae_vals = []\n",
    "    smape_vals = []\n",
    "    r2_vals = []\n",
    "    mase_vals = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "        rmse_vals.append(rmse(yt, yp))\n",
    "        mae_vals.append(mae(yt, yp))\n",
    "        smape_vals.append(smape(yt, yp))\n",
    "        r2_vals.append(r2_score_np(yt, yp))\n",
    "        mase_vals.append(mase(yt, yp, seasonal_period=seasonal_period))\n",
    "    return {\n",
    "        'rmse': float(np.mean(rmse_vals)),\n",
    "        'mae': float(np.mean(mae_vals)),\n",
    "        'smape': float(np.mean(smape_vals)),\n",
    "        'r2': float(np.mean(r2_vals)),\n",
    "        'mase': float(np.mean(mase_vals)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7ff9d3d",
   "metadata": {
    "id": "d7ff9d3d"
   },
   "outputs": [],
   "source": [
    "def build_dataloader(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    batch_size: int,\n",
    "    shuffle: bool,\n",
    "    task_type: Literal[\"regression\", \"classification\", \"multitask\"] = \"regression\",\n",
    "    drop_last: bool = False,\n",
    ") -> DataLoader:\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    if task_type == \"classification\":\n",
    "        y_tensor = torch.from_numpy(y.squeeze()).long()\n",
    "    else:\n",
    "        y_tensor = torch.from_numpy(y.astype(np.float32))\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=GLOBAL_CONFIG[\"num_workers\"],\n",
    "        pin_memory=(DEVICE.type == \"cuda\"),\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.start = time.perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.end = time.perf_counter()\n",
    "\n",
    "    @property\n",
    "    def elapsed(self) -> float:\n",
    "        return getattr(self, \"end\", time.perf_counter()) - getattr(self, \"start\", time.perf_counter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c32b3093",
   "metadata": {
    "id": "c32b3093"
   },
   "outputs": [],
   "source": [
    "def coerce_decimal(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return series\n",
    "    as_str = series.astype(str).str.replace(\" \", \"\")\n",
    "    as_str = as_str.replace({\"nan\": np.nan, \"None\": np.nan})\n",
    "    as_str = as_str.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(as_str, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def coerce_datetime(series: pd.Series) -> pd.Series:\n",
    "    as_str = series.astype(str).str.strip()\n",
    "    as_str = as_str.replace({\"nan\": np.nan, \"NaT\": np.nan})\n",
    "    as_str = as_str.str.replace(\",\", \".\", n=1, regex=False)\n",
    "    return pd.to_datetime(as_str, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def ensure_float(df: pd.DataFrame, columns: Iterable[str]) -> pd.DataFrame:\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = coerce_decimal(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_datetime(df: pd.DataFrame, columns: Iterable[str]) -> pd.DataFrame:\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = coerce_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_calendar_features(frame: pd.DataFrame, timestamp_col: str) -> pd.DataFrame:\n",
    "    ts = pd.to_datetime(frame[timestamp_col])\n",
    "    frame[f\"{timestamp_col}_year\"] = ts.dt.year\n",
    "    frame[f\"{timestamp_col}_month\"] = ts.dt.month\n",
    "    frame[f\"{timestamp_col}_day\"] = ts.dt.day\n",
    "    frame[f\"{timestamp_col}_hour\"] = ts.dt.hour\n",
    "    frame[f\"{timestamp_col}_dow\"] = ts.dt.dayofweek\n",
    "    frame[f\"{timestamp_col}_week\"] = ts.dt.isocalendar().week.astype(int)\n",
    "    frame[f\"{timestamp_col}_dayofyear\"] = ts.dt.dayofyear\n",
    "    frame[f\"{timestamp_col}_sin_hour\"] = np.sin(2 * np.pi * frame[f\"{timestamp_col}_hour\"] / 24.0)\n",
    "    frame[f\"{timestamp_col}_cos_hour\"] = np.cos(2 * np.pi * frame[f\"{timestamp_col}_hour\"] / 24.0)\n",
    "    frame[f\"{timestamp_col}_sin_dayofyear\"] = np.sin(2 * np.pi * frame[f\"{timestamp_col}_dayofyear\"] / 365.25)\n",
    "    frame[f\"{timestamp_col}_cos_dayofyear\"] = np.cos(2 * np.pi * frame[f\"{timestamp_col}_dayofyear\"] / 365.25)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def train_val_test_split_by_time(df: pd.DataFrame, time_col: str, train_end: str, val_end: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    ts = pd.to_datetime(df[time_col])\n",
    "    train_mask = ts < pd.to_datetime(train_end)\n",
    "    val_mask = (ts >= pd.to_datetime(train_end)) & (ts < pd.to_datetime(val_end))\n",
    "    test_mask = ts >= pd.to_datetime(val_end)\n",
    "    return df[train_mask].copy(), df[val_mask].copy(), df[test_mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e7bd4b5",
   "metadata": {
    "id": "3e7bd4b5"
   },
   "outputs": [],
   "source": [
    "EAF_TABLES = [\n",
    "    \"eaf_temp\",\n",
    "    \"eaf_gaslance_mat\",\n",
    "    \"inj_mat\",\n",
    "    \"eaf_transformer\",\n",
    "    \"eaf_added_materials\",\n",
    "    \"basket_charged\",\n",
    "    \"lf_added_materials\",\n",
    "    \"lf_initial_chemical_measurements\",\n",
    "    \"eaf_final_chemical_measurements\",\n",
    "    \"ladle_tapping\",\n",
    "]\n",
    "\n",
    "\n",
    "def parse_duration_minutes(value: Any) -> Optional[float]:\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    s = str(value).strip()\n",
    "    if not s:\n",
    "        return np.nan\n",
    "    s = s.replace(\" \", \"\")\n",
    "    if \":\" not in s:\n",
    "        return coerce_decimal(pd.Series([s])).iloc[0]\n",
    "    parts = s.split(\":\")\n",
    "    try:\n",
    "        hours = float(parts[0])\n",
    "        minutes = float(parts[1])\n",
    "        return hours * 60.0 + minutes\n",
    "    except Exception:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a55a25b",
   "metadata": {
    "id": "7a55a25b"
   },
   "outputs": [],
   "source": [
    "def load_eaf_tables(data_root: Path) -> Dict[str, pd.DataFrame]:\n",
    "    candidate_dirs = [\n",
    "        data_root / \"Industrial Data from the Electric Arc Furnace\",\n",
    "        data_root / \"Industrial_Data_from_the_Electric_Arc_Furnace\",\n",
    "    ]\n",
    "    base = next((path for path in candidate_dirs if path.exists()), None)\n",
    "\n",
    "    table_paths: Dict[str, Path] = {}\n",
    "    if base is not None:\n",
    "        table_paths = {name: base / f\"{name}.csv\" for name in EAF_TABLES}\n",
    "    else:\n",
    "        print(f\"[WARN] Expected EAF directory missing under {data_root}. Falling back to glob search.\")\n",
    "        for name in EAF_TABLES:\n",
    "            path = next(\n",
    "                (\n",
    "                    candidate\n",
    "                    for candidate in [\n",
    "                        data_root / f\"{name}.csv\",\n",
    "                        data_root / f\"{name.upper()}.csv\",\n",
    "                    ]\n",
    "                    if candidate.exists()\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if path is None:\n",
    "                matches = list(data_root.rglob(f\"{name}.csv\"))\n",
    "                if matches:\n",
    "                    path = matches[0]\n",
    "            table_paths[name] = path\n",
    "\n",
    "    missing = [name for name, path in table_paths.items() if path is None or not path.exists()]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(\n",
    "            \"Unable to locate EAF tables: \" + \", \".join(missing) + f\". Ensure the CSV files are present under {data_root}.\"\n",
    "        )\n",
    "\n",
    "    tables: Dict[str, pd.DataFrame] = {}\n",
    "    for name, path in table_paths.items():\n",
    "        if path is None:\n",
    "            continue\n",
    "        print(f\"Loading {name} from {path}...\")\n",
    "        if name in {\"eaf_gaslance_mat\", \"inj_mat\"}:\n",
    "            df = pd.read_csv(path, dtype=str)\n",
    "            df = ensure_datetime(df, [\"REVTIME\"])\n",
    "            if \"DATETIME\" not in df.columns and \"REVTIME\" in df.columns:\n",
    "                df[\"DATETIME\"] = df[\"REVTIME\"]\n",
    "            numeric_cols = [c for c in df.columns if c not in (\"REVTIME\", \"HEATID\", \"DATETIME\")]\n",
    "            df = ensure_float(df, numeric_cols)\n",
    "        elif name == \"eaf_temp\":\n",
    "            df = pd.read_csv(path)\n",
    "            df = ensure_datetime(df, [\"DATETIME\"])\n",
    "            numeric_cols = [c for c in df.columns if c not in (\"HEATID\", \"DATETIME\")]\n",
    "            df = ensure_float(df, numeric_cols)\n",
    "        elif name == \"eaf_transformer\":\n",
    "            df = pd.read_csv(path, dtype=str)\n",
    "            df = ensure_datetime(df, [\"STARTTIME\"])\n",
    "            if \"DATETIME\" not in df.columns and \"STARTTIME\" in df.columns:\n",
    "                df[\"DATETIME\"] = df[\"STARTTIME\"]\n",
    "            df[\"DURATION_MIN\"] = df[\"DURATION\"].astype(str).str.replace(\" \", \"\")\n",
    "            df[\"DURATION_MIN\"] = df[\"DURATION_MIN\"].apply(parse_duration_minutes)\n",
    "            df = ensure_float(df, [\"DURATION_MIN\", \"MW\"])\n",
    "        else:\n",
    "            df = pd.read_csv(path, dtype=str)\n",
    "            datetime_cols = [c for c in df.columns if \"DATE\" in c.upper() or \"TIME\" in c.upper()]\n",
    "            if datetime_cols:\n",
    "                df = ensure_datetime(df, datetime_cols)\n",
    "                if \"DATETIME\" not in df.columns:\n",
    "                    df[\"DATETIME\"] = df[datetime_cols[0]]\n",
    "            numeric_cols = [\n",
    "                c\n",
    "                for c in df.columns\n",
    "                if c not in datetime_cols and c not in (\"HEATID\", \"RECID\", \"POSITIONROW\", \"DATETIME\")\n",
    "            ]\n",
    "            df = ensure_float(df, numeric_cols)\n",
    "        tables[name] = df\n",
    "    return tables\n",
    "\n",
    "\n",
    "def compute_heatwise_aggregates(df: pd.DataFrame, heat_col: str, aggregations: Dict[str, List[str]]) -> pd.DataFrame:\n",
    "    grouped = df.groupby(heat_col).agg(aggregations)\n",
    "    grouped.columns = [f\"{col}_{agg}\" for col, agg in grouped.columns]\n",
    "    grouped = grouped.reset_index()\n",
    "    return grouped\n",
    "\n",
    "# Fixed vectorized merge_asof_multikey (searchsorted-based, dtype-safe assignments)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "def merge_asof_multikey(\n",
    "    left: pd.DataFrame,\n",
    "    right: pd.DataFrame,\n",
    "    *,\n",
    "    on: str,\n",
    "    by: str,\n",
    "    suffix: str = \"rhs\",\n",
    "    tolerance: Optional[pd.Timedelta] = None,\n",
    "    direction: str = \"backward\",\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Vectorized as-of merge on (by, on) using numpy.searchsorted on structured keys.\n",
    "    Supports direction='backward' (most common for telemetry alignment).\n",
    "    Returns left with right's non-key columns suffixed by _{suffix}.\n",
    "    \"\"\"\n",
    "    if right is None or len(right) == 0:\n",
    "        return left.copy()\n",
    "    if direction != \"backward\":\n",
    "        raise NotImplementedError(\"Only 'backward' direction supported in this implementation\")\n",
    "\n",
    "    # Basic checks\n",
    "    if on not in left.columns or on not in right.columns or by not in left.columns or by not in right.columns:\n",
    "        raise KeyError(f\"Both frames must contain columns '{by}' and '{on}'\")\n",
    "\n",
    "    # Work on copies\n",
    "    L = left.copy()\n",
    "    R = right.copy()\n",
    "\n",
    "    # Mask and filter rows missing keys (we'll reattach them at the end)\n",
    "    mask_L_valid = L[on].notna() & L[by].notna()\n",
    "    mask_R_valid = R[on].notna() & R[by].notna()\n",
    "    L_valid = L.loc[mask_L_valid].copy()\n",
    "    R_valid = R.loc[mask_R_valid].copy()\n",
    "\n",
    "    # Coerce datetimes\n",
    "    L_valid[on] = pd.to_datetime(L_valid[on], errors=\"coerce\")\n",
    "    R_valid[on] = pd.to_datetime(R_valid[on], errors=\"coerce\")\n",
    "    L_valid = L_valid[L_valid[on].notna()]\n",
    "    R_valid = R_valid[R_valid[on].notna()]\n",
    "\n",
    "    # If no valid rows remain on left, return original left with NaNs for merge cols\n",
    "    if L_valid.empty:\n",
    "        merged = L.copy()\n",
    "        merge_cols = [c for c in R.columns if c not in (by, on)]\n",
    "        for c in merge_cols:\n",
    "            merged[f\"{c}_{suffix}\"] = np.nan\n",
    "        return merged\n",
    "\n",
    "    # Dedupe right on (by, on) keeping last measurement (reduces search space)\n",
    "    R_valid = R_valid.sort_values([by, on], kind=\"mergesort\").drop_duplicates(subset=[by, on], keep=\"last\")\n",
    "\n",
    "    # Factorize right groups to compact integer ids\n",
    "    right_labels = pd.unique(R_valid[by].astype(object))  # preserve order\n",
    "    group_to_id = {val: i for i, val in enumerate(right_labels)}\n",
    "    # Map right group ids\n",
    "    right_group_ids = np.array([group_to_id[v] for v in R_valid[by].astype(object)], dtype=np.int32)\n",
    "\n",
    "    # Map left group ids; groups not in right get -1\n",
    "    left_group_values = L_valid[by].astype(object).values\n",
    "    left_group_ids = np.array([group_to_id.get(v, -1) for v in left_group_values], dtype=np.int32)\n",
    "\n",
    "    # Convert times to int64 ns\n",
    "    left_times_ns = L_valid[on].values.astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "    right_times_ns = R_valid[on].values.astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "\n",
    "    # Build structured keys and sort by (group,time)\n",
    "    key_dtype = np.dtype([(\"g\", np.int32), (\"t\", np.int64)])\n",
    "    right_keys = np.empty(len(right_group_ids), dtype=key_dtype)\n",
    "    right_keys[\"g\"] = right_group_ids\n",
    "    right_keys[\"t\"] = right_times_ns\n",
    "    order = np.argsort(right_keys, order=(\"g\", \"t\"))\n",
    "    right_keys_sorted = right_keys[order]\n",
    "    R_sorted = R_valid.reset_index(drop=True).iloc[order].reset_index(drop=True)\n",
    "    right_times_sorted = right_keys_sorted[\"t\"]\n",
    "\n",
    "    # Left keys structured array (same dtype)\n",
    "    left_keys = np.empty(len(left_group_ids), dtype=key_dtype)\n",
    "    left_keys[\"g\"] = left_group_ids\n",
    "    left_keys[\"t\"] = left_times_ns\n",
    "\n",
    "    # Searchsorted to find previous (backward) right index for each left key\n",
    "    idxs = np.searchsorted(right_keys_sorted, left_keys, side=\"right\") - 1\n",
    "\n",
    "    # Initialize keep_mask (default False)\n",
    "    keep_mask = np.zeros(len(idxs), dtype=bool)\n",
    "\n",
    "    # valid where idxs >= 0\n",
    "    valid_mask = idxs >= 0\n",
    "    if valid_mask.any():\n",
    "        # Check matched group's id equals left group id (otherwise it's from a different group)\n",
    "        matched_group_ids = right_keys_sorted[\"g\"][idxs[valid_mask]]\n",
    "        left_group_ids_valid = left_keys[\"g\"][valid_mask]\n",
    "        same_group = matched_group_ids == left_group_ids_valid\n",
    "        # Set keep_mask True only where same_group is True\n",
    "        keep_mask[np.flatnonzero(valid_mask)[same_group]] = True\n",
    "\n",
    "    # Apply tolerance if provided (left_time - matched_right_time must be <= tol and >=0)\n",
    "    if tolerance is not None and keep_mask.any():\n",
    "        tol_ns = int(pd.to_timedelta(tolerance).to_timedelta64().astype(\"timedelta64[ns]\") / np.timedelta64(1, \"ns\"))\n",
    "        kept_positions = np.flatnonzero(keep_mask)\n",
    "        matched_right_times = right_times_sorted[idxs[kept_positions]]\n",
    "        left_times_for_kept = left_keys[\"t\"][kept_positions]\n",
    "        diffs = left_times_for_kept - matched_right_times\n",
    "        tol_ok = (diffs >= 0) & (diffs <= tol_ns)\n",
    "        # Zero out positions violating tolerance\n",
    "        if not np.all(tol_ok):\n",
    "            keep_mask[kept_positions[~tol_ok]] = False\n",
    "\n",
    "    # Prepare result skeleton using proper dtypes (avoid assigning arrays of incompatible dtype)\n",
    "    merge_cols = [c for c in R_sorted.columns if c not in (by, on)]\n",
    "    result = L_valid.copy()\n",
    "    for c in merge_cols:\n",
    "        src_dtype = R_sorted[c].dtype\n",
    "        try:\n",
    "            result[f\"{c}_{suffix}\"] = pd.Series(index=result.index, dtype=src_dtype)\n",
    "        except Exception:\n",
    "            result[f\"{c}_{suffix}\"] = pd.Series(index=result.index, dtype=\"object\")\n",
    "\n",
    "    # Fill merged columns for kept matches\n",
    "    kept_positions = np.flatnonzero(keep_mask)\n",
    "    if kept_positions.size:\n",
    "        matched_idxs = idxs[kept_positions]  # indices into R_sorted\n",
    "        for col in merge_cols:\n",
    "            vals = R_sorted.iloc[matched_idxs][col].values\n",
    "            s = pd.Series(vals, index=result.index[kept_positions])\n",
    "            # If target dtype is datetime, ensure series is datetime\n",
    "            if np.issubdtype(result[f\"{col}_{suffix}\"].dtype, np.datetime64):\n",
    "                s = pd.to_datetime(s)\n",
    "            result.loc[result.index[kept_positions], f\"{col}_{suffix}\"] = s\n",
    "\n",
    "    # Rows that were invalid (no match) remain NaN in merged cols\n",
    "\n",
    "    # Reattach left rows that were dropped due to missing keys\n",
    "    if mask_L_valid.sum() != len(L):\n",
    "        dropped = L.loc[~mask_L_valid].copy()\n",
    "        for c in merge_cols:\n",
    "            dropped[f\"{c}_{suffix}\"] = np.nan\n",
    "        combined = pd.concat([result, dropped]).loc[L.index]\n",
    "    else:\n",
    "        combined = result\n",
    "\n",
    "    # Reindex to original left.index to preserve order\n",
    "    combined = combined.reindex(left.index)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12cfea05",
   "metadata": {
    "id": "12cfea05"
   },
   "outputs": [],
   "source": [
    "def prepare_eaf_temp_and_o2_bundles(\n",
    "    tables: Dict[str, pd.DataFrame],\n",
    "    history_lags: List[int] = (1, 2, 3, 6),\n",
    "    horizon: int = 1,\n",
    ") -> Tuple[DatasetBundle, DatasetBundle]:\n",
    "    temp = tables[\"eaf_temp\"].copy()\n",
    "    temp[\"DATETIME\"] = pd.to_datetime(temp[\"DATETIME\"])\n",
    "    temp = temp.sort_values([\"HEATID\", \"DATETIME\"]).reset_index(drop=True)\n",
    "    temp = temp.drop_duplicates(subset=[\"HEATID\", \"DATETIME\"], keep=\"last\")\n",
    "\n",
    "    for lag in history_lags:\n",
    "        temp[f\"TEMP_lag_{lag}\"] = temp.groupby(\"HEATID\")[\"TEMP\"].shift(lag)\n",
    "        temp[f\"VALO2_lag_{lag}\"] = temp.groupby(\"HEATID\")[\"VALO2_PPM\"].shift(lag)\n",
    "\n",
    "    temp[\"TEMP_target\"] = temp.groupby(\"HEATID\")[\"TEMP\"].shift(-horizon)\n",
    "    temp[\"VALO2_target\"] = temp.groupby(\"HEATID\")[\"VALO2_PPM\"].shift(-horizon)\n",
    "\n",
    "    temp[\"HEAT_START\"] = temp.groupby(\"HEATID\")[\"DATETIME\"].transform(\"min\")\n",
    "    temp[\"minutes_from_heat_start\"] = (temp[\"DATETIME\"] - temp[\"HEAT_START\"]).dt.total_seconds() / 60.0\n",
    "    temp[\"sample_index\"] = temp.groupby(\"HEATID\").cumcount()\n",
    "    temp[\"minutes_between_samples\"] = temp.groupby(\"HEATID\")[\"DATETIME\"].diff().dt.total_seconds().fillna(0.0) / 60.0\n",
    "\n",
    "    gas = tables.get(\"eaf_gaslance_mat\")\n",
    "    if gas is not None and not gas.empty:\n",
    "        gas = gas.sort_values([\"HEATID\", \"REVTIME\"])\n",
    "        for col in [\"O2_AMOUNT\", \"GAS_AMOUNT\", \"O2_FLOW\", \"GAS_FLOW\"]:\n",
    "            if col in gas.columns:\n",
    "                gas[f\"{col}_cum\"] = gas.groupby(\"HEATID\")[col].cumsum()\n",
    "        temp = merge_asof_multikey(\n",
    "            temp,\n",
    "            gas,\n",
    "            on=\"DATETIME\",\n",
    "            by=\"HEATID\",\n",
    "            suffix=\"gas\",\n",
    "            tolerance=pd.Timedelta(minutes=30),\n",
    "        )\n",
    "\n",
    "    inj = tables.get(\"inj_mat\")\n",
    "    if inj is not None and not inj.empty:\n",
    "        inj = inj.sort_values([\"HEATID\", \"REVTIME\"])\n",
    "        for col in [\"INJ_AMOUNT_CARBON\", \"INJ_FLOW_CARBON\"]:\n",
    "            if col in inj.columns:\n",
    "                inj[f\"{col}_cum\"] = inj.groupby(\"HEATID\")[col].cumsum()\n",
    "        temp = merge_asof_multikey(\n",
    "            temp,\n",
    "            inj,\n",
    "            on=\"DATETIME\",\n",
    "            by=\"HEATID\",\n",
    "            suffix=\"inj\",\n",
    "            tolerance=pd.Timedelta(minutes=30),\n",
    "        )\n",
    "\n",
    "    transformer = tables.get(\"eaf_transformer\")\n",
    "    if transformer is not None and not transformer.empty:\n",
    "        transformer = transformer.sort_values([\"HEATID\", \"STARTTIME\"])\n",
    "        temp = merge_asof_multikey(\n",
    "            temp,\n",
    "            transformer,\n",
    "            on=\"DATETIME\",\n",
    "            by=\"HEATID\",\n",
    "            suffix=\"xfmr\",\n",
    "            tolerance=pd.Timedelta(hours=2),\n",
    "        )\n",
    "\n",
    "    temp = add_calendar_features(temp, \"DATETIME\")\n",
    "    feature_cols = [\n",
    "        col\n",
    "        for col in temp.columns\n",
    "        if col\n",
    "        not in {\n",
    "            \"TEMP\",\n",
    "            \"VALO2_PPM\",\n",
    "            \"TEMP_target\",\n",
    "            \"VALO2_target\",\n",
    "            \"HEATID\",\n",
    "            \"HEAT_START\",\n",
    "            \"DATETIME\",\n",
    "        }\n",
    "        and not col.endswith(\"_xfmr\")\n",
    "    ]\n",
    "    feature_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(temp[c])]\n",
    "\n",
    "    temp[feature_cols] = temp[feature_cols].astype(np.float32)\n",
    "\n",
    "    temp = temp.dropna(subset=feature_cols + [\"TEMP_target\", \"VALO2_target\"]).reset_index(drop=True)\n",
    "\n",
    "    temp[\"year\"] = temp[\"DATETIME\"].dt.year\n",
    "    heat_year = temp.groupby(\"HEATID\")[\"year\"].max().reset_index().rename(columns={\"year\": \"heat_year\"})\n",
    "    temp = temp.merge(heat_year, on=\"HEATID\", how=\"left\")\n",
    "\n",
    "    train_mask = temp[\"heat_year\"] <= 2016\n",
    "    val_mask = temp[\"heat_year\"] == 2017\n",
    "    test_mask = temp[\"heat_year\"] >= 2018\n",
    "\n",
    "\n",
    "    feature_mean = temp.loc[train_mask, feature_cols].mean()\n",
    "    feature_std = temp.loc[train_mask, feature_cols].std().replace(0.0, 1.0)\n",
    "    temp[feature_cols] = (temp[feature_cols] - feature_mean) / feature_std\n",
    "\n",
    "    scaler_meta = {\n",
    "        \"feature_mean\": {k: float(v) for k, v in feature_mean.items()},\n",
    "        \"feature_std\": {k: float(v) for k, v in feature_std.items()},\n",
    "    }\n",
    "\n",
    "    def build_split(mask: pd.Series) -> Dict[str, np.ndarray]:\n",
    "        X = temp.loc[mask, feature_cols].to_numpy(dtype=np.float32)\n",
    "        y_temp = temp.loc[mask, \"TEMP_target\"].to_numpy(dtype=np.float32)[:, None]\n",
    "        y_o2 = temp.loc[mask, \"VALO2_target\"].to_numpy(dtype=np.float32)[:, None]\n",
    "        return {\"X\": X, \"y_temp\": y_temp, \"y_o2\": y_o2}\n",
    "\n",
    "    train_split = build_split(train_mask)\n",
    "    val_split = build_split(val_mask)\n",
    "    test_split = build_split(test_mask)\n",
    "\n",
    "    temp_target_mean = train_split[\"y_temp\"].mean(axis=0, keepdims=True)\n",
    "    temp_target_std = train_split[\"y_temp\"].std(axis=0, keepdims=True)\n",
    "    temp_target_std = np.where(temp_target_std < 1e-6, 1.0, temp_target_std)\n",
    "\n",
    "    o2_target_mean = train_split[\"y_o2\"].mean(axis=0, keepdims=True)\n",
    "    o2_target_std = train_split[\"y_o2\"].std(axis=0, keepdims=True)\n",
    "    o2_target_std = np.where(o2_target_std < 1e-6, 1.0, o2_target_std)\n",
    "\n",
    "    def _normalize_target(split: Dict[str, np.ndarray], key: str, mean: np.ndarray, std: np.ndarray) -> None:\n",
    "        split[key] = ((split[key] - mean) / std).astype(np.float32)\n",
    "\n",
    "    for split_dict in (train_split, val_split, test_split):\n",
    "        _normalize_target(split_dict, \"y_temp\", temp_target_mean, temp_target_std)\n",
    "        _normalize_target(split_dict, \"y_o2\", o2_target_mean, o2_target_std)\n",
    "\n",
    "    temp_bundle = DatasetBundle(\n",
    "        name=\"EAF_TEMP_forecast\",\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"tabular\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=[\"TEMP_target\"],\n",
    "        train={\"X\": train_split[\"X\"], \"y\": train_split[\"y_temp\"]},\n",
    "        val={\"X\": val_split[\"X\"], \"y\": val_split[\"y_temp\"]},\n",
    "        test={\"X\": test_split[\"X\"], \"y\": test_split[\"y_temp\"]},\n",
    "        metadata={\n",
    "            \"horizon_steps\": horizon,\n",
    "            \"history_lags\": list(history_lags),\n",
    "            \"feature_source\": \"temp + gas + injection + calendar\",\n",
    "            **scaler_meta,\n",
    "            \"target_scaler\": {\n",
    "                \"mean\": float(temp_target_mean.squeeze()),\n",
    "                \"std\": float(temp_target_std.squeeze()),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    o2_bundle = DatasetBundle(\n",
    "        name=\"EAF_VALO2_forecast\",\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"tabular\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=[\"VALO2_target\"],\n",
    "        train={\"X\": train_split[\"X\"], \"y\": train_split[\"y_o2\"]},\n",
    "        val={\"X\": val_split[\"X\"], \"y\": val_split[\"y_o2\"]},\n",
    "        test={\"X\": test_split[\"X\"], \"y\": test_split[\"y_o2\"]},\n",
    "        metadata={\n",
    "            \"horizon_steps\": horizon,\n",
    "            \"history_lags\": list(history_lags),\n",
    "            \"feature_source\": \"temp + gas + injection + calendar\",\n",
    "            **scaler_meta,\n",
    "            \"target_scaler\": {\n",
    "                \"mean\": float(o2_target_mean.squeeze()),\n",
    "                \"std\": float(o2_target_std.squeeze()),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return temp_bundle, o2_bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9a10e15f",
   "metadata": {
    "id": "9a10e15f"
   },
   "outputs": [],
   "source": [
    "def prepare_eaf_chemistry_bundle(tables: Dict[str, pd.DataFrame]) -> DatasetBundle:\n",
    "    chem = tables[\"eaf_final_chemical_measurements\"].copy()\n",
    "    chem = ensure_datetime(chem, [\"DATETIME\"])\n",
    "    chem = chem.sort_values([\"HEATID\", \"DATETIME\"])\n",
    "    chem = chem.drop_duplicates(subset=[\"HEATID\"], keep=\"last\")\n",
    "\n",
    "    target_cols = [c for c in chem.columns if c not in (\"HEATID\", \"POSITIONROW\", \"DATETIME\")]\n",
    "    chem = ensure_float(chem, target_cols)\n",
    "\n",
    "    temp = tables[\"eaf_temp\"].copy()\n",
    "    temp = ensure_datetime(temp, [\"DATETIME\"])\n",
    "    temp = temp.sort_values([\"HEATID\", \"DATETIME\"])\n",
    "    temp[\"sample_index\"] = temp.groupby(\"HEATID\").cumcount()\n",
    "    temp = add_calendar_features(temp, \"DATETIME\")\n",
    "    temp_aggs = compute_heatwise_aggregates(\n",
    "        temp,\n",
    "        \"HEATID\",\n",
    "        {\n",
    "            \"TEMP\": [\"mean\", \"max\", \"min\", \"last\"],\n",
    "            \"VALO2_PPM\": [\"mean\", \"max\", \"last\"],\n",
    "            \"DATETIME_month\": [\"last\"],\n",
    "            \"DATETIME_hour\": [\"mean\"],\n",
    "            \"sample_index\": [\"max\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    def safe_aggregates(frame: Optional[pd.DataFrame], aggregations: Dict[str, List[str]]) -> pd.DataFrame:\n",
    "        if frame is None or frame.empty:\n",
    "            columns = [\"HEATID\"] + [f\"{feature}_{agg}\" for feature, aggs in aggregations.items() for agg in aggs]\n",
    "            return pd.DataFrame(columns=columns)\n",
    "        frame = frame.copy()\n",
    "        datetime_cols = [c for c in frame.columns if \"TIME\" in c.upper() or \"DATE\" in c.upper()]\n",
    "        if datetime_cols:\n",
    "            frame = ensure_datetime(frame, datetime_cols)\n",
    "        numeric_cols = [c for c in frame.columns if c not in (\"HEATID\", \"REVTIME\", \"STARTTIME\")]\n",
    "        frame = ensure_float(frame, numeric_cols)\n",
    "        return compute_heatwise_aggregates(frame, \"HEATID\", aggregations)\n",
    "\n",
    "    gas_aggs = safe_aggregates(\n",
    "        tables.get(\"eaf_gaslance_mat\"),\n",
    "        {\n",
    "            \"O2_AMOUNT\": [\"max\"],\n",
    "            \"GAS_AMOUNT\": [\"max\"],\n",
    "            \"O2_FLOW\": [\"mean\", \"max\"],\n",
    "            \"GAS_FLOW\": [\"mean\", \"max\"],\n",
    "        },\n",
    "    )\n",
    "    inj_aggs = safe_aggregates(\n",
    "        tables.get(\"inj_mat\"),\n",
    "        {\n",
    "            \"INJ_AMOUNT_CARBON\": [\"max\"],\n",
    "            \"INJ_FLOW_CARBON\": [\"mean\", \"max\"],\n",
    "        },\n",
    "    )\n",
    "    transformer_aggs = safe_aggregates(\n",
    "        tables.get(\"eaf_transformer\"),\n",
    "        {\n",
    "            \"MW\": [\"mean\", \"max\"],\n",
    "            \"DURATION_MIN\": [\"sum\"],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    features = chem[[\"HEATID\", \"DATETIME\"]].merge(temp_aggs, on=\"HEATID\", how=\"left\")\n",
    "    features = features.merge(gas_aggs, on=\"HEATID\", how=\"left\")\n",
    "    features = features.merge(inj_aggs, on=\"HEATID\", how=\"left\")\n",
    "    features = features.merge(transformer_aggs, on=\"HEATID\", how=\"left\")\n",
    "\n",
    "    numeric_feature_cols = [c for c in features.columns if c not in (\"HEATID\", \"DATETIME\")]\n",
    "    features = ensure_float(features, numeric_feature_cols)\n",
    "    features = add_calendar_features(features, \"DATETIME\")\n",
    "    feature_cols = [c for c in features.columns if c not in (\"HEATID\", \"DATETIME\")]\n",
    "\n",
    "    merged = features.merge(chem[[\"HEATID\"] + target_cols], on=\"HEATID\", how=\"inner\")\n",
    "    merged = merged.dropna(subset=feature_cols + target_cols).reset_index(drop=True)\n",
    "\n",
    "    merged[\"year\"] = pd.to_datetime(merged[\"DATETIME\"]).dt.year\n",
    "    train_mask = merged[\"year\"] <= 2016\n",
    "    val_mask = merged[\"year\"] == 2017\n",
    "    test_mask = merged[\"year\"] >= 2018\n",
    "\n",
    "    X_train = merged.loc[train_mask, feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_train = merged.loc[train_mask, target_cols].to_numpy(dtype=np.float32)\n",
    "    X_val = merged.loc[val_mask, feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_val = merged.loc[val_mask, target_cols].to_numpy(dtype=np.float32)\n",
    "    X_test = merged.loc[test_mask, feature_cols].to_numpy(dtype=np.float32)\n",
    "    y_test = merged.loc[test_mask, target_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "    if X_train.size == 0 or X_val.size == 0 or X_test.size == 0:\n",
    "        raise ValueError(\"EAF chemistry splits produced empty partitions; check year filters.\")\n",
    "\n",
    "    feature_mean = X_train.mean(axis=0, keepdims=True)\n",
    "    feature_std = X_train.std(axis=0, keepdims=True)\n",
    "    feature_std = np.where(feature_std < 1e-6, 1.0, feature_std)\n",
    "\n",
    "    target_mean = y_train.mean(axis=0, keepdims=True)\n",
    "    target_std = y_train.std(axis=0, keepdims=True)\n",
    "    target_std = np.where(target_std < 1e-6, 1.0, target_std)\n",
    "\n",
    "    def _normalize(arr: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "        return ((arr - mean) / std).astype(np.float32)\n",
    "\n",
    "    X_train = _normalize(X_train, feature_mean, feature_std)\n",
    "    X_val = _normalize(X_val, feature_mean, feature_std)\n",
    "    X_test = _normalize(X_test, feature_mean, feature_std)\n",
    "\n",
    "    y_train_norm = _normalize(y_train, target_mean, target_std)\n",
    "    y_val_norm = _normalize(y_val, target_mean, target_std)\n",
    "    y_test_norm = _normalize(y_test, target_mean, target_std)\n",
    "\n",
    "    bundle = DatasetBundle(\n",
    "        name=\"EAF_chemistry\",\n",
    "        task_type=\"regression\",\n",
    "        input_kind=\"tabular\",\n",
    "        feature_names=feature_cols,\n",
    "        target_names=target_cols,\n",
    "        train={\"X\": X_train, \"y\": y_train_norm},\n",
    "        val={\"X\": X_val, \"y\": y_val_norm},\n",
    "        test={\"X\": X_test, \"y\": y_test_norm},\n",
    "        metadata={\n",
    "            \"target_dim\": len(target_cols),\n",
    "            \"note\": \"heat-level aggregates for final composition\",\n",
    "            \"feature_scaler\": {\n",
    "                \"mean\": feature_mean.flatten().astype(np.float32).tolist(),\n",
    "                \"std\": feature_std.flatten().astype(np.float32).tolist(),\n",
    "            },\n",
    "            \"target_scaler\": {\n",
    "                \"mean\": target_mean.flatten().astype(np.float32).tolist(),\n",
    "                \"std\": target_std.flatten().astype(np.float32).tolist(),\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "    return bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98e9d6d0",
   "metadata": {
    "id": "98e9d6d0"
   },
   "outputs": [],
   "source": [
    "from psann.nn import ResidualPSANNNet\n",
    "from psann.models.wave_resnet import WaveResNet\n",
    "\n",
    "\n",
    "class IdentitySpine(nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim == 3:\n",
    "            return x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TemporalConvSpine(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        hidden_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 2,\n",
    "        depth: int = 2,\n",
    "        activation: Callable[[], nn.Module] = nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        channels = input_channels\n",
    "        for _ in range(depth):\n",
    "            layers.append(\n",
    "                nn.Conv1d(\n",
    "                    channels,\n",
    "                    hidden_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=kernel_size // 2,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.BatchNorm1d(hidden_channels))\n",
    "            layers.append(activation())\n",
    "            channels = hidden_channels\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = x.transpose(1, 2)\n",
    "        z = self.net(z)\n",
    "        z = self.pool(z).squeeze(-1)\n",
    "        return z\n",
    "\n",
    "\n",
    "class TemporalAttentionSpine(nn.Module):\n",
    "    def __init__(self, input_dim: int, num_heads: int = 1, ff_factor: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True, dropout=dropout)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.LayerNorm(input_dim),\n",
    "            nn.Linear(input_dim, ff_factor * input_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(ff_factor * input_dim, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.norm(x)\n",
    "        attn_out, _ = self.attn(z, z, z)\n",
    "        z = z + attn_out\n",
    "        z = z + self.ff(z)\n",
    "        return z.mean(dim=1)\n",
    "\n",
    "\n",
    "class FlattenSpine(nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim == 3:\n",
    "            return x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SequencePSANNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, ...],\n",
    "        output_dim: int,\n",
    "        *,\n",
    "        hidden_layers: int,\n",
    "        hidden_units: int,\n",
    "        spine_type: str = \"flatten\",\n",
    "        spine_params: Optional[Dict[str, Any]] = None,\n",
    "        activation_type: str = \"psann\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        spine_params = spine_params or {}\n",
    "        time_steps, channels = input_shape\n",
    "        if spine_type == \"conv\":\n",
    "            self.spine = TemporalConvSpine(\n",
    "                channels,\n",
    "                spine_params.get(\"channels\", hidden_units),\n",
    "                kernel_size=spine_params.get(\"kernel_size\", 5),\n",
    "                stride=spine_params.get(\"stride\", 2),\n",
    "                depth=spine_params.get(\"depth\", 2),\n",
    "            )\n",
    "            psann_input_dim = spine_params.get(\"channels\", hidden_units)\n",
    "        elif spine_type == \"attention\":\n",
    "            self.spine = TemporalAttentionSpine(\n",
    "                input_dim=channels,\n",
    "                num_heads=spine_params.get(\"num_heads\", 1),\n",
    "                ff_factor=spine_params.get(\"ff_factor\", 2),\n",
    "                dropout=spine_params.get(\"dropout\", 0.1),\n",
    "            )\n",
    "            psann_input_dim = channels\n",
    "        elif spine_type == \"flatten\":\n",
    "            self.spine = FlattenSpine()\n",
    "            psann_input_dim = time_steps * channels\n",
    "        else:\n",
    "            self.spine = IdentitySpine()\n",
    "            psann_input_dim = time_steps * channels\n",
    "        self.core = ResidualPSANNNet(\n",
    "            psann_input_dim,\n",
    "            output_dim,\n",
    "            hidden_layers=hidden_layers,\n",
    "            hidden_units=hidden_units,\n",
    "            hidden_width=hidden_units,\n",
    "            activation_type=activation_type,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim == 3:\n",
    "            z = self.spine(x)\n",
    "        else:\n",
    "            z = x\n",
    "        return self.core(z)\n",
    "\n",
    "\n",
    "class TabularPSANNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        *,\n",
    "        hidden_layers: int,\n",
    "        hidden_units: int,\n",
    "        activation_type: str = \"psann\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.core = ResidualPSANNNet(\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            hidden_layers=hidden_layers,\n",
    "            hidden_units=hidden_units,\n",
    "            hidden_width=hidden_units,\n",
    "            activation_type=activation_type,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim > 2:\n",
    "            x = x.reshape(x.size(0), -1)\n",
    "        return self.core(x)\n",
    "\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_layers: int = 3, hidden_units: int = 256, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        in_dim = input_dim\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(in_dim, hidden_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_dim = hidden_units\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim > 2:\n",
    "            x = x.reshape(x.size(0), -1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class LSTMHead(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_units: int, num_layers: int, output_dim: int, bidirectional: bool = False, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_units,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "        out_dim = hidden_units * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(out_dim),\n",
    "            nn.Linear(out_dim, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        z = h_n[-1]\n",
    "        return self.head(z)\n",
    "\n",
    "\n",
    "class TinyTCNBlock(nn.Module):\n",
    "    def __init__(self, channels: int, kernel_size: int, dilation: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(channels, channels, kernel_size, padding=\"same\", dilation=dilation),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(channels, channels, kernel_size, padding=\"same\", dilation=dilation),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + self.conv(x)\n",
    "\n",
    "\n",
    "class TinyTCN(nn.Module):\n",
    "    def __init__(self, input_channels: int, output_dim: int, hidden_channels: int = 128, layers: int = 3, kernel_size: int = 3, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.pre = nn.Conv1d(input_channels, hidden_channels, kernel_size=1)\n",
    "        blocks = []\n",
    "        for i in range(layers):\n",
    "            blocks.append(TinyTCNBlock(hidden_channels, kernel_size, dilation=2 ** i, dropout=dropout))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_channels, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = x.transpose(1, 2)\n",
    "        z = self.pre(z)\n",
    "        z = self.blocks(z)\n",
    "        z = self.head(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "def build_psann_tabular(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    hidden_layers = extra.get(\"hidden_layers\", 8)\n",
    "    hidden_units = extra.get(\"hidden_units\", 256)\n",
    "    activation_type = extra.get(\"activation_type\", \"psann\")\n",
    "    return TabularPSANNModel(\n",
    "        input_dim=int(np.prod(input_shape)),\n",
    "        output_dim=output_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        hidden_units=hidden_units,\n",
    "        activation_type=activation_type,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_psann_sequence(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    hidden_layers = extra.get(\"hidden_layers\", 8)\n",
    "    hidden_units = extra.get(\"hidden_units\", 256)\n",
    "    spine_type = extra.get(\"spine_type\", \"flatten\")\n",
    "    spine_params = extra.get(\"spine_params\", {})\n",
    "    activation_type = extra.get(\"activation_type\", \"psann\")\n",
    "    return SequencePSANNModel(\n",
    "        input_shape,\n",
    "        output_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        hidden_units=hidden_units,\n",
    "        spine_type=spine_type,\n",
    "        spine_params=spine_params,\n",
    "        activation_type=activation_type,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_mlp_model(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    hidden_layers = extra.get(\"hidden_layers\", 3)\n",
    "    hidden_units = extra.get(\"hidden_units\", 256)\n",
    "    dropout = extra.get(\"dropout\", 0.1)\n",
    "    return MLPModel(\n",
    "        input_dim=int(np.prod(input_shape)),\n",
    "        output_dim=output_dim,\n",
    "        hidden_layers=hidden_layers,\n",
    "        hidden_units=hidden_units,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_lstm_model(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    sequence_length, channels = input_shape\n",
    "    hidden_units = extra.get(\"hidden_units\", 128)\n",
    "    num_layers = extra.get(\"num_layers\", 1)\n",
    "    bidirectional = extra.get(\"bidirectional\", False)\n",
    "    return LSTMHead(\n",
    "        input_dim=channels,\n",
    "        hidden_units=hidden_units,\n",
    "        num_layers=num_layers,\n",
    "        output_dim=output_dim,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout=extra.get(\"dropout\", 0.1),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_tcn_model(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    sequence_length, channels = input_shape\n",
    "    hidden_channels = extra.get(\"hidden_channels\", 128)\n",
    "    layers = extra.get(\"layers\", 3)\n",
    "    kernel_size = extra.get(\"kernel_size\", 3)\n",
    "    dropout = extra.get(\"dropout\", 0.1)\n",
    "    return TinyTCN(\n",
    "        input_channels=channels,\n",
    "        output_dim=output_dim,\n",
    "        hidden_channels=hidden_channels,\n",
    "        layers=layers,\n",
    "        kernel_size=kernel_size,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "\n",
    "class WaveResNetSequenceModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, ...],\n",
    "        output_dim: int,\n",
    "        *,\n",
    "        aggregator: str = \"conv\",\n",
    "        aggregator_params: Optional[Dict[str, Any]] = None,\n",
    "        wave_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        aggregator_params = aggregator_params or {}\n",
    "        wave_kwargs = wave_kwargs or {}\n",
    "        time_steps, channels = input_shape\n",
    "        if aggregator == \"conv\":\n",
    "            hidden_channels = aggregator_params.get(\"channels\", wave_kwargs.get(\"hidden_dim\", 128))\n",
    "            activation = aggregator_params.get(\"activation\", nn.GELU)\n",
    "            self.spine = TemporalConvSpine(\n",
    "                channels,\n",
    "                hidden_channels,\n",
    "                kernel_size=aggregator_params.get(\"kernel_size\", 5),\n",
    "                stride=aggregator_params.get(\"stride\", 2),\n",
    "                depth=aggregator_params.get(\"depth\", 2),\n",
    "                activation=activation,\n",
    "            )\n",
    "            wave_input_dim = hidden_channels\n",
    "        elif aggregator == \"flatten\":\n",
    "            self.spine = FlattenSpine()\n",
    "            wave_input_dim = time_steps * channels\n",
    "        elif aggregator == \"identity\":\n",
    "            self.spine = IdentitySpine()\n",
    "            wave_input_dim = time_steps * channels\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported aggregator '{aggregator}' for WaveResNetSequenceModel.\")\n",
    "        final_wave_kwargs = wave_kwargs.copy()\n",
    "        final_wave_kwargs[\"input_dim\"] = wave_input_dim\n",
    "        final_wave_kwargs[\"output_dim\"] = output_dim\n",
    "        self.core = WaveResNet(**final_wave_kwargs)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = self.spine(x) if x.ndim == 3 else x\n",
    "        if z.ndim > 2:\n",
    "            z = z.view(z.size(0), -1)\n",
    "        return self.core(z)\n",
    "\n",
    "\n",
    "def _count_params(module: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "\n",
    "def build_wave_resnet_tabular(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    hidden_dims = extra.get(\"hidden_dims\", [192, 224, 256])\n",
    "    depths = extra.get(\"depths\", [4, 6, 8])\n",
    "    target_params = extra.get(\"target_params\")\n",
    "    tol = extra.get(\"param_tol\", 0.15)\n",
    "    dropout = extra.get(\"dropout\", 0.05)\n",
    "    first_layer_w0 = extra.get(\"first_layer_w0\", 30.0)\n",
    "    hidden_w0 = extra.get(\"hidden_w0\", 1.0)\n",
    "    input_dim = int(np.prod(input_shape))\n",
    "    best_model = None\n",
    "    best_gap = float(\"inf\")\n",
    "    for hidden_dim in hidden_dims:\n",
    "        for depth in depths:\n",
    "            wave_kwargs = {\n",
    "                \"input_dim\": input_dim,\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"depth\": depth,\n",
    "                \"output_dim\": output_dim,\n",
    "                \"dropout\": dropout,\n",
    "                \"first_layer_w0\": first_layer_w0,\n",
    "                \"hidden_w0\": hidden_w0,\n",
    "            }\n",
    "            candidate = WaveResNet(**wave_kwargs)\n",
    "            params = _count_params(candidate)\n",
    "            if target_params:\n",
    "                gap = abs(params - target_params)\n",
    "                if target_params > 0 and gap / target_params <= tol:\n",
    "                    return candidate\n",
    "                if gap < best_gap:\n",
    "                    best_model = candidate\n",
    "                    best_gap = gap\n",
    "            elif best_model is None:\n",
    "                best_model = candidate\n",
    "    if best_model is None:\n",
    "        raise RuntimeError(\"Unable to construct WaveResNet tabular model with the provided search space.\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def build_wave_resnet_sequence(input_shape: Tuple[int, ...], output_dim: int, extra: Dict[str, Any]) -> nn.Module:\n",
    "    hidden_dims = extra.get(\"hidden_dims\", [160, 192, 224])\n",
    "    depths = extra.get(\"depths\", [4, 6, 8])\n",
    "    target_params = extra.get(\"target_params\")\n",
    "    tol = extra.get(\"param_tol\", 0.15)\n",
    "    aggregator = extra.get(\"aggregator\", \"conv\")\n",
    "    aggregator_params = extra.get(\"aggregator_params\", {})\n",
    "    dropout = extra.get(\"dropout\", 0.05)\n",
    "    first_layer_w0 = extra.get(\"first_layer_w0\", 30.0)\n",
    "    hidden_w0 = extra.get(\"hidden_w0\", 1.0)\n",
    "    best_model = None\n",
    "    best_gap = float(\"inf\")\n",
    "    for hidden_dim in hidden_dims:\n",
    "        for depth in depths:\n",
    "            wave_kwargs = {\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"depth\": depth,\n",
    "                \"dropout\": dropout,\n",
    "                \"first_layer_w0\": first_layer_w0,\n",
    "                \"hidden_w0\": hidden_w0,\n",
    "            }\n",
    "            agg_params = dict(aggregator_params)\n",
    "            if aggregator == \"conv\":\n",
    "                agg_params.setdefault(\"channels\", hidden_dim)\n",
    "            candidate = WaveResNetSequenceModel(\n",
    "                input_shape,\n",
    "                output_dim,\n",
    "                aggregator=aggregator,\n",
    "                aggregator_params=agg_params,\n",
    "                wave_kwargs=wave_kwargs,\n",
    "            )\n",
    "            params = _count_params(candidate)\n",
    "            if target_params:\n",
    "                gap = abs(params - target_params)\n",
    "                if target_params > 0 and gap / target_params <= tol:\n",
    "                    return candidate\n",
    "                if gap < best_gap:\n",
    "                    best_model = candidate\n",
    "                    best_gap = gap\n",
    "            elif best_model is None:\n",
    "                best_model = candidate\n",
    "    if best_model is None:\n",
    "        raise RuntimeError(\"Unable to construct WaveResNet sequence model with the provided search space.\")\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3f91c9b",
   "metadata": {
    "id": "b3f91c9b"
   },
   "outputs": [],
   "source": [
    "def count_trainable_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def denormalize_regression_outputs(\n",
    "    bundle: DatasetBundle, y_true: np.ndarray, y_pred: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    scaler = bundle.metadata.get(\"target_scaler\") if getattr(bundle, \"metadata\", None) else None\n",
    "    if not scaler:\n",
    "        return y_true, y_pred\n",
    "    mean = np.asarray(scaler.get(\"mean\", 0.0), dtype=np.float32)\n",
    "    std = np.asarray(scaler.get(\"std\", 1.0), dtype=np.float32)\n",
    "    return y_true * std + mean, y_pred * std + mean\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, loader: DataLoader, spec: ModelSpec) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    model.eval()\n",
    "    param = next(model.parameters(), None)\n",
    "    model_device = param.device if param is not None else torch.device(\"cpu\")\n",
    "\n",
    "    preds: List[np.ndarray] = []\n",
    "    truths: List[np.ndarray] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(model_device)\n",
    "            y_batch = y_batch.to(model_device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            if spec.task_type != \"classification\":\n",
    "                if outputs.ndim > 2:\n",
    "                    outputs = outputs.view(outputs.size(0), -1)\n",
    "                if y_batch.ndim > 2:\n",
    "                    y_batch = y_batch.view(y_batch.size(0), -1)\n",
    "                elif y_batch.ndim == 1:\n",
    "                    y_batch = y_batch.unsqueeze(-1)\n",
    "\n",
    "            preds.append(outputs.detach().cpu().numpy())\n",
    "            truths.append(y_batch.detach().cpu().numpy())\n",
    "\n",
    "    if not preds:\n",
    "        raise ValueError(\"Evaluation loader produced no batches; check dataset splits and batch size.\")\n",
    "\n",
    "    y_pred = np.concatenate(preds, axis=0)\n",
    "    y_true = np.concatenate(truths, axis=0)\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "def train_model_on_bundle(bundle: DatasetBundle, spec: ModelSpec, task_name: str) -> Dict[str, Any]:\n",
    "    input_shape = bundle.train[\"X\"].shape[1:]\n",
    "    if spec.task_type == \"classification\":\n",
    "        output_dim = int(bundle.metadata.get(\"n_classes\", np.unique(bundle.train[\"y\"]).size))\n",
    "    else:\n",
    "        output_dim = bundle.train[\"y\"].shape[1] if bundle.train[\"y\"].ndim > 1 else 1\n",
    "\n",
    "    model = spec.builder(input_shape, output_dim, spec.extra)\n",
    "    model.to(DEVICE)\n",
    "    params = count_trainable_parameters(model)\n",
    "\n",
    "    optimizer_cls = torch.optim.AdamW if spec.train_config.weight_decay > 0 else torch.optim.Adam\n",
    "    optimizer = optimizer_cls(\n",
    "        model.parameters(),\n",
    "        lr=spec.train_config.learning_rate,\n",
    "        weight_decay=spec.train_config.weight_decay,\n",
    "    )\n",
    "    scheduler = None\n",
    "    if spec.train_config.scheduler == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=spec.train_config.epochs)\n",
    "\n",
    "    train_loader = build_dataloader(\n",
    "        bundle.train[\"X\"],\n",
    "        bundle.train[\"y\"],\n",
    "        spec.train_config.batch_size,\n",
    "        shuffle=True,\n",
    "        task_type=spec.task_type,\n",
    "    )\n",
    "    val_loader = build_dataloader(\n",
    "        bundle.val[\"X\"],\n",
    "        bundle.val[\"y\"],\n",
    "        spec.train_config.batch_size,\n",
    "        shuffle=False,\n",
    "        task_type=spec.task_type,\n",
    "    )\n",
    "    test_loader = build_dataloader(\n",
    "        bundle.test[\"X\"],\n",
    "        bundle.test[\"y\"],\n",
    "        spec.train_config.batch_size,\n",
    "        shuffle=False,\n",
    "        task_type=spec.task_type,\n",
    "    )\n",
    "\n",
    "    best_state = None\n",
    "    best_val_metric = -float(\"inf\")\n",
    "    patience_counter = spec.train_config.patience\n",
    "    history: List[Dict[str, float]] = []\n",
    "    criterion_reg = nn.MSELoss()\n",
    "\n",
    "    with Timer() as timer:\n",
    "        for epoch in range(spec.train_config.epochs):\n",
    "            model.train()\n",
    "            model_device = next(model.parameters(), DEVICE).device\n",
    "            running_loss = 0.0\n",
    "            batches = 0\n",
    "\n",
    "            for step, (X_batch, y_batch) in enumerate(train_loader, start=1):\n",
    "                X_batch = X_batch.to(model_device)\n",
    "                y_batch = y_batch.to(model_device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(X_batch)\n",
    "                if spec.task_type != \"classification\" and outputs.ndim > 2:\n",
    "                    outputs = outputs.view(outputs.size(0), -1)\n",
    "\n",
    "                if spec.task_type == \"classification\":\n",
    "                    loss = nn.functional.cross_entropy(\n",
    "                        outputs,\n",
    "                        y_batch,\n",
    "                        label_smoothing=GLOBAL_CONFIG[\"label_smoothing\"],\n",
    "                    )\n",
    "                else:\n",
    "                    target = y_batch\n",
    "                    if target.ndim > 2:\n",
    "                        target = target.view(target.size(0), -1)\n",
    "                    elif target.ndim == 1:\n",
    "                        target = target.unsqueeze(-1)\n",
    "                    loss = criterion_reg(outputs, target)\n",
    "\n",
    "                loss.backward()\n",
    "                if spec.train_config.gradient_clip is not None:\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), spec.train_config.gradient_clip)\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                batches += 1\n",
    "                if spec.train_config.max_batches_per_epoch and batches >= spec.train_config.max_batches_per_epoch:\n",
    "                    break\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            avg_loss = running_loss / max(1, batches)\n",
    "            val_true, val_pred = evaluate_model(model, val_loader, spec)\n",
    "\n",
    "            if spec.task_type == \"classification\":\n",
    "                metrics = classification_metrics(val_true, val_pred)\n",
    "                score = metrics[\"accuracy\"]\n",
    "            else:\n",
    "                val_true_den, val_pred_den = denormalize_regression_outputs(bundle, val_true, val_pred)\n",
    "                metrics = regression_metrics(val_true_den, val_pred_den)\n",
    "                score = -metrics[\"rmse\"]\n",
    "\n",
    "            history.append({\"epoch\": epoch + 1, \"train_loss\": avg_loss, \"val_score\": score})\n",
    "\n",
    "            if score > best_val_metric:\n",
    "                best_val_metric = score\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_counter = spec.train_config.patience\n",
    "            else:\n",
    "                patience_counter -= 1\n",
    "\n",
    "            if spec.train_config.early_stopping and patience_counter <= 0:\n",
    "                break\n",
    "            if spec.train_config.max_minutes is not None and timer.elapsed / 60.0 > spec.train_config.max_minutes:\n",
    "                print(f\"[INFO] Time budget reached for {spec.name}; stopping at epoch {epoch + 1}.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    train_true, train_pred = evaluate_model(model, train_loader, spec)\n",
    "    val_true, val_pred = evaluate_model(model, val_loader, spec)\n",
    "    test_true, test_pred = evaluate_model(model, test_loader, spec)\n",
    "\n",
    "    if spec.task_type == \"classification\":\n",
    "        train_metrics = classification_metrics(train_true, train_pred)\n",
    "        val_metrics = classification_metrics(val_true, val_pred)\n",
    "        test_metrics = classification_metrics(test_true, test_pred)\n",
    "\n",
    "        train_true_out, train_pred_out = train_true, train_pred\n",
    "        val_true_out, val_pred_out = val_true, val_pred\n",
    "        test_true_out, test_pred_out = test_true, test_pred\n",
    "    else:\n",
    "        train_true_den, train_pred_den = denormalize_regression_outputs(bundle, train_true, train_pred)\n",
    "        val_true_den, val_pred_den = denormalize_regression_outputs(bundle, val_true, val_pred)\n",
    "        test_true_den, test_pred_den = denormalize_regression_outputs(bundle, test_true, test_pred)\n",
    "\n",
    "        train_metrics = regression_metrics(train_true_den, train_pred_den)\n",
    "        val_metrics = regression_metrics(val_true_den, val_pred_den)\n",
    "        test_metrics = regression_metrics(test_true_den, test_pred_den)\n",
    "\n",
    "        train_true_out, train_pred_out = train_true_den, train_pred_den\n",
    "        val_true_out, val_pred_out = val_true_den, val_pred_den\n",
    "        test_true_out, test_pred_out = test_true_den, test_pred_den\n",
    "\n",
    "    RESULT_LOGGER.append(\n",
    "        ExperimentResult(\n",
    "            dataset=bundle.name,\n",
    "            task=task_name,\n",
    "            model=spec.name,\n",
    "            group=spec.group,\n",
    "            split=\"train\",\n",
    "            params=params,\n",
    "            train_wall_seconds=timer.elapsed,\n",
    "            metrics=train_metrics,\n",
    "            notes=spec.notes,\n",
    "        )\n",
    "    )\n",
    "    RESULT_LOGGER.append(\n",
    "        ExperimentResult(\n",
    "            dataset=bundle.name,\n",
    "            task=task_name,\n",
    "            model=spec.name,\n",
    "            group=spec.group,\n",
    "            split=\"val\",\n",
    "            params=params,\n",
    "            train_wall_seconds=timer.elapsed,\n",
    "            metrics=val_metrics,\n",
    "            notes=spec.notes,\n",
    "        )\n",
    "    )\n",
    "    RESULT_LOGGER.append(\n",
    "        ExperimentResult(\n",
    "            dataset=bundle.name,\n",
    "            task=task_name,\n",
    "            model=spec.name,\n",
    "            group=spec.group,\n",
    "            split=\"test\",\n",
    "            params=params,\n",
    "            train_wall_seconds=timer.elapsed,\n",
    "            metrics=test_metrics,\n",
    "            notes=spec.notes,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model_cpu = model.to(\"cpu\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_cpu,\n",
    "        \"train_metrics\": train_metrics,\n",
    "        \"val_metrics\": val_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"train_true\": train_true_out,\n",
    "        \"train_pred\": train_pred_out,\n",
    "        \"val_true\": val_true_out,\n",
    "        \"val_pred\": val_pred_out,\n",
    "        \"test_true\": test_true_out,\n",
    "        \"test_pred\": test_pred_out,\n",
    "        \"history\": history,\n",
    "        \"params\": params,\n",
    "        \"train_time\": timer.elapsed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95235c68",
   "metadata": {
    "id": "95235c68"
   },
   "outputs": [],
   "source": [
    "def permutation_importance(\n",
    "    model: nn.Module,\n",
    "    bundle: DatasetBundle,\n",
    "    spec: ModelSpec,\n",
    "    feature_groups: Dict[str, List[int]],\n",
    "    split: str = \"test\",\n",
    "    n_repeats: int = 5,\n",
    ") -> pd.DataFrame:\n",
    "    data = getattr(bundle, split)\n",
    "    baseline_loader = build_dataloader(\n",
    "        data[\"X\"],\n",
    "        data[\"y\"],\n",
    "        spec.train_config.batch_size,\n",
    "        shuffle=False,\n",
    "        task_type=spec.task_type,\n",
    "    )\n",
    "    y_true, y_pred = evaluate_model(model, baseline_loader, spec)\n",
    "    if spec.task_type == \"classification\":\n",
    "        baseline_metric = classification_metrics(y_true, y_pred)[\"accuracy\"]\n",
    "    else:\n",
    "        baseline_metric = regression_metrics(y_true.squeeze(), y_pred.squeeze())[\"rmse\"]\n",
    "\n",
    "    rows = []\n",
    "    for group_name, columns in feature_groups.items():\n",
    "        deltas = []\n",
    "        cols = np.atleast_1d(columns)\n",
    "        for _ in range(n_repeats):\n",
    "            X_perm = data[\"X\"].copy()\n",
    "            if bundle.input_kind == \"tabular\":\n",
    "                for col in cols:\n",
    "                    np.random.shuffle(X_perm[:, col])\n",
    "            else:\n",
    "                for col in cols:\n",
    "                    np.random.shuffle(X_perm[:, :, col])\n",
    "            loader = build_dataloader(\n",
    "                X_perm,\n",
    "                data[\"y\"],\n",
    "                spec.train_config.batch_size,\n",
    "                shuffle=False,\n",
    "                task_type=spec.task_type,\n",
    "            )\n",
    "            y_true_perm, y_pred_perm = evaluate_model(model, loader, spec)\n",
    "            if spec.task_type == \"classification\":\n",
    "                metric_value = classification_metrics(y_true_perm, y_pred_perm)[\"accuracy\"]\n",
    "                delta = baseline_metric - metric_value\n",
    "            else:\n",
    "                metric_value = regression_metrics(y_true_perm.squeeze(), y_pred_perm.squeeze())[\"rmse\"]\n",
    "                delta = metric_value - baseline_metric\n",
    "            deltas.append(delta)\n",
    "        rows.append(\n",
    "            {\n",
    "                \"group\": group_name,\n",
    "                \"mean_delta\": float(np.mean(deltas)),\n",
    "                \"std_delta\": float(np.std(deltas)),\n",
    "                \"baseline\": baseline_metric,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def compute_shap_importance(\n",
    "    model: nn.Module,\n",
    "    bundle: DatasetBundle,\n",
    "    spec: ModelSpec,\n",
    "    split: str = \"val\",\n",
    "    sample_size: int = 512,\n",
    ") -> Dict[str, Any]:\n",
    "    import shap\n",
    "\n",
    "    data = getattr(bundle, split)\n",
    "    X = data[\"X\"]\n",
    "    if len(X) == 0:\n",
    "        raise ValueError(f\"No samples available in {split} split for SHAP computation.\")\n",
    "    sample_size = min(sample_size, len(X))\n",
    "    idx = np.random.choice(len(X), size=sample_size, replace=False)\n",
    "    X_sample = X[idx]\n",
    "\n",
    "    model_cpu = model.to(\"cpu\").eval()\n",
    "\n",
    "    def predict_fn(batch: np.ndarray) -> np.ndarray:\n",
    "        with torch.no_grad():\n",
    "            inputs = torch.from_numpy(batch).float()\n",
    "            outputs = model_cpu(inputs)\n",
    "            if spec.task_type == \"classification\":\n",
    "                return torch.softmax(outputs, dim=-1).numpy()\n",
    "            return outputs.numpy()\n",
    "\n",
    "    if bundle.input_kind == \"tabular\":\n",
    "        background = X_sample[: min(128, sample_size)]\n",
    "        explainer = shap.KernelExplainer(predict_fn, background)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "    else:\n",
    "        background = torch.from_numpy(X_sample[: min(64, sample_size)]).float()\n",
    "        explainer = shap.DeepExplainer(model_cpu, background)\n",
    "        shap_values = explainer.shap_values(torch.from_numpy(X_sample).float())\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    return {\"explainer\": explainer, \"shap_values\": shap_values, \"sample_indices\": idx}\n",
    "\n",
    "\n",
    "def compute_jacobian_singular_values(model: nn.Module, inputs: torch.Tensor, max_samples: int = 128) -> np.ndarray:\n",
    "    model.eval()\n",
    "    inputs = inputs[:max_samples].to(DEVICE).requires_grad_(True)\n",
    "    outputs = model(inputs)\n",
    "    if outputs.ndim == 1:\n",
    "        outputs = outputs.unsqueeze(-1)\n",
    "    jacobian_rows = []\n",
    "    for i in range(outputs.shape[1]):\n",
    "        grad_outputs = torch.zeros_like(outputs)\n",
    "        grad_outputs[:, i] = 1.0\n",
    "        grads = torch.autograd.grad(outputs, inputs, grad_outputs=grad_outputs, retain_graph=True, create_graph=False)[0]\n",
    "        jacobian_rows.append(grads.reshape(grads.size(0), -1).detach().cpu().numpy())\n",
    "    jacobian = np.concatenate(jacobian_rows, axis=1)\n",
    "    sigma = np.linalg.svd(jacobian, compute_uv=False)\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def participation_ratio(singular_values: np.ndarray) -> float:\n",
    "    if singular_values.size == 0:\n",
    "        return float(\"nan\")\n",
    "    numerator = (singular_values ** 2).sum() ** 2\n",
    "    denominator = (singular_values ** 4).sum() + 1e-8\n",
    "    return float(numerator / denominator)\n",
    "\n",
    "\n",
    "def frequency_response_probe(model: nn.Module, input_dim: int, frequencies: Iterable[float], amplitude: float = 1.0) -> pd.DataFrame:\n",
    "    model.eval()\n",
    "    rows = []\n",
    "    times = torch.linspace(0, 2 * math.pi, steps=512).unsqueeze(0)\n",
    "    for freq in frequencies:\n",
    "        signal = amplitude * torch.sin(freq * times)\n",
    "        if input_dim > 1:\n",
    "            signal = signal.repeat(1, input_dim)\n",
    "        signal = signal.to(DEVICE).float()\n",
    "        with torch.no_grad():\n",
    "            output = model(signal)\n",
    "        energy = output.pow(2).mean().sqrt().item()\n",
    "        rows.append({\"frequency\": freq, \"output_rms\": energy})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def evaluate_robustness(\n",
    "    model: nn.Module,\n",
    "    bundle: DatasetBundle,\n",
    "    spec: ModelSpec,\n",
    "    corruption_fn: Callable[[np.ndarray, float], np.ndarray],\n",
    "    split: str = \"test\",\n",
    "    levels: Iterable[float] = (0.0, 0.1, 0.2, 0.3),\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    base_data = getattr(bundle, split)\n",
    "    for level in levels:\n",
    "        X_corrupted = corruption_fn(base_data[\"X\"], level)\n",
    "        loader = build_dataloader(\n",
    "            X_corrupted,\n",
    "            base_data[\"y\"],\n",
    "            spec.train_config.batch_size,\n",
    "            shuffle=False,\n",
    "            task_type=spec.task_type,\n",
    "        )\n",
    "        y_true, y_pred = evaluate_model(model, loader, spec)\n",
    "        if spec.task_type == \"classification\":\n",
    "            metrics = classification_metrics(y_true, y_pred)\n",
    "        else:\n",
    "            metrics = regression_metrics(y_true.squeeze(), y_pred.squeeze())\n",
    "        row = {\"level\": level}\n",
    "        row.update(metrics)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f64a25c2",
   "metadata": {
    "id": "f64a25c2"
   },
   "outputs": [],
   "source": [
    "# Cell (1) â€” helpers + containers\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Where your datasets live (should already be defined in the notebook; override only if missing)\n",
    "try:\n",
    "    DATA_ROOT\n",
    "except NameError:\n",
    "    DATA_ROOT = Path(\"/content/datasets\")\n",
    "\n",
    "# container for results\n",
    "DATA_BUNDLES: Dict[str, \"DatasetBundle\"] = {}\n",
    "\n",
    "def find_key(stations: dict, short_name: str) -> str:\n",
    "    \"\"\"Find the canonical station key by case-insensitive substring match.\n",
    "    Raises KeyError if no match found.\n",
    "    \"\"\"\n",
    "    short = short_name.lower()\n",
    "    matches = [k for k in stations.keys() if short in k.lower()]\n",
    "    if not matches:\n",
    "        raise KeyError(f\"No station matching '{short_name}'\")\n",
    "    # prefer exact prefix match if available (more deterministic)\n",
    "    for m in matches:\n",
    "        if m.lower().startswith(short):\n",
    "            return m\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aefaphdaPGoq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aefaphdaPGoq",
    "outputId": "79b996cb-bef1-407f-b6f4-93aace68e729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loading eaf_temp from /content/datasets/Industrial Data from the Electric Arc Furnace/eaf_temp.csv...\n",
      "Loading eaf_gaslance_mat from /content/datasets/Industrial Data from the Electric Arc Furnace/eaf_gaslance_mat.csv...\n",
      "Loading inj_mat from /content/datasets/Industrial Data from the Electric Arc Furnace/inj_mat.csv...\n",
      "Loading eaf_transformer from /content/datasets/Industrial Data from the Electric Arc Furnace/eaf_transformer.csv...\n",
      "Loading eaf_added_materials from /content/datasets/Industrial Data from the Electric Arc Furnace/eaf_added_materials.csv...\n",
      "Loading basket_charged from /content/datasets/Industrial Data from the Electric Arc Furnace/basket_charged.csv...\n",
      "Loading lf_added_materials from /content/datasets/Industrial Data from the Electric Arc Furnace/lf_added_materials.csv...\n",
      "Loading lf_initial_chemical_measurements from /content/datasets/Industrial Data from the Electric Arc Furnace/lf_initial_chemical_measurements.csv...\n",
      "Loading eaf_final_chemical_measurements from /content/datasets/Industrial Data from the Electric Arc Furnace/eaf_final_chemical_measurements.csv...\n",
      "Loading ladle_tapping from /content/datasets/Industrial Data from the Electric Arc Furnace/ladle_tapping.csv...\n",
      " - EAF bundles ready\n",
      "Loading Beijing station Changping_20130301-20170228...\n",
      "Loading Beijing station Aotizhongxin_20130301-20170228...\n",
      "Loading Beijing station Huairou_20130301-20170228...\n",
      "Loading Beijing station Gucheng_20130301-20170228...\n",
      "Loading Beijing station Wanliu_20130301-20170228...\n",
      "Loading Beijing station Shunyi_20130301-20170228...\n",
      "Loading Beijing station Tiantan_20130301-20170228...\n",
      "Loading Beijing station Dingling_20130301-20170228...\n",
      "Loading Beijing station Dongsi_20130301-20170228...\n",
      "Loading Beijing station Wanshouxigong_20130301-20170228...\n",
      "Loading Beijing station Nongzhanguan_20130301-20170228...\n",
      "Loading Beijing station Guanyuan_20130301-20170228...\n",
      " - Beijing: val=Wanshouxigong_20130301-20170228, test=Huairou_20130301-20170228, train_count=10\n",
      " - Beijing bundle ready\n",
      " - Jena bundle ready\n",
      " - HAR engineered bundle ready\n",
      " - HAR raw bundle ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3127595546.py:6: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(train_path, parse_dates=[\"Date\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Rossmann bundle ready\n",
      "\n",
      "Available dataset bundles:\n",
      " - EAF_TEMP_forecast: {'name': 'EAF_TEMP_forecast', 'task_type': 'regression', 'input_kind': 'tabular', 'n_train': 1984, 'n_val': 429, 'n_test': 89, 'input_shape': (34,), 'target_shape': (1,), 'meta_horizon_steps': 1, 'meta_feature_source': 'temp + gas + injection + calendar'}\n",
      " - EAF_VALO2_forecast: {'name': 'EAF_VALO2_forecast', 'task_type': 'regression', 'input_kind': 'tabular', 'n_train': 1984, 'n_val': 429, 'n_test': 89, 'input_shape': (34,), 'target_shape': (1,), 'meta_horizon_steps': 1, 'meta_feature_source': 'temp + gas + injection + calendar'}\n",
      " - EAF_chemistry: {'name': 'EAF_chemistry', 'task_type': 'regression', 'input_kind': 'tabular', 'n_train': 1189, 'n_val': 290, 'n_test': 932, 'input_shape': (33,), 'target_shape': (12,), 'meta_target_dim': 12, 'meta_note': 'heat-level aggregates for final composition'}\n",
      " - Beijing_PM25_24h_ctx_6h_horizon: {'name': 'Beijing_PM25_24h_ctx_6h_horizon', 'task_type': 'regression', 'input_kind': 'sequence', 'n_train': 350340, 'n_val': 35034, 'n_test': 35034, 'input_shape': (24, 30), 'target_shape': (2,), 'meta_context_hours': 24, 'meta_horizon_hours': 6, 'meta_val_station': 'Wanshouxigong_20130301-20170228', 'meta_test_station': 'Huairou_20130301-20170228'}\n",
      " - Jena_tdegc_72ctx_36h: {'name': 'Jena_tdegc_72ctx_36h', 'task_type': 'regression', 'input_kind': 'sequence', 'n_train': 315659, 'n_val': 52560, 'n_test': 52224, 'input_shape': (72, 24), 'target_shape': (1,), 'meta_context_steps': 72, 'meta_horizon_steps': 36, 'meta_resample_factor': 1}\n",
      " - HAR_engineered: {'name': 'HAR_engineered', 'task_type': 'classification', 'input_kind': 'tabular', 'n_train': 6249, 'n_val': 1103, 'n_test': 2947, 'input_shape': (813,), 'target_shape': (1,), 'meta_n_classes': 6}\n",
      " - HAR_raw_sequence: {'name': 'HAR_raw_sequence', 'task_type': 'classification', 'input_kind': 'sequence', 'n_train': 6249, 'n_val': 1103, 'n_test': 2947, 'input_shape': (128, 9), 'target_shape': (1,), 'meta_sequence_length': 128, 'meta_n_channels': 9, 'meta_n_classes': 6}\n",
      " - Rossmann_sales: {'name': 'Rossmann_sales', 'task_type': 'regression', 'input_kind': 'tabular', 'n_train': 663738, 'n_val': 87212, 'n_test': 85637, 'input_shape': (33,), 'target_shape': (1,)}\n"
     ]
    }
   ],
   "source": [
    "# Cell (2) â€” load all bundles (robust to small naming mismatches)\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# --- EAF bundles (these will use the merge_asof you've patched earlier) ---\n",
    "try:\n",
    "    eaf_tables = load_eaf_tables(DATA_ROOT)\n",
    "    eaf_temp_bundle, eaf_o2_bundle = prepare_eaf_temp_and_o2_bundles(eaf_tables)\n",
    "    eaf_chem_bundle = prepare_eaf_chemistry_bundle(eaf_tables)\n",
    "    DATA_BUNDLES[eaf_temp_bundle.name] = eaf_temp_bundle\n",
    "    DATA_BUNDLES[eaf_o2_bundle.name]   = eaf_o2_bundle\n",
    "    DATA_BUNDLES[eaf_chem_bundle.name] = eaf_chem_bundle\n",
    "    print(\" - EAF bundles ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] EAF bundle creation failed:\", repr(e))\n",
    "\n",
    "# --- Beijing cross-station bundle (use robust mapping for station names) ---\n",
    "try:\n",
    "    beijing_stations = load_beijing_stations(DATA_ROOT)\n",
    "    # map the short names you expect to their actual keys\n",
    "    val_key  = find_key(beijing_stations, \"Wanshouxigong\")\n",
    "    test_key = find_key(beijing_stations, \"Huairou\")\n",
    "    train_keys = [k for k in beijing_stations.keys() if k not in {val_key, test_key}]\n",
    "    print(f\" - Beijing: val={val_key}, test={test_key}, train_count={len(train_keys)}\")\n",
    "\n",
    "    beijing_bundle = assemble_beijing_cross_station_bundle(\n",
    "        beijing_stations,\n",
    "        train_stations=train_keys,\n",
    "        val_station=val_key,\n",
    "        test_station=test_key,\n",
    "        target=\"PM2.5\",\n",
    "        context=24,\n",
    "        horizon=6,\n",
    "    )\n",
    "    DATA_BUNDLES[beijing_bundle.name] = beijing_bundle\n",
    "    print(\" - Beijing bundle ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] Beijing bundle creation failed:\", repr(e))\n",
    "\n",
    "# --- Jena ---\n",
    "try:\n",
    "    jena_df = load_jena_climate(DATA_ROOT)\n",
    "    jena_bundle = prepare_jena_bundle(jena_df, target=\"T (degC)\", context_steps=72, horizon_steps=36)\n",
    "    DATA_BUNDLES[jena_bundle.name] = jena_bundle\n",
    "    print(\" - Jena bundle ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] Jena bundle creation failed:\", repr(e))\n",
    "\n",
    "# --- HAR (engineered + raw) ---\n",
    "try:\n",
    "    har_train_df, har_test_df, har_feature_names = load_har_engineered(DATA_ROOT)\n",
    "    har_engineered_bundle = prepare_har_engineered_bundle(har_train_df, har_test_df, har_feature_names)\n",
    "    DATA_BUNDLES[har_engineered_bundle.name] = har_engineered_bundle\n",
    "    print(\" - HAR engineered bundle ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] HAR engineered creation failed:\", repr(e))\n",
    "\n",
    "try:\n",
    "    X_har_train_raw, y_har_train_raw, X_har_test_raw, y_har_test_raw, har_axes = load_har_raw_sequences(DATA_ROOT)\n",
    "    har_raw_bundle = prepare_har_raw_bundle(X_har_train_raw, y_har_train_raw, X_har_test_raw, y_har_test_raw)\n",
    "    DATA_BUNDLES[har_raw_bundle.name] = har_raw_bundle\n",
    "    print(\" - HAR raw bundle ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] HAR raw creation failed:\", repr(e))\n",
    "\n",
    "# --- Rossmann ---\n",
    "try:\n",
    "    ross_train, ross_test, ross_store = load_rossmann_frames(DATA_ROOT)\n",
    "    ross_prepared, ross_features, ross_target = preprocess_rossmann(ross_train, ross_store)\n",
    "    ross_bundle = prepare_rossmann_bundle(ross_prepared, ross_features, ross_target)\n",
    "    DATA_BUNDLES[ross_bundle.name] = ross_bundle\n",
    "    print(\" - Rossmann bundle ready\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] Rossmann bundle creation failed:\", repr(e))\n",
    "\n",
    "# --- Summary of what succeeded ---\n",
    "print(\"\\nAvailable dataset bundles:\")\n",
    "for name, bundle in DATA_BUNDLES.items():\n",
    "    try:\n",
    "        print(f\" - {name}: {bundle.summary()}\")\n",
    "    except Exception:\n",
    "        print(f\" - {name}: (created, but summary() failed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "526ead74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "526ead74",
    "outputId": "b6f0b0a9-8435-4832-8758-9669877b28ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model specs:\n",
      "- EAF_TEMP_forecast: ['ResPSANN_tabular', 'MLP_baseline']\n",
      "- EAF_VALO2_forecast: ['ResPSANN_tabular', 'MLP_baseline']\n",
      "- EAF_chemistry: ['ResPSANN_tabular', 'MLP_baseline']\n",
      "- Beijing_PM25_24h_ctx_6h_horizon: ['ResPSANN_conv_spine', 'ResPSANN_attention_spine', 'LSTM_baseline', 'TCN_baseline']\n",
      "- Jena_tdegc_72ctx_36h: ['ResPSANN_conv_spine', 'ResPSANN_attention_spine', 'LSTM_baseline', 'TCN_baseline']\n",
      "- HAR_engineered: ['ResPSANN_tabular', 'MLP_baseline']\n",
      "- HAR_raw_sequence: ['ResPSANN_conv_spine', 'ResPSANN_attention_spine', 'LSTM_baseline', 'TCN_baseline']\n",
      "- Rossmann_sales: ['ResPSANN_tabular', 'MLP_baseline']\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_REGISTRY: Dict[str, List[ModelSpec]] = {}\n",
    "\n",
    "common_regression_train = TrainConfig(\n",
    "    epochs=60,\n",
    "    batch_size=512,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    patience=10,\n",
    "    max_minutes=GLOBAL_CONFIG[\"max_time_minutes\"],\n",
    "    gradient_clip=1.0,\n",
    ")\n",
    "\n",
    "common_sequence_train = TrainConfig(\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    patience=8,\n",
    "    max_minutes=GLOBAL_CONFIG[\"max_time_minutes\"],\n",
    "    gradient_clip=1.0,\n",
    ")\n",
    "\n",
    "common_classification_train = TrainConfig(\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=5e-5,\n",
    "    patience=8,\n",
    "    max_minutes=GLOBAL_CONFIG[\"max_time_minutes\"],\n",
    "    gradient_clip=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "def register_specs(bundle: DatasetBundle):\n",
    "    specs: List[ModelSpec] = []\n",
    "    if bundle.input_kind == \"tabular\":\n",
    "        train_cfg = common_regression_train if bundle.task_type == \"regression\" else common_classification_train\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"ResPSANN_tabular\",\n",
    "                builder=build_psann_tabular,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"tabular\",\n",
    "                group=\"psann\",\n",
    "                extra={\"hidden_layers\": 8, \"hidden_units\": 256},\n",
    "                notes=\"Residual PSANN core\",\n",
    "            )\n",
    "        )\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"MLP_baseline\",\n",
    "                builder=build_mlp_model,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"tabular\",\n",
    "                group=\"baseline\",\n",
    "                extra={\"hidden_layers\": 4, \"hidden_units\": 256, \"dropout\": 0.1},\n",
    "                notes=\"ReLU MLP with similar parameter budget\",\n",
    "            )\n",
    "        )\n",
    "specs.append(\n",
    "    ModelSpec(\n",
    "        name=\"WaveResNet_tabular\",\n",
    "        builder=build_wave_resnet_tabular,\n",
    "        train_config=train_cfg,\n",
    "        task_type=bundle.task_type,\n",
    "        input_kind=\"tabular\",\n",
    "        group=\"baseline\",\n",
    "        extra={\n",
    "            \"hidden_dims\": [192, 224, 256],\n",
    "            \"depths\": [4, 6, 8],\n",
    "            \"target_params\": 400_000,\n",
    "            \"param_tol\": 0.2,\n",
    "            \"dropout\": 0.05,\n",
    "            \"first_layer_w0\": 30.0,\n",
    "            \"hidden_w0\": 1.0,\n",
    "        },\n",
    "        notes=\"WaveResNet baseline with sine residual blocks\",\n",
    "    )\n",
    ")\n",
    "    else:\n",
    "        train_cfg = common_sequence_train if bundle.task_type == \"regression\" else common_classification_train\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"ResPSANN_conv_spine\",\n",
    "                builder=build_psann_sequence,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"sequence\",\n",
    "                group=\"psann\",\n",
    "                extra={\n",
    "                    \"hidden_layers\": 6,\n",
    "                    \"hidden_units\": 192,\n",
    "                    \"spine_type\": \"conv\",\n",
    "                    \"spine_params\": {\"channels\": 192, \"depth\": 2, \"kernel_size\": 5, \"stride\": 2},\n",
    "                },\n",
    "                notes=\"ResPSANN with strided Conv1d spine\",\n",
    "            )\n",
    "        )\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"ResPSANN_attention_spine\",\n",
    "                builder=build_psann_sequence,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"sequence\",\n",
    "                group=\"psann\",\n",
    "                extra={\n",
    "                    \"hidden_layers\": 6,\n",
    "                    \"hidden_units\": 192,\n",
    "                    \"spine_type\": \"attention\",\n",
    "                    \"spine_params\": {\"num_heads\": 1},\n",
    "                },\n",
    "                notes=\"ResPSANN with single-head attention spine\",\n",
    "            )\n",
    "        )\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"LSTM_baseline\",\n",
    "                builder=build_lstm_model,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"sequence\",\n",
    "                group=\"baseline\",\n",
    "                extra={\"hidden_units\": 192, \"num_layers\": 1, \"dropout\": 0.1},\n",
    "                notes=\"Single-layer LSTM baseline\",\n",
    "            )\n",
    "        )\n",
    "        specs.append(\n",
    "            ModelSpec(\n",
    "                name=\"TCN_baseline\",\n",
    "                builder=build_tcn_model,\n",
    "                train_config=train_cfg,\n",
    "                task_type=bundle.task_type,\n",
    "                input_kind=\"sequence\",\n",
    "                group=\"baseline\",\n",
    "                extra={\"hidden_channels\": 192, \"layers\": 3, \"kernel_size\": 3, \"dropout\": 0.1},\n",
    "                notes=\"Tiny TCN baseline\",\n",
    "            )\n",
    "        )\n",
    "specs.append(\n",
    "    ModelSpec(\n",
    "        name=\"WaveResNet_sequence\",\n",
    "        builder=build_wave_resnet_sequence,\n",
    "        train_config=train_cfg,\n",
    "        task_type=bundle.task_type,\n",
    "        input_kind=\"sequence\",\n",
    "        group=\"baseline\",\n",
    "        extra={\n",
    "            \"hidden_dims\": [160, 192, 224],\n",
    "            \"depths\": [4, 6, 8],\n",
    "            \"aggregator\": \"conv\",\n",
    "            \"aggregator_params\": {\"depth\": 2, \"kernel_size\": 5, \"stride\": 2},\n",
    "            \"target_params\": 350_000,\n",
    "            \"param_tol\": 0.2,\n",
    "            \"dropout\": 0.05,\n",
    "            \"first_layer_w0\": 30.0,\n",
    "            \"hidden_w0\": 1.0,\n",
    "        },\n",
    "        notes=\"WaveResNet baseline with a lightweight temporal spine\",\n",
    "    )\n",
    ")\n",
    "    EXPERIMENT_REGISTRY[bundle.name] = specs\n",
    "\n",
    "\n",
    "for bundle in DATA_BUNDLES.values():\n",
    "    register_specs(bundle)\n",
    "\n",
    "print(\"Registered model specs:\")\n",
    "for dataset_name, specs in EXPERIMENT_REGISTRY.items():\n",
    "    print(f\"- {dataset_name}: {[spec.name for spec in specs]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fae9ab43",
   "metadata": {
    "id": "fae9ab43"
   },
   "outputs": [],
   "source": [
    "RUN_EXPERIMENTS = {\n",
    "    \"EAF_TEMP_forecast\": True,\n",
    "    \"EAF_VALO2_forecast\": True,\n",
    "    \"EAF_chemistry\": True,\n",
    "    \"Beijing_PM25_24h_ctx_6h_horizon\": True,\n",
    "    \"Jena_tdegc_72ctx_36h\": True,\n",
    "    \"HAR_engineered\": True,\n",
    "    \"HAR_raw_sequence\": True,\n",
    "    \"Rossmann_sales\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed27ae56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ed27ae56",
    "outputId": "ee3a4aa6-6b61-4e5a-e1e7-f2d533942564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Dataset: EAF_TEMP_forecast (regression, tabular)\n",
      "  -> Training ResPSANN_tabular\n",
      "    Validation metrics: {'rmse': 20.683494547953096, 'mae': 13.403224704982517, 'smape': 0.008165598887099217, 'r2': 0.23956036913762524, 'mase': 0.9367374542330634}\n",
      "    Test metrics       : {'rmse': 24.962252279244773, 'mae': 15.8895263671875, 'smape': 0.009694324685986012, 'r2': -0.03632192811632873, 'mase': 0.7441608939103983}\n",
      "    Saved predictions to /content/colab_results/EAF_TEMP_forecast_ResPSANN_tabular_predictions.npz\n",
      "  -> Training MLP_baseline\n",
      "    Validation metrics: {'rmse': 19.917977433661637, 'mae': 12.470661012164918, 'smape': 0.007600588039037466, 'r2': 0.29480799162011695, 'mase': 0.8715615462894025}\n",
      "    Test metrics       : {'rmse': 25.901293090117896, 'mae': 15.062251744645366, 'smape': 0.009193397514782058, 'r2': -0.11575808915917318, 'mase': 0.70541679239384}\n",
      "    Saved predictions to /content/colab_results/EAF_TEMP_forecast_MLP_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: EAF_VALO2_forecast (regression, tabular)\n",
      "  -> Training ResPSANN_tabular\n",
      "    Validation metrics: {'rmse': 678.111530723209, 'mae': 410.86045599094916, 'smape': 0.4350837223164569, 'r2': -0.4637856987269626, 'mase': 1.4972946709963306}\n",
      "    Test metrics       : {'rmse': 524.9421469104342, 'mae': 420.5056207206812, 'smape': 0.657230005079091, 'r2': -1.2730722571656896, 'mase': 1.477874300975255}\n",
      "    Saved predictions to /content/colab_results/EAF_VALO2_forecast_ResPSANN_tabular_predictions.npz\n",
      "  -> Training MLP_baseline\n",
      "    Validation metrics: {'rmse': 579.8917790682481, 'mae': 302.90845665564905, 'smape': 0.3597705734281229, 'r2': -0.07045679950988615, 'mase': 1.103886274127626}\n",
      "    Test metrics       : {'rmse': 561.6690676459639, 'mae': 457.0367287625088, 'smape': 0.6739175820541188, 'r2': -1.6022640929719887, 'mase': 1.6062635141054857}\n",
      "    Saved predictions to /content/colab_results/EAF_VALO2_forecast_MLP_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: EAF_chemistry (regression, tabular)\n",
      "  -> Training ResPSANN_tabular\n",
      "    Validation metrics: {'rmse': 0.022501056567335104, 'mae': 0.015098357684682817, 'smape': 0.31051763341482824, 'r2': -0.2616068121908149, 'mase': 1.256232447361234}\n",
      "    Test metrics       : {'rmse': 0.03152734172362775, 'mae': 0.015707053572479243, 'smape': 0.38997826041196965, 'r2': -0.8227013110807723, 'mase': 1.527257171278344}\n",
      "    Saved predictions to /content/colab_results/EAF_chemistry_ResPSANN_tabular_predictions.npz\n",
      "  -> Training MLP_baseline\n",
      "    Validation metrics: {'rmse': 0.022289120392053673, 'mae': 0.01439963365308191, 'smape': 0.27796794723891255, 'r2': -0.11629004077898093, 'mase': 1.1333220705525324}\n",
      "    Test metrics       : {'rmse': 0.031043567308819145, 'mae': 0.014603624546336466, 'smape': 0.31105435791658326, 'r2': -0.39266943660784576, 'mase': 1.2851904145120157}\n",
      "    Saved predictions to /content/colab_results/EAF_chemistry_MLP_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: Beijing_PM25_24h_ctx_6h_horizon (regression, sequence)\n",
      "  -> Training ResPSANN_conv_spine\n",
      "[INFO] Time budget reached for ResPSANN_conv_spine; stopping at epoch 11.\n",
      "    Validation metrics: {'rmse': 47.242326951360056, 'mae': 30.470228588328183, 'smape': 0.4630944650777761, 'r2': 0.6985767517969662, 'mase': 2.6949983594143703}\n",
      "    Test metrics       : {'rmse': 46.054452601194065, 'mae': 29.08973394005703, 'smape': 0.49913399256616786, 'r2': 0.5803918973693383, 'mase': 3.2245387783275636}\n",
      "    Saved predictions to /content/colab_results/Beijing_PM25_24h_ctx_6h_horizon_ResPSANN_conv_spine_predictions.npz\n",
      "  -> Training ResPSANN_attention_spine\n",
      "[INFO] Time budget reached for ResPSANN_attention_spine; stopping at epoch 10.\n",
      "    Validation metrics: {'rmse': 63.25929800931421, 'mae': 42.959044215126, 'smape': 0.6057503338110137, 'r2': 0.4595407930614597, 'mase': 3.7995958365117795}\n",
      "    Test metrics       : {'rmse': 53.28866899542433, 'mae': 36.41841336987156, 'smape': 0.6110309939898508, 'r2': 0.43821474404994243, 'mase': 4.036908223303043}\n",
      "    Saved predictions to /content/colab_results/Beijing_PM25_24h_ctx_6h_horizon_ResPSANN_attention_spine_predictions.npz\n",
      "  -> Training LSTM_baseline\n",
      "[INFO] Time budget reached for LSTM_baseline; stopping at epoch 19.\n",
      "    Validation metrics: {'rmse': 58.365052333436225, 'mae': 38.35049711254751, 'smape': 0.5515009574840495, 'r2': 0.5399342093320708, 'mase': 3.391983965641521}\n",
      "    Test metrics       : {'rmse': 47.46308712963247, 'mae': 31.59719163584401, 'smape': 0.5622945265897057, 'r2': 0.5543308662926927, 'mase': 3.502485444726849}\n",
      "    Saved predictions to /content/colab_results/Beijing_PM25_24h_ctx_6h_horizon_LSTM_baseline_predictions.npz\n",
      "  -> Training TCN_baseline\n",
      "    Validation metrics: {'rmse': 35.9429551031605, 'mae': 23.296510591744344, 'smape': 0.4075875993750975, 'r2': 0.8255215704095122, 'mase': 2.0605049825218686}\n",
      "    Test metrics       : {'rmse': 43.87832783127398, 'mae': 28.723817698004943, 'smape': 0.5128409826618476, 'r2': 0.6191089860876097, 'mase': 3.183977695350724}\n",
      "    Saved predictions to /content/colab_results/Beijing_PM25_24h_ctx_6h_horizon_TCN_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: Jena_tdegc_72ctx_36h (regression, sequence)\n",
      "  -> Training ResPSANN_conv_spine\n",
      "[INFO] Time budget reached for ResPSANN_conv_spine; stopping at epoch 12.\n",
      "    Validation metrics: {'rmse': 2.4373232583700415, 'mae': 1.886096081395401, 'smape': 0.35944113630445096, 'r2': 0.9022805767987234, 'mase': 11.088452324253081}\n",
      "    Test metrics       : {'rmse': 2.2745495509987443, 'mae': 1.7867266208012391, 'smape': 0.3689493360049165, 'r2': 0.923553978173709, 'mase': 11.135801798498838}\n",
      "    Saved predictions to /content/colab_results/Jena_tdegc_72ctx_36h_ResPSANN_conv_spine_predictions.npz\n",
      "  -> Training ResPSANN_attention_spine\n",
      "[INFO] Time budget reached for ResPSANN_attention_spine; stopping at epoch 11.\n",
      "    Validation metrics: {'rmse': 3.1550413488732474, 'mae': 2.405025153706606, 'smape': 0.40832179266251506, 'r2': 0.8362562471064081, 'mase': 14.139262054865837}\n",
      "    Test metrics       : {'rmse': 2.867616772928079, 'mae': 2.19658091966962, 'smape': 0.4055310000737099, 'r2': 0.8784915980237009, 'mase': 13.69022516988975}\n",
      "    Saved predictions to /content/colab_results/Jena_tdegc_72ctx_36h_ResPSANN_attention_spine_predictions.npz\n",
      "  -> Training LSTM_baseline\n",
      "[INFO] Time budget reached for LSTM_baseline; stopping at epoch 7.\n",
      "    Validation metrics: {'rmse': 3.0345853797289526, 'mae': 2.283950090937882, 'smape': 0.39761074142799646, 'r2': 0.8485206784011192, 'mase': 13.427455761215256}\n",
      "    Test metrics       : {'rmse': 2.5522628397450537, 'mae': 1.935643553225115, 'smape': 0.3662919500007251, 'r2': 0.9037468657875373, 'mase': 12.063928924723148}\n",
      "    Saved predictions to /content/colab_results/Jena_tdegc_72ctx_36h_LSTM_baseline_predictions.npz\n",
      "  -> Training TCN_baseline\n",
      "    Validation metrics: {'rmse': 11.071543448123421, 'mae': 2.985945511226758, 'smape': 0.4737817817593049, 'r2': -1.016373432630493, 'mase': 17.55452162307649}\n",
      "    Test metrics       : {'rmse': 3.040843339696817, 'mae': 2.3460737692388576, 'smape': 0.45717414622445207, 'r2': 0.8633680777999166, 'mase': 14.621941708791098}\n",
      "    Saved predictions to /content/colab_results/Jena_tdegc_72ctx_36h_TCN_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: HAR_engineered (classification, tabular)\n",
      "  -> Training ResPSANN_tabular\n",
      "    Validation metrics: {'accuracy': 0.986400725294651, 'f1_macro': 0.9872814968339371, 'nll': 0.08921076912462576, 'ece': 0.04460010356721502}\n",
      "    Test metrics       : {'accuracy': 0.9372242958941296, 'f1_macro': 0.9366644827565508, 'nll': 0.22579217945086094, 'ece': 0.02788264418926569}\n",
      "    Saved predictions to /content/colab_results/HAR_engineered_ResPSANN_tabular_predictions.npz\n",
      "  -> Training MLP_baseline\n",
      "    Validation metrics: {'accuracy': 0.9836808703535811, 'f1_macro': 0.9846939859768565, 'nll': 0.09026792057441327, 'ece': 0.046015766811500554}\n",
      "    Test metrics       : {'accuracy': 0.9426535459789617, 'f1_macro': 0.9420061581803884, 'nll': 0.19701738167210717, 'ece': 0.03097683208491143}\n",
      "    Saved predictions to /content/colab_results/HAR_engineered_MLP_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: HAR_raw_sequence (classification, sequence)\n",
      "  -> Training ResPSANN_conv_spine\n",
      "    Validation metrics: {'accuracy': 0.9637352674524026, 'f1_macro': 0.9665829145728644, 'nll': 0.13870868593229752, 'ece': 0.0385365160562078}\n",
      "    Test metrics       : {'accuracy': 0.9229725144214456, 'f1_macro': 0.9242847911336529, 'nll': 0.21739700569268502, 'ece': 0.04288411275952963}\n",
      "    Saved predictions to /content/colab_results/HAR_raw_sequence_ResPSANN_conv_spine_predictions.npz\n",
      "  -> Training ResPSANN_attention_spine\n",
      "    Validation metrics: {'accuracy': 0.9737080689029919, 'f1_macro': 0.9737043544910727, 'nll': 0.11394827108814645, 'ece': 0.04178398431482258}\n",
      "    Test metrics       : {'accuracy': 0.7757041058703766, 'f1_macro': 0.7723894118070591, 'nll': 0.8034769781871232, 'ece': 0.13179676711539068}\n",
      "    Saved predictions to /content/colab_results/HAR_raw_sequence_ResPSANN_attention_spine_predictions.npz\n",
      "  -> Training LSTM_baseline\n",
      "    Validation metrics: {'accuracy': 0.9592021758839528, 'f1_macro': 0.9618804707222286, 'nll': 0.16399757064953316, 'ece': 0.05075013486234467}\n",
      "    Test metrics       : {'accuracy': 0.9009161859518154, 'f1_macro': 0.9025375065108023, 'nll': 0.33276216622696575, 'ece': 0.020670247980000635}\n",
      "    Saved predictions to /content/colab_results/HAR_raw_sequence_LSTM_baseline_predictions.npz\n",
      "  -> Training TCN_baseline\n",
      "    Validation metrics: {'accuracy': 0.9646418857660924, 'f1_macro': 0.9673892013536106, 'nll': 0.15072972328411952, 'ece': 0.06704734518435039}\n",
      "    Test metrics       : {'accuracy': 0.9233118425517476, 'f1_macro': 0.9256951907229128, 'nll': 0.23398740609978572, 'ece': 0.061461983038119464}\n",
      "    Saved predictions to /content/colab_results/HAR_raw_sequence_TCN_baseline_predictions.npz\n",
      "================================================================================\n",
      "Dataset: Rossmann_sales (regression, tabular)\n",
      "  -> Training ResPSANN_tabular\n",
      "[INFO] Time budget reached for ResPSANN_tabular; stopping at epoch 10.\n",
      "    Validation metrics: {'rmse': 478.44637720302757, 'mae': 337.93176128161923, 'smape': 0.05093985861686564, 'r2': 0.9742563979732718, 'mase': 0.12585753210598372}\n",
      "    Test metrics       : {'rmse': 488.9785735172513, 'mae': 348.9749551123583, 'smape': 0.050791488139079244, 'r2': 0.9748466600599208, 'mase': 0.12555739621201267}\n",
      "    Saved predictions to /content/colab_results/Rossmann_sales_ResPSANN_tabular_predictions.npz\n",
      "  -> Training MLP_baseline\n",
      "    Validation metrics: {'rmse': 559.5486651018768, 'mae': 416.9143799399201, 'smape': 0.06397832971376347, 'r2': 0.9647889885859657, 'mase': 0.15527340419182087}\n",
      "    Test metrics       : {'rmse': 573.8418085779969, 'mae': 417.80086683620345, 'smape': 0.06113288401384641, 'r2': 0.9653582059920035, 'mase': 0.15032021125466102}\n",
      "    Saved predictions to /content/colab_results/Rossmann_sales_MLP_baseline_predictions.npz\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_ARTIFACTS: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "for dataset_name, run_flag in RUN_EXPERIMENTS.items():\n",
    "    if not run_flag:\n",
    "        continue\n",
    "    if dataset_name not in DATA_BUNDLES:\n",
    "        print(f\"[WARN] Dataset {dataset_name} not loaded; skipping.\")\n",
    "        continue\n",
    "    bundle = DATA_BUNDLES[dataset_name]\n",
    "    specs = EXPERIMENT_REGISTRY.get(dataset_name, [])\n",
    "    if not specs:\n",
    "        print(f\"[WARN] No model specs registered for {dataset_name}; skipping.\")\n",
    "        continue\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Dataset: {dataset_name} ({bundle.task_type}, {bundle.input_kind})\")\n",
    "    for spec in specs:\n",
    "        print(f\"  -> Training {spec.name}\")\n",
    "        result = train_model_on_bundle(bundle, spec, task_name=dataset_name)\n",
    "        EXPERIMENT_ARTIFACTS.setdefault(dataset_name, {})[spec.name] = result\n",
    "        artifact_path = RESULTS_ROOT / f\"{dataset_name}_{spec.name}_predictions.npz\"\n",
    "        np.savez_compressed(\n",
    "            artifact_path,\n",
    "            train_true=result[\"train_true\"],\n",
    "            train_pred=result[\"train_pred\"],\n",
    "            val_true=result[\"val_true\"],\n",
    "            val_pred=result[\"val_pred\"],\n",
    "            test_true=result[\"test_true\"],\n",
    "            test_pred=result[\"test_pred\"],\n",
    "        )\n",
    "        print(f\"    Validation metrics: {result['val_metrics']}\")\n",
    "        print(f\"    Test metrics       : {result['test_metrics']}\")\n",
    "        print(f\"    Saved predictions to {artifact_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "47f24804",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "id": "47f24804",
    "outputId": "046dd8fe-a24c-4b4d-cdaf-30b9b62aa130"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"EAF_VALO2_forecast\",\n          \"Jena_tdegc_72ctx_36h\",\n          \"EAF_TEMP_forecast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"EAF_VALO2_forecast\",\n          \"Jena_tdegc_72ctx_36h\",\n          \"EAF_TEMP_forecast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"ResPSANN_tabular\",\n          \"MLP_baseline\",\n          \"TCN_baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"baseline\",\n          \"psann\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"train\",\n          \"val\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 376951,\n        \"min\": 157446,\n        \"max\": 1277198,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1076489,\n          456759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_wall_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 137.4940787698296,\n        \"min\": 4.141093297000225,\n        \"max\": 321.5767890269999,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          19.740484281000136,\n          309.1087250769997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Residual PSANN core\",\n          \"ReLU MLP with similar parameter budget\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 318.54664356989474,\n        \"min\": 0.014498550723875403,\n        \"max\": 1127.084230480859,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          20.4185918815282,\n          2.5522628397450537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179.22561083962543,\n        \"min\": 0.009224878428554786,\n        \"max\": 475.67126580207577,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          13.498109190614073,\n          1.935643553225115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smape\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2112573482750618,\n        \"min\": 0.007600588039037466,\n        \"max\": 0.6781309161976523,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.008228057346459861,\n          0.3662919500007251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6605898280949707,\n        \"min\": -1.6022640929719887,\n        \"max\": 0.9880367636040194,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.25891420742472326,\n          0.9037468657875373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.100976607360784,\n        \"min\": 0.07542295577304148,\n        \"max\": 17.55452162307649,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          0.9433688323881784,\n          12.063928924723148\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04984311808487782,\n        \"min\": 0.7757041058703766,\n        \"max\": 0.9887982077132341,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.9878380540886542,\n          0.986400725294651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050797271193308256,\n        \"min\": 0.7723894118070591,\n        \"max\": 0.9896744088701831,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.9886374210186951,\n          0.9872814968339371\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nll\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.167428180195621,\n        \"min\": 0.06595445482510397,\n        \"max\": 0.8034769781871232,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.07516104613207182,\n          0.08921076912462576\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ece\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023514328667513122,\n        \"min\": 0.020670247980000635,\n        \"max\": 0.13179676711539068,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.042770051030010796,\n          0.04460010356721502\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "results_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1287a421-176f-4140-ada1-cd3c0b884a9d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>group</th>\n",
       "      <th>split</th>\n",
       "      <th>params</th>\n",
       "      <th>train_wall_seconds</th>\n",
       "      <th>notes</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "      <th>mase</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>nll</th>\n",
       "      <th>ece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>psann</td>\n",
       "      <td>train</td>\n",
       "      <td>1076489</td>\n",
       "      <td>7.958187</td>\n",
       "      <td>Residual PSANN core</td>\n",
       "      <td>21.872530</td>\n",
       "      <td>14.257730</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>0.289276</td>\n",
       "      <td>0.541215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>psann</td>\n",
       "      <td>val</td>\n",
       "      <td>1076489</td>\n",
       "      <td>7.958187</td>\n",
       "      <td>Residual PSANN core</td>\n",
       "      <td>20.517528</td>\n",
       "      <td>13.436105</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.251715</td>\n",
       "      <td>0.939035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>psann</td>\n",
       "      <td>test</td>\n",
       "      <td>1076489</td>\n",
       "      <td>7.958187</td>\n",
       "      <td>Residual PSANN core</td>\n",
       "      <td>23.891865</td>\n",
       "      <td>15.075829</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>0.706053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>206593</td>\n",
       "      <td>6.217907</td>\n",
       "      <td>ReLU MLP with similar parameter budget</td>\n",
       "      <td>21.370292</td>\n",
       "      <td>14.206419</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.321541</td>\n",
       "      <td>0.538999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>EAF_TEMP_forecast</td>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>val</td>\n",
       "      <td>206593</td>\n",
       "      <td>6.217907</td>\n",
       "      <td>ReLU MLP with similar parameter budget</td>\n",
       "      <td>20.418592</td>\n",
       "      <td>13.498109</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>0.943369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>psann</td>\n",
       "      <td>val</td>\n",
       "      <td>1076233</td>\n",
       "      <td>321.576789</td>\n",
       "      <td>Residual PSANN core</td>\n",
       "      <td>478.446377</td>\n",
       "      <td>337.931761</td>\n",
       "      <td>0.050940</td>\n",
       "      <td>0.974256</td>\n",
       "      <td>0.125858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>psann</td>\n",
       "      <td>test</td>\n",
       "      <td>1076233</td>\n",
       "      <td>321.576789</td>\n",
       "      <td>Residual PSANN core</td>\n",
       "      <td>488.978574</td>\n",
       "      <td>348.974955</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.974847</td>\n",
       "      <td>0.125557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>206337</td>\n",
       "      <td>75.815578</td>\n",
       "      <td>ReLU MLP with similar parameter budget</td>\n",
       "      <td>548.341991</td>\n",
       "      <td>389.962456</td>\n",
       "      <td>0.058990</td>\n",
       "      <td>0.969114</td>\n",
       "      <td>0.119690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>val</td>\n",
       "      <td>206337</td>\n",
       "      <td>75.815578</td>\n",
       "      <td>ReLU MLP with similar parameter budget</td>\n",
       "      <td>559.548665</td>\n",
       "      <td>416.914380</td>\n",
       "      <td>0.063978</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.155273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>Rossmann_sales</td>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>test</td>\n",
       "      <td>206337</td>\n",
       "      <td>75.815578</td>\n",
       "      <td>ReLU MLP with similar parameter budget</td>\n",
       "      <td>573.841809</td>\n",
       "      <td>417.800867</td>\n",
       "      <td>0.061133</td>\n",
       "      <td>0.965358</td>\n",
       "      <td>0.150320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 17 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1287a421-176f-4140-ada1-cd3c0b884a9d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1287a421-176f-4140-ada1-cd3c0b884a9d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1287a421-176f-4140-ada1-cd3c0b884a9d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-6e698636-99aa-4511-b5fa-0a4b0f3f9bc9\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e698636-99aa-4511-b5fa-0a4b0f3f9bc9')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-6e698636-99aa-4511-b5fa-0a4b0f3f9bc9 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_4b7092e3-f2f8-431f-94ab-5a465ddd662c\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_4b7092e3-f2f8-431f-94ab-5a465ddd662c button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('results_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              dataset               task             model     group  split  \\\n",
       "0   EAF_TEMP_forecast  EAF_TEMP_forecast  ResPSANN_tabular     psann  train   \n",
       "1   EAF_TEMP_forecast  EAF_TEMP_forecast  ResPSANN_tabular     psann    val   \n",
       "2   EAF_TEMP_forecast  EAF_TEMP_forecast  ResPSANN_tabular     psann   test   \n",
       "3   EAF_TEMP_forecast  EAF_TEMP_forecast      MLP_baseline  baseline  train   \n",
       "4   EAF_TEMP_forecast  EAF_TEMP_forecast      MLP_baseline  baseline    val   \n",
       "..                ...                ...               ...       ...    ...   \n",
       "85     Rossmann_sales     Rossmann_sales  ResPSANN_tabular     psann    val   \n",
       "86     Rossmann_sales     Rossmann_sales  ResPSANN_tabular     psann   test   \n",
       "87     Rossmann_sales     Rossmann_sales      MLP_baseline  baseline  train   \n",
       "88     Rossmann_sales     Rossmann_sales      MLP_baseline  baseline    val   \n",
       "89     Rossmann_sales     Rossmann_sales      MLP_baseline  baseline   test   \n",
       "\n",
       "     params  train_wall_seconds                                   notes  \\\n",
       "0   1076489            7.958187                     Residual PSANN core   \n",
       "1   1076489            7.958187                     Residual PSANN core   \n",
       "2   1076489            7.958187                     Residual PSANN core   \n",
       "3    206593            6.217907  ReLU MLP with similar parameter budget   \n",
       "4    206593            6.217907  ReLU MLP with similar parameter budget   \n",
       "..      ...                 ...                                     ...   \n",
       "85  1076233          321.576789                     Residual PSANN core   \n",
       "86  1076233          321.576789                     Residual PSANN core   \n",
       "87   206337           75.815578  ReLU MLP with similar parameter budget   \n",
       "88   206337           75.815578  ReLU MLP with similar parameter budget   \n",
       "89   206337           75.815578  ReLU MLP with similar parameter budget   \n",
       "\n",
       "          rmse         mae     smape        r2      mase  accuracy  f1_macro  \\\n",
       "0    21.872530   14.257730  0.008698  0.289276  0.541215       NaN       NaN   \n",
       "1    20.517528   13.436105  0.008185  0.251715  0.939035       NaN       NaN   \n",
       "2    23.891865   15.075829  0.009201  0.050648  0.706053       NaN       NaN   \n",
       "3    21.370292   14.206419  0.008670  0.321541  0.538999       NaN       NaN   \n",
       "4    20.418592   13.498109  0.008228  0.258914  0.943369       NaN       NaN   \n",
       "..         ...         ...       ...       ...       ...       ...       ...   \n",
       "85  478.446377  337.931761  0.050940  0.974256  0.125858       NaN       NaN   \n",
       "86  488.978574  348.974955  0.050791  0.974847  0.125557       NaN       NaN   \n",
       "87  548.341991  389.962456  0.058990  0.969114  0.119690       NaN       NaN   \n",
       "88  559.548665  416.914380  0.063978  0.964789  0.155273       NaN       NaN   \n",
       "89  573.841809  417.800867  0.061133  0.965358  0.150320       NaN       NaN   \n",
       "\n",
       "    nll  ece  \n",
       "0   NaN  NaN  \n",
       "1   NaN  NaN  \n",
       "2   NaN  NaN  \n",
       "3   NaN  NaN  \n",
       "4   NaN  NaN  \n",
       "..  ...  ...  \n",
       "85  NaN  NaN  \n",
       "86  NaN  NaN  \n",
       "87  NaN  NaN  \n",
       "88  NaN  NaN  \n",
       "89  NaN  NaN  \n",
       "\n",
       "[90 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to /content/colab_results/experiment_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "results_df = RESULT_LOGGER.to_frame()\n",
    "results_path = RESULTS_ROOT / \"experiment_metrics.csv\"\n",
    "if not results_df.empty:\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    display(results_df)\n",
    "    print(f\"Metrics saved to {results_path}\")\n",
    "else:\n",
    "    print(\"No experiments were run yet. Toggle RUN_EXPERIMENTS before executing the training cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37cb9471",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "37cb9471",
    "outputId": "47401f1a-affe-42ce-9f57-0b3c1c9bf91b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"    print(\\\"Train the target model first; EXPERIMENT_ARTIFACTS does not contain it yet\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"calendar\",\n          \"valo2_lags\",\n          \"gas_flow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016979438122031437,\n        \"min\": -0.007852936297598933,\n        \"max\": 0.03185433129188457,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.01838459000493662,\n          -0.007852936297598933,\n          0.006854753289968429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0029730829640524647,\n        \"min\": 0.0024483536563007276,\n        \"max\": 0.009792026615368637,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.004914955603668698,\n          0.0024483536563007276,\n          0.0033835713094108218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.9621327059837288,\n        \"max\": 0.9621327059837288,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9621327059837288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-44e3f1d4-f0db-47f9-ae09-689d0b3a332a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>std_delta</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>temp_lags</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.007176</td>\n",
       "      <td>0.962133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calendar</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>0.962133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gas_flow</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.962133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inj</td>\n",
       "      <td>-0.006991</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>0.962133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valo2_lags</td>\n",
       "      <td>-0.007853</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.962133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44e3f1d4-f0db-47f9-ae09-689d0b3a332a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-44e3f1d4-f0db-47f9-ae09-689d0b3a332a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-44e3f1d4-f0db-47f9-ae09-689d0b3a332a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-50929e8b-eaff-43d1-9b30-d47db29b4a7d\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50929e8b-eaff-43d1-9b30-d47db29b4a7d')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-50929e8b-eaff-43d1-9b30-d47db29b4a7d button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        group  mean_delta  std_delta  baseline\n",
       "0   temp_lags    0.031854   0.007176  0.962133\n",
       "4    calendar    0.018385   0.004915  0.962133\n",
       "2    gas_flow    0.006855   0.003384  0.962133\n",
       "3         inj   -0.006991   0.009792  0.962133\n",
       "1  valo2_lags   -0.007853   0.002448  0.962133"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TARGET_DATASET = \"EAF_TEMP_forecast\"\n",
    "TARGET_MODEL = \"ResPSANN_tabular\"\n",
    "\n",
    "if TARGET_DATASET in EXPERIMENT_ARTIFACTS and TARGET_MODEL in EXPERIMENT_ARTIFACTS[TARGET_DATASET]:\n",
    "    bundle = DATA_BUNDLES[TARGET_DATASET]\n",
    "    spec = next(spec for spec in EXPERIMENT_REGISTRY[TARGET_DATASET] if spec.name == TARGET_MODEL)\n",
    "    trained_model = EXPERIMENT_ARTIFACTS[TARGET_DATASET][TARGET_MODEL][\"model\"]\n",
    "\n",
    "    prefix_groups = {\n",
    "        \"temp_lags\": [i for i, name in enumerate(bundle.feature_names) if name.startswith(\"TEMP_lag\")],\n",
    "        \"valo2_lags\": [i for i, name in enumerate(bundle.feature_names) if name.startswith(\"VALO2_lag\")],\n",
    "        \"gas_flow\": [i for i, name in enumerate(bundle.feature_names) if \"gas\" in name.lower()],\n",
    "        \"inj\": [i for i, name in enumerate(bundle.feature_names) if \"inj\" in name.lower()],\n",
    "        \"calendar\": [i for i, name in enumerate(bundle.feature_names) if \"DATETIME\" in name],\n",
    "    }\n",
    "\n",
    "    perm_df = permutation_importance(\n",
    "        trained_model,\n",
    "        bundle,\n",
    "        spec,\n",
    "        feature_groups=prefix_groups,\n",
    "        split=\"test\",\n",
    "        n_repeats=5,\n",
    "    )\n",
    "    display(perm_df.sort_values(\"mean_delta\", ascending=False))\n",
    "else:\n",
    "    print(\"Train the target model first; EXPERIMENT_ARTIFACTS does not contain it yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1c6a52d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1c6a52d",
    "outputId": "a116f8ec-32ce-4afa-f725-7d9e03cb1dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participation ratio: 1.4756\n"
     ]
    }
   ],
   "source": [
    "TARGET_DATASET = \"Jena_tdegc_72ctx_36h\"\n",
    "TARGET_MODEL = \"ResPSANN_conv_spine\"\n",
    "\n",
    "if TARGET_DATASET in EXPERIMENT_ARTIFACTS and TARGET_MODEL in EXPERIMENT_ARTIFACTS[TARGET_DATASET]:\n",
    "    bundle = DATA_BUNDLES[TARGET_DATASET]\n",
    "    spec = next(spec for spec in EXPERIMENT_REGISTRY[TARGET_DATASET] if spec.name == TARGET_MODEL)\n",
    "    trained_model = EXPERIMENT_ARTIFACTS[TARGET_DATASET][TARGET_MODEL][\"model\"].to(DEVICE)\n",
    "    sample_loader = build_dataloader(\n",
    "        bundle.val[\"X\"],\n",
    "        bundle.val[\"y\"],\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        task_type=spec.task_type,\n",
    "    )\n",
    "    sample_batch = next(iter(sample_loader))[0][:64]\n",
    "    singular_values = compute_jacobian_singular_values(trained_model, sample_batch, max_samples=64)\n",
    "    pr = participation_ratio(singular_values)\n",
    "    print(f\"Participation ratio: {pr:.4f}\")\n",
    "    trained_model.to(\"cpu\")\n",
    "else:\n",
    "    print(\"Train the target model first to access EXPERIMENT_ARTIFACTS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9afd5b0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9afd5b0b",
    "outputId": "540e61fd-1d8d-4e8f-ceee-019a9668c0d0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"robustness_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15811388300841897,\n        \"min\": 0.0,\n        \"max\": 0.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.1,\n          0.4,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.575474718560812,\n        \"min\": 46.01486439628873,\n        \"max\": 127.79765443479715,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          127.79765443479715,\n          94.48472058668499,\n          110.87102858677721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.327271595355068,\n        \"min\": 29.070318274944725,\n        \"max\": 95.99605338560534,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          95.99605338560534,\n          68.61259907706207,\n          84.1766082951975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smape\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3220457251905292,\n        \"min\": 0.4990691613592151,\n        \"max\": 1.2525394925530584,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.2122244069359396,\n          1.2525394925530584,\n          1.1996402064392508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0309984934338199,\n        \"min\": -2.2310735453932526,\n        \"max\": 0.5811129745965989,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -2.2310735453932526,\n          -0.7661345380431882,\n          -1.4318511930468296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8074773587391744,\n        \"min\": 3.222386590714206,\n        \"max\": 10.6409703624701,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10.6409703624701,\n          7.605569265835468,\n          9.330808533184609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "robustness_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-18afc318-dd98-41e8-a934-b2c322698918\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "      <th>mase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.014864</td>\n",
       "      <td>29.070318</td>\n",
       "      <td>0.499069</td>\n",
       "      <td>0.581113</td>\n",
       "      <td>3.222387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>127.797654</td>\n",
       "      <td>95.996053</td>\n",
       "      <td>1.212224</td>\n",
       "      <td>-2.231074</td>\n",
       "      <td>10.640970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>110.871029</td>\n",
       "      <td>84.176608</td>\n",
       "      <td>1.199640</td>\n",
       "      <td>-1.431851</td>\n",
       "      <td>9.330809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>98.701487</td>\n",
       "      <td>73.510134</td>\n",
       "      <td>1.206441</td>\n",
       "      <td>-0.927294</td>\n",
       "      <td>8.148451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>94.484721</td>\n",
       "      <td>68.612599</td>\n",
       "      <td>1.252539</td>\n",
       "      <td>-0.766135</td>\n",
       "      <td>7.605569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18afc318-dd98-41e8-a934-b2c322698918')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-18afc318-dd98-41e8-a934-b2c322698918 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-18afc318-dd98-41e8-a934-b2c322698918');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-36fd093e-1d9a-4ef7-8dd6-55724f055158\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36fd093e-1d9a-4ef7-8dd6-55724f055158')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-36fd093e-1d9a-4ef7-8dd6-55724f055158 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_19e9065e-5a69-4c06-9f78-4040639330ab\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('robustness_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_19e9065e-5a69-4c06-9f78-4040639330ab button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('robustness_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   level        rmse        mae     smape        r2       mase\n",
       "0    0.0   46.014864  29.070318  0.499069  0.581113   3.222387\n",
       "1    0.1  127.797654  95.996053  1.212224 -2.231074  10.640970\n",
       "2    0.2  110.871029  84.176608  1.199640 -1.431851   9.330809\n",
       "3    0.3   98.701487  73.510134  1.206441 -0.927294   8.148451\n",
       "4    0.4   94.484721  68.612599  1.252539 -0.766135   7.605569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TARGET_DATASET = \"Beijing_PM25_24h_ctx_6h_horizon\"\n",
    "TARGET_MODEL = \"ResPSANN_conv_spine\"\n",
    "\n",
    "if TARGET_DATASET in EXPERIMENT_ARTIFACTS and TARGET_MODEL in EXPERIMENT_ARTIFACTS[TARGET_DATASET]:\n",
    "    bundle = DATA_BUNDLES[TARGET_DATASET]\n",
    "    spec = next(spec for spec in EXPERIMENT_REGISTRY[TARGET_DATASET] if spec.name == TARGET_MODEL)\n",
    "    trained_model = EXPERIMENT_ARTIFACTS[TARGET_DATASET][TARGET_MODEL][\"model\"]\n",
    "\n",
    "    def missingness_fn(X: np.ndarray, level: float) -> np.ndarray:\n",
    "        rng = np.random.default_rng(GLOBAL_CONFIG[\"seed\"])\n",
    "        mask = rng.random(size=X.shape) < level\n",
    "        X_corrupted = X.copy()\n",
    "        X_corrupted[mask] = 0.0\n",
    "        return X_corrupted\n",
    "\n",
    "    robustness_df = evaluate_robustness(\n",
    "        trained_model,\n",
    "        bundle,\n",
    "        spec,\n",
    "        corruption_fn=missingness_fn,\n",
    "        split=\"test\",\n",
    "        levels=[0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    )\n",
    "    display(robustness_df)\n",
    "else:\n",
    "    print(\"Train the target model before running robustness experiments.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a58771f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a58771f",
    "outputId": "aa9c3544-31e8-4ffb-cdaa-2efe8a720034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv spine accuracy: 0.9230\n",
      "Attention spine accuracy: 0.7757\n"
     ]
    }
   ],
   "source": [
    "TARGET_DATASET = \"HAR_raw_sequence\"\n",
    "if TARGET_DATASET in EXPERIMENT_ARTIFACTS:\n",
    "    results = EXPERIMENT_ARTIFACTS[TARGET_DATASET]\n",
    "    if \"ResPSANN_conv_spine\" in results and \"ResPSANN_attention_spine\" in results:\n",
    "        conv_acc = results[\"ResPSANN_conv_spine\"][\"test_metrics\"][\"accuracy\"]\n",
    "        attn_acc = results[\"ResPSANN_attention_spine\"][\"test_metrics\"][\"accuracy\"]\n",
    "        print(f\"Conv spine accuracy: {conv_acc:.4f}\")\n",
    "        print(f\"Attention spine accuracy: {attn_acc:.4f}\")\n",
    "    else:\n",
    "        print(\"Run both PSANN spine variants on HAR_raw_sequence first.\")\n",
    "else:\n",
    "    print(\"Train HAR_raw_sequence models before evaluating H5.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c00e71",
   "metadata": {
    "id": "a9c00e71"
   },
   "source": [
    "## Notebook Complete\n",
    "All core experiment scaffolding is now in place. Toggle the runs you need, execute the training cell per hypothesis, and archive outputs from `colab_results/` before ending your Colab session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "x6qgdD_WPmvf",
   "metadata": {
    "id": "x6qgdD_WPmvf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def zip_folder(folder_path: str | Path, output_path: str | Path | None = None, *, include_hidden: bool = True) -> Path:\n",
    "    \"\"\"\n",
    "    Compresses an entire folder (recursively) into a .zip archive.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str or Path\n",
    "        Path to the folder to zip.\n",
    "    output_path : str or Path or None, optional\n",
    "        Output .zip file path. Defaults to \"<folder_name>.zip\" in the same directory.\n",
    "    include_hidden : bool, optional\n",
    "        Whether to include hidden files (those starting with '.').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Path to the created .zip file.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path).resolve()\n",
    "    if not folder_path.is_dir():\n",
    "        raise ValueError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = folder_path.with_suffix(\".zip\")\n",
    "    else:\n",
    "        output_path = Path(output_path).resolve()\n",
    "\n",
    "    with zipfile.ZipFile(output_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            # skip hidden dirs/files if requested\n",
    "            if not include_hidden:\n",
    "                dirs[:] = [d for d in dirs if not d.startswith(\".\")]\n",
    "                files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "            for file in files:\n",
    "                abs_path = Path(root) / file\n",
    "                # relative path inside the zip\n",
    "                rel_path = abs_path.relative_to(folder_path)\n",
    "                zf.write(abs_path, arcname=rel_path)\n",
    "\n",
    "    print(f\"Zipped {folder_path} â†’ {output_path}\")\n",
    "    return output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eeG6oGYtM1rd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeG6oGYtM1rd",
    "outputId": "394f511d-7777-4613-8abc-09ecfe6e8ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped /content/colab_results â†’ /content/colab_results.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/colab_results.zip')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_folder(folder_path = '/content/colab_results', output_path = '/content/colab_results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kKFbc--ONBQa",
   "metadata": {
    "id": "kKFbc--ONBQa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "411c15a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Synthetic Probe Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0a1ab",
   "metadata": {
    "id": "yvJaRyajTB4k"
   },
   "source": [
    "This notebook fabricates compact synthetic datasets that stand in for the larger\n",
    "benchmarks in the plan, then runs a focused suite of probes:\n",
    "\n",
    "â€¢ Parity-locked comparisons (PSANN + tiny temporal spine vs TCN/LSTM/MLP)\n",
    "â€¢ Cross-\"station\" generalization & missingness robustness\n",
    "â€¢ Grouped permutation (information-usage) ablations\n",
    "â€¢ Spectral/geometry diagnostics (Jacobian SVD & participation ratio)\n",
    "â€¢ EAF-style per-heat resets & Î”TEMP targets\n",
    "\n",
    "Results are saved to: /content/psann_synth_results/\n",
    "\n",
    "Design draws from the experiment plan and PSANN docs:\n",
    "- Plan & hypotheses (H1â€“H5), fairness constraints, and probes:  :contentReference[oaicite:3]{index=3}\n",
    "- Estimator surface and usage patterns (sklearn-style, HISSO-ready):  :contentReference[oaicite:4]{index=4}\n",
    "- Activation math, residual wrappers, and utilities (Jacobian/NTK):  :contentReference[oaicite:5]{index=5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fc84dd",
   "metadata": {
    "id": "LG858hEjS9sb"
   },
   "outputs": [],
   "source": [
    "# @title Imports, device, tiny utils\n",
    "import os, math, time, json, random, itertools, functools\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict, List, Callable, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RESULTS_DIR = \"/content/psann_synth_results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def set_seed(s:int):\n",
    "    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n",
    "\n",
    "def param_count(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred) + eps)\n",
    "    return (100.0 / len(y_true)) * np.sum(np.abs(y_pred - y_true) / denom)\n",
    "\n",
    "def mase(y_true, y_pred, m=1):\n",
    "    # naive seasonal m=1 by default\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    naive = np.mean(np.abs(y_true[m:] - y_true[:-m])) + 1e-8\n",
    "    return np.mean(np.abs(y_true - y_pred)) / naive\n",
    "\n",
    "def save_csv(df: pd.DataFrame, name: str):\n",
    "    path = os.path.join(RESULTS_DIR, name)\n",
    "    if os.path.exists(path):\n",
    "        old = pd.read_csv(path)\n",
    "        df = pd.concat([old, df], ignore_index=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Saved -> {path} ({len(df)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a3c8a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44rE4SziTLTr",
    "outputId": "b4d210a7-3675-4864-b205-e59807d06a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psann\n",
      "  Downloading psann-0.10.3-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from psann) (2.0.2)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.12/dist-packages (from psann) (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1->psann) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1->psann) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1->psann) (3.0.3)\n",
      "Downloading psann-0.10.3-py3-none-any.whl (78 kB)\n",
      "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/78.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psann\n",
      "Successfully installed psann-0.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install psann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1494e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHVxaMXfTEPm",
    "outputId": "23f25747-1a3b-45a2-ddf6-f38991aa1b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using installed psann package.\n"
     ]
    }
   ],
   "source": [
    "# @title Try importing your PSANN; else define a compact fallback that mirrors PSANN\n",
    "try:\n",
    "    import psann  # type: ignore\n",
    "    HAVE_PSANN = True\n",
    "    from psann import PSANNRegressor  # sklearn-style\n",
    "    try:\n",
    "        from psann.models.wave_resnet import WaveResNet as PSANNWaveResNet\n",
    "    except Exception:\n",
    "        PSANNWaveResNet = None\n",
    "    print(\"Using installed psann package.\")\n",
    "except Exception as e:\n",
    "    HAVE_PSANN = False\n",
    "    PSANNRegressor = None\n",
    "    PSANNWaveResNet = None\n",
    "    print(\"psann not found; using a compact sine-activated residual fallback.\")\n",
    "\n",
    "import math\n",
    "\n",
    "class SineParam(nn.Module):\n",
    "    \"\"\"SIREN-style learnable sine activation with optional decay as in TECHNICAL_DETAILS.md (simplified).\"\"\"\n",
    "    def __init__(self, features, w0=30.0, use_decay=True):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.zeros(features))  # amplitude pre-softplus\n",
    "        self.b = nn.Parameter(torch.zeros(features))  # frequency pre-softplus\n",
    "        self.c = nn.Parameter(torch.zeros(features))  # decay pre-softplus\n",
    "        self.w0 = w0\n",
    "        self.use_decay = use_decay\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z):\n",
    "        A = self.softplus(self.a).view(1, -1)\n",
    "        f = self.softplus(self.b).view(1, -1) + 1e-6\n",
    "        d = self.softplus(self.c).view(1, -1)\n",
    "        if z.dim() == 3:  # (B, T, F)\n",
    "            A = A.unsqueeze(1)\n",
    "            f = f.unsqueeze(1)\n",
    "            d = d.unsqueeze(1)\n",
    "        if self.use_decay:\n",
    "            return A * torch.exp(-d * torch.abs(z)) * torch.sin(f * z)\n",
    "        else:\n",
    "            return A * torch.sin(f * z)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_f, out_f, p_drop=0.0):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_f, out_f)\n",
    "        self.act = SineParam(out_f)\n",
    "        self.alpha = nn.Parameter(torch.tensor(1.0))\n",
    "        self.do = nn.Dropout(p_drop)\n",
    "        self.short = (in_f == out_f)\n",
    "\n",
    "        # SIREN-ish init for fc\n",
    "        wstd = math.sqrt(6.0 / in_f) / 30.0\n",
    "        nn.init.uniform_(self.fc.weight, -wstd, wstd)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.do(self.act(self.fc(x)))\n",
    "        out = h\n",
    "        if self.short:\n",
    "            out = x + self.alpha * h\n",
    "        return out\n",
    "\n",
    "class ResSineMLP(nn.Module):\n",
    "    def __init__(self, in_f, hidden, layers=2, out_f=1, p_drop=0.0):\n",
    "        super().__init__()\n",
    "        net = []\n",
    "        dim = in_f\n",
    "        for _ in range(layers):\n",
    "            net.append(ResBlock(dim, hidden, p_drop))\n",
    "            dim = hidden\n",
    "        self.net = nn.Sequential(*net)\n",
    "        self.head = nn.Linear(dim, out_f)\n",
    "        nn.init.zeros_(self.head.bias)\n",
    "\n",
    "    def forward(self, x):  # x: (B, F)\n",
    "        h = self.net(x)\n",
    "        return self.head(h)\n",
    "\n",
    "class ConvSpine1D(nn.Module):\n",
    "    \"\"\"Tiny strided Conv1d spine -> global average -> residual sine MLP head.\"\"\"\n",
    "    def __init__(self, in_ch, ch=32, k=5, stride=2, mlp_hidden=64, mlp_layers=2, out_f=1):\n",
    "        super().__init__()\n",
    "        pad = (k//2)\n",
    "        self.conv1 = nn.Conv1d(in_ch, ch, kernel_size=k, padding=pad, stride=stride)\n",
    "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=k, padding=pad, stride=stride)\n",
    "        self.mlp = ResSineMLP(in_f=ch, hidden=mlp_hidden, layers=mlp_layers, out_f=out_f)\n",
    "        # SIREN-ish init\n",
    "        for c in [self.conv1, self.conv2]:\n",
    "            nn.init.kaiming_uniform_(c.weight, a=math.sqrt(5))\n",
    "            if c.bias is not None: nn.init.zeros_(c.bias)\n",
    "\n",
    "    def forward(self, x):  # x: (B, T, F) -> (B, F, T)\n",
    "        x = x.transpose(1, 2)\n",
    "        h = F.silu(self.conv1(x))\n",
    "        h = F.silu(self.conv2(h))\n",
    "        h = h.mean(-1)  # GAP over time -> (B, ch)\n",
    "        return self.mlp(h)\n",
    "\n",
    "class AttentionSpine1D(nn.Module):\n",
    "    \"\"\"Single-head self-attention spine -> mean pool -> residual sine MLP head.\"\"\"\n",
    "    def __init__(self, in_f, d=64, mlp_hidden=64, mlp_layers=2, out_f=1):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(in_f, d); self.k = nn.Linear(in_f, d); self.v = nn.Linear(in_f, d)\n",
    "        self.mlp = ResSineMLP(in_f=d, hidden=mlp_hidden, layers=mlp_layers, out_f=out_f)\n",
    "\n",
    "    def forward(self, x):  # (B, T, F)\n",
    "        Q, K, V = self.q(x), self.k(x), self.v(x)\n",
    "        att = torch.softmax(Q @ K.transpose(1,2) / math.sqrt(Q.size(-1)), dim=-1)\n",
    "        H = att @ V\n",
    "        h = H.mean(1)  # pool over time\n",
    "        return self.mlp(h)\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    \"\"\"Simple 1D TCN block with causal padding.\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, k=5, dilation=1):\n",
    "        super().__init__()\n",
    "        pad = (k-1)*dilation\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, k, padding=pad, dilation=dilation)\n",
    "        self.short = (in_ch == out_ch)\n",
    "        self.proj = nn.Conv1d(in_ch, out_ch, 1) if not self.short else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = h[..., :x.size(-1)]  # causal trim\n",
    "        h = F.relu(h)\n",
    "        return F.relu(self.proj(x) + h)\n",
    "\n",
    "class TinyTCN(nn.Module):\n",
    "    def __init__(self, in_ch, ch=32, layers=2, k=5, out_f=1):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        c = in_ch\n",
    "        for i in range(layers):\n",
    "            blocks.append(TCNBlock(c, ch, k=k, dilation=2**i))\n",
    "            c = ch\n",
    "        self.tcn = nn.Sequential(*blocks)\n",
    "        self.head = nn.Linear(ch, out_f)\n",
    "\n",
    "    def forward(self, x):  # (B, T, F) -> (B, F, T)\n",
    "        x = x.transpose(1,2)\n",
    "        h = self.tcn(x).transpose(1,2)  # back to (B, T, C)\n",
    "        h_last = h[:, -1, :]\n",
    "        return self.head(h_last)\n",
    "\n",
    "class TinyLSTM(nn.Module):\n",
    "    def __init__(self, in_f, hidden=64, out_f=1, layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_f, hidden, num_layers=layers, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, out_f)\n",
    "\n",
    "    def forward(self, x):  # (B, T, F)\n",
    "        h, (hn, cn) = self.lstm(x)\n",
    "        return self.head(h[:, -1, :])\n",
    "\n",
    "class WaveResNetFallback(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        *,\n",
    "        hidden_dim: int,\n",
    "        depth: int,\n",
    "        output_dim: int,\n",
    "        dropout: float = 0.0,\n",
    "        first_layer_w0: float = 30.0,\n",
    "        hidden_w0: float = 1.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if input_dim <= 0 or hidden_dim <= 0 or output_dim <= 0:\n",
    "            raise ValueError(\"input_dim, hidden_dim, and output_dim must be positive.\")\n",
    "        if depth <= 0:\n",
    "            raise ValueError(\"depth must be positive.\")\n",
    "        self.stem = nn.Linear(input_dim, hidden_dim)\n",
    "        wstd = math.sqrt(6.0 / input_dim) / max(first_layer_w0, 1e-6)\n",
    "        nn.init.uniform_(self.stem.weight, -wstd, wstd)\n",
    "        nn.init.zeros_(self.stem.bias)\n",
    "        self.blocks = nn.ModuleList([ResBlock(hidden_dim, hidden_dim, p_drop=dropout) for _ in range(depth)])\n",
    "        self.head = nn.Linear(hidden_dim, output_dim)\n",
    "        nn.init.zeros_(self.head.bias)\n",
    "        self.stem_w0 = first_layer_w0\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = torch.sin(self.stem_w0 * self.stem(x))\n",
    "        for block in self.blocks:\n",
    "            h = block(h)\n",
    "        return self.head(h)\n",
    "\n",
    "\n",
    "def make_wave_resnet(\n",
    "    input_dim: int,\n",
    "    *,\n",
    "    hidden_dim: int,\n",
    "    depth: int,\n",
    "    output_dim: int,\n",
    "    dropout: float = 0.0,\n",
    "    first_layer_w0: float = 30.0,\n",
    "    hidden_w0: float = 1.0,\n",
    "):\n",
    "    if 'PSANNWaveResNet' in globals() and PSANNWaveResNet is not None:\n",
    "        return PSANNWaveResNet(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            depth=depth,\n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout,\n",
    "            first_layer_w0=first_layer_w0,\n",
    "            hidden_w0=hidden_w0,\n",
    "        )\n",
    "    return WaveResNetFallback(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        depth=depth,\n",
    "        output_dim=output_dim,\n",
    "        dropout=dropout,\n",
    "        first_layer_w0=first_layer_w0,\n",
    "        hidden_w0=hidden_w0,\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Generic training helpers (regression) ---\n",
    "def fit_regressor(model, X_train, y_train, X_val, y_val, epochs=60, lr=1e-3, bs=128, verbose=False):\n",
    "    model = model.to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    best = math.inf; best_state = None\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32); y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32); y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "    train_loader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=bs, shuffle=True)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            pred = model(xb)\n",
    "            loss = F.mse_loss(pred.view_as(yb), yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val.to(DEVICE)).cpu().numpy().ravel()\n",
    "            vloss = np.mean((val_pred - y_val.numpy().ravel())**2)\n",
    "        if vloss < best:\n",
    "            best = vloss; best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "        if verbose and (ep+1)%10==0:\n",
    "            print(f\"ep {ep+1:3d} val_mse={vloss:.6f}\")\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "def predict_regressor(model, X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(X, dtype=torch.float32, device=DEVICE)\n",
    "        y = model(X).cpu().numpy().ravel()\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c3d01d",
   "metadata": {
    "id": "LGL52f5ATFp9"
   },
   "outputs": [],
   "source": [
    "# @title Generators: Seasonal (Jena proxy), Cross-Station Air (Beijing proxy), and EAF Î”TEMP\n",
    "def gen_seasonal_series(n=20000, noise=0.15, drift=0.0002, w=(1/24, 1/168)):\n",
    "    t = np.arange(n, dtype=np.float32)\n",
    "    daily = np.sin(2*np.pi*w[0]*t)\n",
    "    weekly = 0.5*np.sin(2*np.pi*w[1]*t + 0.3)\n",
    "    trend = drift * t\n",
    "    base = daily + weekly + trend\n",
    "    exo = np.stack([\n",
    "        np.cos(2*np.pi*w[0]*t), np.sin(2*np.pi*w[0]*t),\n",
    "        np.cos(2*np.pi*w[1]*t), np.sin(2*np.pi*w[1]*t),\n",
    "    ], axis=1)\n",
    "    y = base + noise*np.random.randn(n).astype(np.float32)\n",
    "    return y.astype(np.float32), exo.astype(np.float32)\n",
    "\n",
    "def window_xy(y, exo, ctx=72, horizon=6):\n",
    "    Xs, Ys = [], []\n",
    "    for i in range(ctx, len(y)-horizon):\n",
    "        hist = y[i-ctx:i].reshape(-1,1)\n",
    "        feats = np.concatenate([hist, exo[i-ctx:i]], axis=1)\n",
    "        Xs.append(feats)           # (ctx, 1+exo_dim)\n",
    "        Ys.append(y[i+horizon])\n",
    "    return np.array(Xs, np.float32), np.array(Ys, np.float32)\n",
    "\n",
    "def gen_cross_station_air(stations=10, n=5000, ctx=24, horizon=3, missing=0.0, seed=0):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    data = []\n",
    "    for s in range(stations):\n",
    "        amp = 0.8 + 0.4*rs.rand()\n",
    "        phi = rs.rand()*2*np.pi\n",
    "        t = np.arange(n, dtype=np.float32)\n",
    "        base = amp*np.sin(2*np.pi*(1/24)*t + phi) + 0.2*np.sin(2*np.pi*(1/48)*t)\n",
    "        met = np.stack([\n",
    "            np.sin(2*np.pi*(1/24)*t + 0.1), np.cos(2*np.pi*(1/24)*t + 0.2),\n",
    "            0.5*np.sin(2*np.pi*(1/168)*t + 0.3)\n",
    "        ], axis=1).astype(np.float32)\n",
    "        y = base + 0.1*rs.randn(n).astype(np.float32)\n",
    "        X, Y = window_xy(y, met, ctx=ctx, horizon=horizon)\n",
    "        # inject missingness on met channels only\n",
    "        if missing > 0:\n",
    "            mask = rs.rand(*X.shape) < (missing * (X.shape[-1]-1)/X.shape[-1])\n",
    "            # keep history column (index 0) intact, drop some exo\n",
    "            mask[..., 0] = False\n",
    "            X[mask] = 0.0\n",
    "            # optional: append masks as features\n",
    "            X = np.concatenate([X, mask.astype(np.float32)], axis=-1)\n",
    "        data.append((s, X, Y))\n",
    "    return data  # list of (station_id, X, y)\n",
    "\n",
    "def gen_eaf_heats(heats=120, min_len=80, max_len=200, seed=0):\n",
    "    \"\"\"Î”TEMP_t â‰ˆ a1*O2_t + a2*MW_t + a3*sqrt(O2_t)*noise; counters reset per heat.\"\"\"\n",
    "    rs = np.random.RandomState(seed)\n",
    "    X_rows, y_rows, heat_ids = [], [], []\n",
    "    for h in range(heats):\n",
    "        L = rs.randint(min_len, max_len+1)\n",
    "        O2 = np.abs(rs.randn(L).astype(np.float32))*2.0\n",
    "        MW = np.abs(rs.randn(L).astype(np.float32))*3.0\n",
    "        # cumulative counters reset at each heat:\n",
    "        c_O2 = np.cumsum(O2)\n",
    "        c_MW = np.cumsum(MW)\n",
    "        dtemp = 0.7*O2 + 0.4*MW + 0.15*np.sqrt(O2+1e-6)*rs.randn(L).astype(np.float32)\n",
    "        TEMP = np.cumsum(dtemp) + 20*rs.rand()  # integral of Î”TEMP\n",
    "        # target: next-step Î”TEMP\n",
    "        y = np.roll(dtemp, -1); y[-1] = dtemp[-1]\n",
    "        feats = np.stack([O2, MW, c_O2, c_MW, TEMP], axis=1).astype(np.float32)\n",
    "        X_rows.append(feats); y_rows.append(y.astype(np.float32)); heat_ids += [h]*L\n",
    "    X = np.concatenate(X_rows, axis=0)\n",
    "    y = np.concatenate(y_rows, axis=0)\n",
    "    heat_ids = np.array(heat_ids, dtype=np.int32)\n",
    "    # build windows\n",
    "    ctx=24\n",
    "    Xs, Ys = [], []\n",
    "    for i in range(ctx, len(y)-1):\n",
    "        if heat_ids[i-ctx] != heat_ids[i]:  # ensure window does not cross heats\n",
    "            continue\n",
    "        hist = X[i-ctx:i, :]  # includes counters already reset per-heat\n",
    "        Xs.append(hist); Ys.append(y[i])\n",
    "    return np.array(Xs, np.float32), np.array(Ys, np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d0619f2",
   "metadata": {
    "id": "NrRxnUloTQaa"
   },
   "outputs": [],
   "source": [
    "# @title Parity matchers: adjust hidden sizes to hit a target parameter budget\n",
    "def build_psann_conv(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    # search small grid over (conv_ch, mlp_hidden, layers)\n",
    "    for ch in [16, 24, 32, 40, 48]:\n",
    "        for mh in [32, 48, 64, 96]:\n",
    "            for layers in [1, 2, 3]:\n",
    "                m = ConvSpine1D(in_ch=in_f, ch=ch, k=5, stride=2, mlp_hidden=mh, mlp_layers=layers, out_f=out_f)\n",
    "                p = param_count(m)\n",
    "                if abs(p - target_params)/target_params <= tol:\n",
    "                    return m, p\n",
    "    # fallback: pick closest\n",
    "    best, bestp = None, 1e18\n",
    "    for ch in [16, 24, 32, 40, 48]:\n",
    "        for mh in [32, 48, 64, 96]:\n",
    "            for layers in [1, 2, 3]:\n",
    "                m = ConvSpine1D(in_ch=in_f, ch=ch, k=5, stride=2, mlp_hidden=mh, mlp_layers=layers, out_f=out_f)\n",
    "                p = param_count(m)\n",
    "                if abs(p - target_params) < abs(bestp - target_params):\n",
    "                    best, bestp = m, p\n",
    "    return best, bestp\n",
    "\n",
    "def build_tcn(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    for ch in [16, 24, 32, 40, 48, 64]:\n",
    "        for layers in [1,2,3,4]:\n",
    "            m = TinyTCN(in_ch=in_f, ch=ch, layers=layers, k=5, out_f=out_f)\n",
    "            p = param_count(m)\n",
    "            if abs(p - target_params)/target_params <= tol:\n",
    "                return m, p\n",
    "    # fallback\n",
    "    best, bestp = None, 1e18\n",
    "    for ch in [16, 24, 32, 40, 48, 64]:\n",
    "        for layers in [1,2,3,4]:\n",
    "            m = TinyTCN(in_ch=in_f, ch=ch, layers=layers, k=5, out_f=out_f)\n",
    "            p = param_count(m)\n",
    "            if abs(p - target_params) < abs(bestp - target_params):\n",
    "                best, bestp = m, p\n",
    "    return best, bestp\n",
    "\n",
    "def build_lstm(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    for h in [32, 48, 64, 80, 96, 128, 160]:\n",
    "        m = TinyLSTM(in_f=in_f, hidden=h, out_f=out_f, layers=1)\n",
    "        p = param_count(m)\n",
    "        if abs(p - target_params)/target_params <= tol:\n",
    "            return m, p\n",
    "    # fallback\n",
    "    best, bestp = None, 1e18\n",
    "    for h in [32, 48, 64, 80, 96, 128, 160]:\n",
    "        m = TinyLSTM(in_f=in_f, hidden=h, out_f=out_f, layers=1)\n",
    "        p = param_count(m)\n",
    "        if abs(p - target_params) < abs(bestp - target_params):\n",
    "            best, bestp = m, p\n",
    "    return best, bestp\n",
    "\n",
    "def build_psann_tabular(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    for mh in [32, 48, 64, 96, 128]:\n",
    "        for layers in [1, 2, 3]:\n",
    "            m = ResSineMLP(in_f, hidden=mh, layers=layers, out_f=out_f)\n",
    "            p = param_count(m)\n",
    "            if abs(p - target_params)/target_params <= tol:\n",
    "                return m, p\n",
    "    # fallback\n",
    "    best, bestp = None, 1e18\n",
    "    for mh in [32, 48, 64, 96, 128]:\n",
    "        for layers in [1, 2, 3]:\n",
    "            m = ResSineMLP(in_f, hidden=mh, layers=layers, out_f=out_f)\n",
    "            p = param_count(m)\n",
    "            if abs(p - target_params) < abs(bestp - target_params):\n",
    "                best, bestp = m, p\n",
    "    return best, bestp\n",
    "\n",
    "class SimpleScaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None; self.std = None\n",
    "    def fit(self, X):\n",
    "        self.mean = X.mean(axis=0, keepdims=True)\n",
    "        self.std = X.std(axis=0, keepdims=True) + 1e-8\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean)/self.std\n",
    "\n",
    "def eval_regression(y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
    "    sm = smape(y_true, y_pred)\n",
    "    ms = mase(y_true, y_pred, m=1)\n",
    "    return dict(r2=r2, mae=mae, rmse=rmse, smape=sm, mase=ms)\n",
    "\n",
    "class WaveResNetSeqBaseline(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch: int,\n",
    "        *,\n",
    "        conv_channels: int = 64,\n",
    "        conv_depth: int = 2,\n",
    "        hidden_dim: int = 160,\n",
    "        depth: int = 4,\n",
    "        out_f: int = 1,\n",
    "        dropout: float = 0.05,\n",
    "        first_layer_w0: float = 30.0,\n",
    "        hidden_w0: float = 1.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        layers: List[nn.Module] = []\n",
    "        channels = in_ch\n",
    "        for _ in range(conv_depth):\n",
    "            conv = nn.Conv1d(channels, conv_channels, kernel_size=5, padding=2, stride=2)\n",
    "            nn.init.kaiming_uniform_(conv.weight, a=math.sqrt(5))\n",
    "            if conv.bias is not None:\n",
    "                nn.init.zeros_(conv.bias)\n",
    "            layers.extend([conv, nn.GELU()])\n",
    "            channels = conv_channels\n",
    "        self.conv = nn.Sequential(*layers) if layers else nn.Identity()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        final_input = conv_channels if layers else in_ch\n",
    "        self.wave = make_wave_resnet(\n",
    "            final_input,\n",
    "            hidden_dim=hidden_dim,\n",
    "            depth=depth,\n",
    "            output_dim=out_f,\n",
    "            dropout=dropout,\n",
    "            first_layer_w0=first_layer_w0,\n",
    "            hidden_w0=hidden_w0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        z = x.transpose(1, 2)\n",
    "        z = self.conv(z)\n",
    "        z = self.pool(z).squeeze(-1)\n",
    "        return self.wave(z)\n",
    "\n",
    "\n",
    "def build_wave_resnet_seq(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    best, bestp = None, float('inf')\n",
    "    for conv_channels in [48, 64, 96, 128]:\n",
    "        for conv_depth in [1, 2, 3]:\n",
    "            for hidden_dim in [128, 160, 192, 224]:\n",
    "                for depth in [3, 4, 5]:\n",
    "                    model = WaveResNetSeqBaseline(\n",
    "                        in_ch=in_f,\n",
    "                        conv_channels=conv_channels,\n",
    "                        conv_depth=conv_depth,\n",
    "                        hidden_dim=hidden_dim,\n",
    "                        depth=depth,\n",
    "                        out_f=out_f,\n",
    "                        dropout=0.05,\n",
    "                    )\n",
    "                    p = param_count(model)\n",
    "                    if abs(p - target_params) / max(target_params, 1) <= tol:\n",
    "                        return model, p\n",
    "                    if abs(p - target_params) < abs(bestp - target_params):\n",
    "                        best, bestp = model, p\n",
    "    return best, bestp\n",
    "\n",
    "\n",
    "def build_wave_resnet_tabular(in_f, target_params=200_000, tol=0.15, out_f=1):\n",
    "    best, bestp = None, float('inf')\n",
    "    for hidden_dim in [128, 160, 192, 224, 256]:\n",
    "        for depth in [3, 4, 5, 6]:\n",
    "            model = make_wave_resnet(\n",
    "                in_f,\n",
    "                hidden_dim=hidden_dim,\n",
    "                depth=depth,\n",
    "                output_dim=out_f,\n",
    "                dropout=0.05,\n",
    "            )\n",
    "            p = param_count(model)\n",
    "            if abs(p - target_params) / max(target_params, 1) <= tol:\n",
    "                return model, p\n",
    "            if abs(p - target_params) < abs(bestp - target_params):\n",
    "                best, bestp = model, p\n",
    "    return best, bestp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355fbc57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "GDaJGQNlTSx1",
    "outputId": "5d20884d-8880-40f2-a406-5f8c5d88c39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /content/psann_synth_results/synthetic_experiment_metrics.csv (9 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03473763569003126,\n        \"min\": 0.1113,\n        \"max\": 0.1742,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1742,\n          0.1172,\n          0.1113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mase\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8531000018119812,\n          0.5741999745368958,\n          0.545199990272522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35295.65099272147,\n        \"min\": 37108.0,\n        \"max\": 107041.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          107041.0,\n          37108.0,\n          63745.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02327581004677035,\n        \"min\": 0.9279,\n        \"max\": 0.9704,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9279,\n          0.9656,\n          0.9704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04229708421786698,\n        \"min\": 0.1395,\n        \"max\": 0.2176,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2176,\n          0.1504,\n          0.1395\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smape\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.8717000484466553,\n          1.9844000339508057,\n          1.9404000043869019\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_wall_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.336845777146019,\n        \"min\": 29.8154,\n        \"max\": 41.4863,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          39.9298,\n          41.4863,\n          29.8154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-df57e823-be35-4b86-aa51-f3ee877e21b7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>mase</th>\n",
       "      <th>params</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "      <th>train_wall_seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>probe</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SEASONAL_JENA_PROXY</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">PARITY</th>\n",
       "      <th>LSTM_baseline</th>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>107041.0</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>2.8717</td>\n",
       "      <td>39.9298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResPSANN_conv_spine</th>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>37108.0</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>1.9844</td>\n",
       "      <td>41.4863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCN_baseline</th>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>63745.0</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>1.9404</td>\n",
       "      <td>29.8154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df57e823-be35-4b86-aa51-f3ee877e21b7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-df57e823-be35-4b86-aa51-f3ee877e21b7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-df57e823-be35-4b86-aa51-f3ee877e21b7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4042996b-4ef8-4bcd-af34-4c5ae425a097\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4042996b-4ef8-4bcd-af34-4c5ae425a097')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4042996b-4ef8-4bcd-af34-4c5ae425a097 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                   mae    mase    params  \\\n",
       "dataset             probe  model                                           \n",
       "SEASONAL_JENA_PROXY PARITY LSTM_baseline        0.1742  0.8531  107041.0   \n",
       "                           ResPSANN_conv_spine  0.1172  0.5742   37108.0   \n",
       "                           TCN_baseline         0.1113  0.5452   63745.0   \n",
       "\n",
       "                                                    r2    rmse   smape  \\\n",
       "dataset             probe  model                                         \n",
       "SEASONAL_JENA_PROXY PARITY LSTM_baseline        0.9279  0.2176  2.8717   \n",
       "                           ResPSANN_conv_spine  0.9656  0.1504  1.9844   \n",
       "                           TCN_baseline         0.9704  0.1395  1.9404   \n",
       "\n",
       "                                                train_wall_seconds  \n",
       "dataset             probe  model                                    \n",
       "SEASONAL_JENA_PROXY PARITY LSTM_baseline                   39.9298  \n",
       "                           ResPSANN_conv_spine             41.4863  \n",
       "                           TCN_baseline                    29.8154  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Seasonal probe: PSANN+Conv vs TCN vs LSTM (parity, 3 seeds)\n",
    "set_seed(SEED)\n",
    "y, exo = gen_seasonal_series(n=22000, noise=0.12, drift=0.00015)\n",
    "X, Y = window_xy(y, exo, ctx=72, horizon=6)   # X: (N, 72, 1+4) -> F=5\n",
    "# Train/val/test split\n",
    "N = len(Y); n_train = int(0.7*N); n_val = int(0.15*N)\n",
    "X_train, y_train = X[:n_train], Y[:n_train]\n",
    "X_val,   y_val   = X[n_train:n_train+n_val], Y[n_train:n_train+n_val]\n",
    "X_test,  y_test  = X[n_train+n_val:], Y[n_train+n_val:]\n",
    "sc = SimpleScaler();  # scale per-feature across flattened dims\n",
    "flat = X_train.reshape(-1, X_train.shape[-1]); sc.fit(flat)\n",
    "def scale_seq(Xseq):\n",
    "    shp = Xseq.shape\n",
    "    Xs = sc.transform(Xseq.reshape(-1, shp[-1])).reshape(shp)\n",
    "    return Xs\n",
    "\n",
    "X_train_s = scale_seq(X_train); X_val_s = scale_seq(X_val); X_test_s = scale_seq(X_test)\n",
    "\n",
    "target_params = 220_000\n",
    "in_f = X.shape[-1]\n",
    "records = []\n",
    "for seed in [1, 2, 3]:\n",
    "    set_seed(seed)\n",
    "    # Build parity-matched models\n",
    "    psann_m, p_ps = build_psann_conv(in_f, target_params, out_f=1)\n",
    "    tcn_m,   p_tc = build_tcn(in_f, target_params, out_f=1)\n",
    "    lstm_m,  p_ls = build_lstm(in_f, target_params, out_f=1)\n",
    "    wave_m,  p_wr = build_wave_resnet_seq(in_f, target_params, out_f=1)\n",
    "    for name, model, pcount in [\n",
    "        (\"ResPSANN_conv_spine\", psann_m, p_ps),\n",
    "        (\"TCN_baseline\",        tcn_m,   p_tc),\n",
    "        (\"LSTM_baseline\",       lstm_m,  p_ls),\n",
    "        (\"WaveResNet_sequence\",  wave_m,  p_wr),\n",
    "    ]:\n",
    "        t0 = time.time()\n",
    "        model = fit_regressor(model, X_train_s, y_train[:,None], X_val_s, y_val[:,None],\n",
    "                              epochs=60, lr=3e-3, bs=128, verbose=False)\n",
    "        t1 = time.time()\n",
    "        yhat = predict_regressor(model, X_test_s)\n",
    "        mets = eval_regression(y_test, yhat)\n",
    "        rec = dict(\n",
    "            dataset=\"SEASONAL_JENA_PROXY\", probe=\"PARITY\", split=\"test\", seed=seed,\n",
    "            model=name, params=param_count(model), train_wall_seconds=t1-t0, **mets\n",
    "        )\n",
    "        records.append(rec)\n",
    "df = pd.DataFrame(records)\n",
    "save_csv(df, \"synthetic_experiment_metrics.csv\")\n",
    "df.pivot_table(index=[\"dataset\",\"probe\",\"model\"], values=[\"r2\",\"mae\",\"rmse\",\"smape\",\"mase\",\"params\",\"train_wall_seconds\"]).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a561039d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "7_e1c8LpTUZw",
    "outputId": "4c70685b-69b0-4194-dfe0-2540084abb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /content/psann_synth_results/synthetic_experiment_metrics.csv (36 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \")\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009069561425143138,\n        \"min\": 0.0856,\n        \"max\": 0.1117,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0985,\n          0.0948,\n          0.0887\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007238976293494667,\n        \"min\": 0.9528,\n        \"max\": 0.9748,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9634,\n          0.9688,\n          0.9703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011360286576979966,\n        \"min\": 0.1075,\n        \"max\": 0.1405,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.1237,\n          0.1195,\n          0.1114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-709ffcfe-b5f6-42bc-a48d-dde41e00c6ed\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probe</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HELDOUT+MISS_0</th>\n",
       "      <th>LSTM_baseline</th>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResPSANN_conv_spine</th>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCN_baseline</th>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HELDOUT+MISS_10</th>\n",
       "      <th>LSTM_baseline</th>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResPSANN_conv_spine</th>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCN_baseline</th>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">HELDOUT+MISS_30</th>\n",
       "      <th>LSTM_baseline</th>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResPSANN_conv_spine</th>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCN_baseline</th>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.1134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-709ffcfe-b5f6-42bc-a48d-dde41e00c6ed')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-709ffcfe-b5f6-42bc-a48d-dde41e00c6ed button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-709ffcfe-b5f6-42bc-a48d-dde41e00c6ed');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-667147a1-3c81-483d-a8ce-f64e9142bdf5\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-667147a1-3c81-483d-a8ce-f64e9142bdf5')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-667147a1-3c81-483d-a8ce-f64e9142bdf5 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                        mae      r2    rmse\n",
       "probe           model                                      \n",
       "HELDOUT+MISS_0  LSTM_baseline        0.1025  0.9635  0.1292\n",
       "                ResPSANN_conv_spine  0.0948  0.9688  0.1195\n",
       "                TCN_baseline         0.0856  0.9748  0.1075\n",
       "HELDOUT+MISS_10 LSTM_baseline        0.1096  0.9545  0.1374\n",
       "                ResPSANN_conv_spine  0.0973  0.9645  0.1218\n",
       "                TCN_baseline         0.0887  0.9703  0.1114\n",
       "HELDOUT+MISS_30 LSTM_baseline        0.1117  0.9528  0.1405\n",
       "                ResPSANN_conv_spine  0.0985  0.9634  0.1237\n",
       "                TCN_baseline         0.0899  0.9692  0.1134"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Cross-station held-out & missingness robustness; parity-matched PSANN+Conv vs TCN vs LSTM\n",
    "set_seed(SEED)\n",
    "\n",
    "def prep_dataset(miss=0.0, seed=42, ctx=24, horizon=3):\n",
    "    \"\"\"\n",
    "    Generate a fresh cross-station dataset with a given missingness rate,\n",
    "    split into train (stations != 0,1), val (station 0), test (station 1),\n",
    "    and fit a scaler on the training split only.\n",
    "    \"\"\"\n",
    "    data = gen_cross_station_air(stations=10, n=6000, ctx=ctx, horizon=horizon, missing=miss, seed=seed)\n",
    "    # Split by station id\n",
    "    X_train = np.concatenate([x for (sid, x, y) in data if sid not in (0, 1)], axis=0)\n",
    "    y_train = np.concatenate([y for (sid, x, y) in data if sid not in (0, 1)], axis=0)\n",
    "    X_val   = next(x for (sid, x, y) in data if sid == 0)\n",
    "    y_val   = next(y for (sid, x, y) in data if sid == 0)\n",
    "    X_test  = next(x for (sid, x, y) in data if sid == 1)\n",
    "    y_test  = next(y for (sid, x, y) in data if sid == 1)\n",
    "\n",
    "    # Scale using only TRAIN statistics\n",
    "    scaler = SimpleScaler()\n",
    "    scaler.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
    "    def scale_seq(X):\n",
    "        shp = X.shape\n",
    "        return scaler.transform(X.reshape(-1, shp[-1])).reshape(shp)\n",
    "\n",
    "    return scale_seq(X_train), y_train, scale_seq(X_val), y_val, scale_seq(X_test), y_test\n",
    "\n",
    "target_params = 200_000\n",
    "records = []\n",
    "for miss in [0.0, 0.1, 0.3]:\n",
    "    # Fresh dataset (and scaler) per missingness level for clean robustness curves\n",
    "    Xtr, ytr, Xv, yv, Xte, yte = prep_dataset(miss=miss, seed=42, ctx=24, horizon=3)\n",
    "    in_f = Xtr.shape[-1]\n",
    "\n",
    "    for seed in [7, 8, 9]:\n",
    "        set_seed(seed)\n",
    "        # Build parity-matched models (â‰ˆ same param count)\n",
    "        psann_m, p_ps = build_psann_conv(in_f, target_params, out_f=1)\n",
    "        tcn_m,   p_tc = build_tcn(in_f, target_params, out_f=1)\n",
    "        lstm_m,  p_ls = build_lstm(in_f, target_params, out_f=1)\n",
    "        wave_m,  p_wr = build_wave_resnet_seq(in_f, target_params, out_f=1)\n",
    "\n",
    "        for name, model in [\n",
    "            (\"ResPSANN_conv_spine\", psann_m),\n",
    "            (\"TCN_baseline\",        tcn_m),\n",
    "            (\"LSTM_baseline\",       lstm_m),\n",
    "            (\"WaveResNet_sequence\",  wave_m),\n",
    "        ]:\n",
    "            t0 = time.time()\n",
    "            model = fit_regressor(model, Xtr, ytr[:, None], Xv, yv[:, None],\n",
    "                                  epochs=50, lr=3e-3, bs=256)\n",
    "            t1 = time.time()\n",
    "            yhat = predict_regressor(model, Xte)\n",
    "            mets = eval_regression(yte, yhat)\n",
    "            rec = dict(\n",
    "                dataset=\"AIR_BEIJING_PROXY\",\n",
    "                probe=f\"HELDOUT+MISS_{int(miss*100)}\",\n",
    "                split=\"test\",\n",
    "                seed=seed,\n",
    "                model=name,\n",
    "                params=param_count(model),\n",
    "                train_wall_seconds=t1 - t0,\n",
    "                **mets\n",
    "            )\n",
    "            records.append(rec)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "save_csv(df, \"synthetic_experiment_metrics.csv\")\n",
    "df[df[\"dataset\"] == \"AIR_BEIJING_PROXY\"].pivot_table(\n",
    "    index=[\"probe\", \"model\"], values=[\"r2\", \"mae\", \"rmse\"]\n",
    ").round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5bb2fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "nyFVmmBaTWe7",
    "outputId": "4df529b2-16e8-4601-8bac-245428348ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /content/psann_synth_results/synthetic_ablation_results.csv (3 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"abl_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AIR_BEIJING_PROXY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"probe\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ABLATE_GROUPS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ResPSANN_conv_spine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"history\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.984804093837738,\n        \"max\": 0.984804093837738,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.984804093837738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ablated_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0253813566330807,\n        \"min\": -0.8238558769226074,\n        \"max\": 0.984804093837738,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.8238558769226074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0253813566330807,\n        \"min\": -1.8086599707603455,\n        \"max\": 0.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1.8086599707603455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "abl_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f4a3e3ee-3642-42db-9bc7-1d1557ca52b5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>probe</th>\n",
       "      <th>model</th>\n",
       "      <th>group</th>\n",
       "      <th>base_r2</th>\n",
       "      <th>ablated_r2</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>history</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>-0.823856</td>\n",
       "      <td>-1.808660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>meteorology</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.917602</td>\n",
       "      <td>-0.067202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>calendar</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4a3e3ee-3642-42db-9bc7-1d1557ca52b5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f4a3e3ee-3642-42db-9bc7-1d1557ca52b5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f4a3e3ee-3642-42db-9bc7-1d1557ca52b5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-8192e9fd-9278-4596-8590-aafa9b4d13b1\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8192e9fd-9278-4596-8590-aafa9b4d13b1')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-8192e9fd-9278-4596-8590-aafa9b4d13b1 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_9e8f4991-cf87-4975-8a45-303a00e66be4\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('abl_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9e8f4991-cf87-4975-8a45-303a00e66be4 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('abl_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             dataset          probe                model        group  \\\n",
       "0  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine      history   \n",
       "1  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine  meteorology   \n",
       "2  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine     calendar   \n",
       "\n",
       "    base_r2  ablated_r2     delta  \n",
       "0  0.984804   -0.823856 -1.808660  \n",
       "1  0.984804    0.917602 -0.067202  \n",
       "2  0.984804    0.984804  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Permute grouped features on the AIR proxy (history vs meteorology vs calendar)\n",
    "# FIX: make sure F is the PyTorch functional module, not an int\n",
    "import torch.nn.functional as F  # restore F after any accidental shadowing\n",
    "\n",
    "def grouped_permute(X, groups: Dict[str, List[int]], which: str, rs: np.random.RandomState):\n",
    "    Xp = X.copy()\n",
    "    idxs = groups[which]\n",
    "    # permute across samples independently for each feature channel\n",
    "    for j in idxs:\n",
    "        rs.shuffle(Xp[:, :, j])\n",
    "    return Xp\n",
    "\n",
    "# Rebuild a dataset with explicit groups: [0]=history, [1..m]=met; append calendar(sin/cos hour)\n",
    "def air_with_calendar(seed=2024):\n",
    "    data = gen_cross_station_air(stations=10, n=6000, ctx=24, horizon=3, missing=0.0, seed=seed)\n",
    "    def add_calendar(X):\n",
    "        N, T, Fd = X.shape\n",
    "        hours = np.arange(T, dtype=np.float32)[None, :, None].repeat(N, axis=0)\n",
    "        sin = np.sin(2*np.pi*hours/24.0).astype(np.float32)\n",
    "        cos = np.cos(2*np.pi*hours/24.0).astype(np.float32)\n",
    "        return np.concatenate([X, sin, cos], axis=2)\n",
    "    return [(s, add_calendar(X), y) for (s, X, y) in data]\n",
    "\n",
    "set_seed(101)\n",
    "data = air_with_calendar(seed=101)\n",
    "# Train on all but station 1; test on station 1\n",
    "Xtr = np.concatenate([x for (s, x, y) in data if s != 1], axis=0)\n",
    "ytr = np.concatenate([y for (s, x, y) in data if s != 1], axis=0)\n",
    "Xte = [x for (s, x, y) in data if s == 1][0]\n",
    "yte = [y for (s, x, y) in data if s == 1][0]\n",
    "\n",
    "# Scale on training only\n",
    "sc = SimpleScaler(); sc.fit(Xtr.reshape(-1, Xtr.shape[-1]))\n",
    "def scale_seq(X):\n",
    "    shp = X.shape\n",
    "    return sc.transform(X.reshape(-1, shp[-1])).reshape(shp)\n",
    "\n",
    "Xtr_s, Xte_s = scale_seq(Xtr), scale_seq(Xte)\n",
    "\n",
    "# Group indices:\n",
    "feat_dim = Xtr_s.shape[-1]   # FIX: don't shadow F\n",
    "# history at index 0; meteorology next 3; calendar at the end (2 dims)\n",
    "groups = {\"history\": [0], \"meteorology\": [1, 2, 3], \"calendar\": [feat_dim - 2, feat_dim - 1]}\n",
    "\n",
    "# pick a parity-matched winner config (PSANN+Conv) and compare\n",
    "psann_m, _ = build_psann_conv(feat_dim, target_params=180_000, out_f=1)\n",
    "psann_m = fit_regressor(psann_m, Xtr_s, ytr[:, None], Xtr_s[-5000:], ytr[-5000:, None],\n",
    "                        epochs=40, lr=3e-3, bs=256)\n",
    "base = eval_regression(yte, predict_regressor(psann_m, Xte_s))[\"r2\"]\n",
    "\n",
    "abl_records = []\n",
    "rs = np.random.RandomState(7)\n",
    "for gname in [\"history\", \"meteorology\", \"calendar\"]:\n",
    "    Xp = grouped_permute(Xte_s, groups, gname, rs)\n",
    "    r2 = eval_regression(yte, predict_regressor(psann_m, Xp))[\"r2\"]\n",
    "    abl_records.append(dict(dataset=\"AIR_BEIJING_PROXY\", probe=\"ABLATE_GROUPS\",\n",
    "                            model=\"ResPSANN_conv_spine\",\n",
    "                            group=gname, base_r2=base, ablated_r2=r2, delta=r2 - base))\n",
    "\n",
    "abl_df = pd.DataFrame(abl_records)\n",
    "save_csv(abl_df, \"synthetic_ablation_results.csv\")\n",
    "abl_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7cc412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8ncW57lTeUK",
    "outputId": "c3b37994-61e4-455c-c0e9-08c0d705aa31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'SEASONAL_JENA_PROXY',\n",
       "  'probe': 'SPECTRAL',\n",
       "  'model': 'ResPSANN_conv_spine',\n",
       "  'top_sv': 4.814483165740967,\n",
       "  'sum_sv': 6.343472957611084,\n",
       "  'pr': 1.770914912223816},\n",
       " {'dataset': 'SEASONAL_JENA_PROXY',\n",
       "  'probe': 'SPECTRAL',\n",
       "  'model': 'MLP_laststep',\n",
       "  'top_sv': 4.128472328186035,\n",
       "  'sum_sv': 5.6605544090271,\n",
       "  'pr': 2.7963361740112305}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Jacobian spectrum & participation ratio (PSANN vs MLP) on a small batch â€” FIXED\n",
    "def jacobian_matrix(model: nn.Module, Xb: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute d y / d x for a batch: for each sample i (out_i is scalar y[i,0]),\n",
    "    we compute grad(out_i, Xb)[i, :, :] and vectorize into one row.\n",
    "    Returns J of shape (B, T*F).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    xb = torch.tensor(Xb, dtype=torch.float32, device=DEVICE, requires_grad=True)\n",
    "    y = model(xb)  # (B, 1)\n",
    "    assert y.ndim == 2 and y.shape[1] == 1, f\"Expected (B,1) output, got {tuple(y.shape)}\"\n",
    "\n",
    "    B, T, Fdim = xb.shape\n",
    "    rows = []\n",
    "    for i in range(B):\n",
    "        # grad_outputs must be same shape as y: (B,1)\n",
    "        go = torch.zeros_like(y)\n",
    "        go[i, 0] = 1.0\n",
    "        g = torch.autograd.grad(outputs=y, inputs=xb,\n",
    "                                grad_outputs=go,\n",
    "                                retain_graph=True, create_graph=False,\n",
    "                                allow_unused=False)[0]  # (B,T,F)\n",
    "        gi = g[i].reshape(-1).detach().cpu().numpy()       # (T*F,)\n",
    "        rows.append(gi)\n",
    "    J = np.stack(rows, axis=0)  # (B, T*F)\n",
    "    return J\n",
    "\n",
    "def participation_ratio(M: np.ndarray):\n",
    "    # effective dimensionality of rows of M\n",
    "    C = (M - M.mean(0, keepdims=True))\n",
    "    C = C.T @ C / max(C.shape[0]-1, 1)\n",
    "    evals = np.maximum(np.linalg.eigvalsh(C), 1e-12)\n",
    "    s1 = evals.sum(); s2 = (evals**2).sum()\n",
    "    return float((s1**2) / s2)\n",
    "\n",
    "# build small dataset\n",
    "y, exo = gen_seasonal_series(n=6000)\n",
    "X, Y = window_xy(y, exo, ctx=72, horizon=6)\n",
    "sc = SimpleScaler(); sc.fit(X.reshape(-1, X.shape[-1]))\n",
    "Xs = sc.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "\n",
    "# models: PSANN+Conv (parity-targeted) vs MLP baseline on pooled features\n",
    "psann_m, _ = build_psann_conv(Xs.shape[-1], target_params=160_000, out_f=1)\n",
    "psann_m = fit_regressor(psann_m, Xs[:3000], Y[:3000,None], Xs[3000:4000], Y[3000:4000,None], epochs=30)\n",
    "\n",
    "# Simple MLP baseline on last-step features only\n",
    "class TinyMLP(nn.Module):\n",
    "    def __init__(self, in_f, hidden=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_f, hidden), nn.ReLU(), nn.Linear(hidden, 1))\n",
    "    def forward(self, x):  # x: (B,T,F)\n",
    "        x_last = x[:, -1, :]\n",
    "        return self.net(x_last)\n",
    "\n",
    "mlp = TinyMLP(Xs.shape[-1])\n",
    "mlp = fit_regressor(mlp, Xs[:3000], Y[:3000,None], Xs[3000:4000], Y[3000:4000,None], epochs=30)\n",
    "\n",
    "# Jacobian on a tiny batch for each\n",
    "batch = Xs[4000:4024]\n",
    "J_ps = jacobian_matrix(psann_m, batch)\n",
    "J_ml = jacobian_matrix(mlp, batch)\n",
    "\n",
    "# SVD & metrics\n",
    "_, s_ps, _ = np.linalg.svd(J_ps, full_matrices=False)\n",
    "_, s_ml, _ = np.linalg.svd(J_ml, full_matrices=False)\n",
    "\n",
    "spec_records = [{\n",
    "    \"dataset\":\"SEASONAL_JENA_PROXY\",\"probe\":\"SPECTRAL\",\"model\":\"ResPSANN_conv_spine\",\n",
    "    \"top_sv\": float(s_ps[0]), \"sum_sv\": float(s_ps.sum()), \"pr\": participation_ratio(J_ps)\n",
    "},{\n",
    "    \"dataset\":\"SEASONAL_JENA_PROXY\",\"probe\":\"SPECTRAL\",\"model\":\"MLP_laststep\",\n",
    "    \"top_sv\": float(s_ml[0]), \"sum_sv\": float(s_ml.sum()), \"pr\": participation_ratio(J_ml)\n",
    "}]\n",
    "with open(os.path.join(RESULTS_DIR,\"synthetic_spectral_results.json\"),\"w\") as f:\n",
    "    json.dump(spec_records, f, indent=2)\n",
    "spec_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a839de4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "28MX7IVOTgXU",
    "outputId": "1f35b1ed-5bac-496c-dc6d-7e2117ee7f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /content/psann_synth_results/synthetic_experiment_metrics.csv (38 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"rec[[\\\"model\\\",\\\"r2\\\",\\\"mae\\\",\\\"rmse\\\",\\\"params\\\"]]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ResPSANN_attention_spine\",\n          \"ResPSANN_conv_spine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21069660759015563,\n        \"min\": 0.67226,\n        \"max\": 0.97023,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.67226,\n          0.97023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14581956041628985,\n        \"min\": 0.0943,\n        \"max\": 0.30052,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.30052,\n          0.0943\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19434829880912258,\n        \"min\": 0.11857,\n        \"max\": 0.39342,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.39342,\n          0.11857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15658,\n        \"min\": 14723,\n        \"max\": 36868,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          14723,\n          36868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e58c52a1-fb68-4ff0-a217-5c1ce9dc0bc4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>0.97023</td>\n",
       "      <td>0.09430</td>\n",
       "      <td>0.11857</td>\n",
       "      <td>36868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResPSANN_attention_spine</td>\n",
       "      <td>0.67226</td>\n",
       "      <td>0.30052</td>\n",
       "      <td>0.39342</td>\n",
       "      <td>14723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e58c52a1-fb68-4ff0-a217-5c1ce9dc0bc4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e58c52a1-fb68-4ff0-a217-5c1ce9dc0bc4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e58c52a1-fb68-4ff0-a217-5c1ce9dc0bc4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-3ceb8413-5b02-4a2f-b350-4104f595842b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ceb8413-5b02-4a2f-b350-4104f595842b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-3ceb8413-5b02-4a2f-b350-4104f595842b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                      model       r2      mae     rmse  params\n",
       "0       ResPSANN_conv_spine  0.97023  0.09430  0.11857   36868\n",
       "1  ResPSANN_attention_spine  0.67226  0.30052  0.39342   14723"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Fairness check: single-head attention spine vs conv spine under matched params\n",
    "set_seed(2025)\n",
    "data = gen_cross_station_air(stations=8, n=5000, ctx=24, horizon=3, missing=0.0, seed=77)\n",
    "X = np.concatenate([x for (s,x,y) in data], axis=0)\n",
    "y = np.concatenate([y for (s,x,y) in data], axis=0)\n",
    "sc = SimpleScaler(); sc.fit(X.reshape(-1, X.shape[-1]))\n",
    "Xs = sc.transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "\n",
    "N = len(y); ntr=int(0.7*N); nv=int(0.15*N)\n",
    "Xtr, ytr = Xs[:ntr], y[:ntr]; Xv, yv = Xs[ntr:ntr+nv], y[ntr:ntr+nv]; Xte, yte = Xs[ntr+nv:], y[ntr+nv:]\n",
    "\n",
    "target_params = 180_000\n",
    "# match conv\n",
    "conv_m, p_conv = build_psann_conv(Xs.shape[-1], target_params, out_f=1)\n",
    "# for attention, sweep d & mlp until within tol\n",
    "best_att = None; bestp = 1e18\n",
    "for d in [48, 64, 80]:\n",
    "    for mh in [48, 64, 80]:\n",
    "        att = AttentionSpine1D(in_f=Xs.shape[-1], d=d, mlp_hidden=mh, mlp_layers=2, out_f=1)\n",
    "        p = param_count(att)\n",
    "        if abs(p - target_params) < abs(bestp - target_params):\n",
    "            bestp = p; best_att = att\n",
    "att_m = best_att\n",
    "\n",
    "conv_m = fit_regressor(conv_m, Xtr, ytr[:,None], Xv, yv[:,None], epochs=40, lr=3e-3)\n",
    "att_m  = fit_regressor(att_m,  Xtr, ytr[:,None], Xv, yv[:,None], epochs=40, lr=3e-3)\n",
    "\n",
    "yhat_c = predict_regressor(conv_m, Xte)\n",
    "yhat_a = predict_regressor(att_m,  Xte)\n",
    "rec = pd.DataFrame([\n",
    "    dict(dataset=\"AIR_BEIJING_PROXY\", probe=\"SPINE_FAIRNESS\", split=\"test\", model=\"ResPSANN_conv_spine\",\n",
    "         params=param_count(conv_m), **eval_regression(yte, yhat_c)),\n",
    "    dict(dataset=\"AIR_BEIJING_PROXY\", probe=\"SPINE_FAIRNESS\", split=\"test\", model=\"ResPSANN_attention_spine\",\n",
    "         params=param_count(att_m), **eval_regression(yte, yhat_a)),\n",
    "])\n",
    "save_csv(rec, \"synthetic_experiment_metrics.csv\")\n",
    "rec[[\"model\",\"r2\",\"mae\",\"rmse\",\"params\"]].round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24434be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "TMZULaIfTh9X",
    "outputId": "66810c62-48ac-4b9f-ef4b-aa4ca98556d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> /content/psann_synth_results/synthetic_experiment_metrics.csv (40 rows)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"rec[[\\\"model\\\",\\\"r2\\\",\\\"mae\\\",\\\"rmse\\\",\\\"params\\\",\\\"train_wall_seconds\\\"]]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MLP_baseline\",\n          \"ResPSANN_tabular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004666904755831213,\n        \"min\": -0.00844,\n        \"max\": -0.00184,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.00844,\n          -0.00184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00027577164466275456,\n        \"min\": 0.90144,\n        \"max\": 0.90183,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.90144,\n          0.90183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0026233661582020064,\n        \"min\": 1.12802,\n        \"max\": 1.13173,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.13173,\n          1.12802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 816,\n        \"min\": 34561,\n        \"max\": 35716,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          34561,\n          35716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_wall_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.668765993910494,\n        \"min\": 15.71341,\n        \"max\": 29.38711,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          15.71341,\n          29.38711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d1337cf8-ede0-467e-991c-71907b2122f6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "      <th>train_wall_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResPSANN_tabular</td>\n",
       "      <td>-0.00184</td>\n",
       "      <td>0.90183</td>\n",
       "      <td>1.12802</td>\n",
       "      <td>35716</td>\n",
       "      <td>29.38711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP_baseline</td>\n",
       "      <td>-0.00844</td>\n",
       "      <td>0.90144</td>\n",
       "      <td>1.13173</td>\n",
       "      <td>34561</td>\n",
       "      <td>15.71341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1337cf8-ede0-467e-991c-71907b2122f6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d1337cf8-ede0-467e-991c-71907b2122f6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d1337cf8-ede0-467e-991c-71907b2122f6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-de0f412c-ddef-447b-bb19-29564adf095a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de0f412c-ddef-447b-bb19-29564adf095a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-de0f412c-ddef-447b-bb19-29564adf095a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              model       r2      mae     rmse  params  train_wall_seconds\n",
       "0  ResPSANN_tabular -0.00184  0.90183  1.12802   35716            29.38711\n",
       "1      MLP_baseline -0.00844  0.90144  1.13173   34561            15.71341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title EAF synthetic: Î”TEMP regression with per-heat resets; PSANN-tabular vs MLP baseline\n",
    "set_seed(606)\n",
    "X, y = gen_eaf_heats(heats=140, min_len=80, max_len=180, seed=606)  # X: (N, ctx, F_tabular_per_step)\n",
    "# Collapse per-step features to summary stats over last k steps (tabular proxy)\n",
    "def collapse_tail(Xseq, k=6):\n",
    "    # concat mean and last values for each channel to form a fixed-length tabular vector\n",
    "    tail = Xseq[:, -k:, :]  # (N,k,F)\n",
    "    mean = tail.mean(axis=1)\n",
    "    last = tail[:, -1, :]\n",
    "    return np.concatenate([mean, last], axis=1)\n",
    "\n",
    "X_tab = collapse_tail(X, k=8)\n",
    "# scale\n",
    "mu = X_tab.mean(0, keepdims=True); sd = X_tab.std(0, keepdims=True) + 1e-8\n",
    "Xn = (X_tab - mu)/sd\n",
    "\n",
    "N = len(y); ntr=int(0.7*N); nv=int(0.15*N)\n",
    "Xtr, ytr = Xn[:ntr], y[:ntr]; Xv,yv = Xn[ntr:ntr+nv], y[ntr:ntr+nv]; Xte,yte = Xn[ntr+nv:], y[ntr+nv:]\n",
    "\n",
    "# Baseline MLP\n",
    "class MLP_Reg(nn.Module):\n",
    "    def __init__(self, in_f, hidden=64, layers=2):\n",
    "        super().__init__()\n",
    "        net=[nn.Linear(in_f, hidden), nn.ReLU()]\n",
    "        for _ in range(layers-1):\n",
    "            net += [nn.Linear(hidden, hidden), nn.ReLU()]\n",
    "        self.net = nn.Sequential(*net)\n",
    "        self.head = nn.Linear(hidden, 1)\n",
    "    def forward(self, x): return self.head(self.net(x))\n",
    "\n",
    "def fit_reg_tab(model, Xtr, ytr, Xv, yv, epochs=80, lr=2e-3, bs=128):\n",
    "    model = model.to(DEVICE); opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    Xtr = torch.tensor(Xtr, dtype=torch.float32); ytr = torch.tensor(ytr, dtype=torch.float32)[:,None]\n",
    "    Xv = torch.tensor(Xv, dtype=torch.float32); yv = torch.tensor(yv, dtype=torch.float32)[:,None]\n",
    "    dl = DataLoader(torch.utils.data.TensorDataset(Xtr, ytr), batch_size=bs, shuffle=True)\n",
    "    best=1e9; best_state=None\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in dl:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            pred = model(xb)\n",
    "            loss = F.mse_loss(pred, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            vpred = model(Xv.to(DEVICE)).cpu().numpy().ravel()\n",
    "        v = np.mean((vpred - yv.numpy().ravel())**2)\n",
    "        if v < best: best=v; best_state={k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "    if best_state: model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "in_f = Xn.shape[1]\n",
    "target_params = 160_000\n",
    "psann_tab, p_ps = build_psann_tabular(in_f, target_params, out_f=1)\n",
    "mlp = MLP_Reg(in_f, hidden=128, layers=3)\n",
    "wave_tab, p_wr = build_wave_resnet_tabular(in_f, target_params, out_f=1)\n",
    "\n",
    "t0 = time.time(); psann_tab = fit_reg_tab(psann_tab, Xtr, ytr, Xv, yv, epochs=80, lr=2e-3); t1 = time.time()\n",
    "tw0 = time.time(); wave_tab = fit_reg_tab(wave_tab, Xtr, ytr, Xv, yv, epochs=80, lr=2e-3); tw1 = time.time()\n",
    "tp0 = time.time(); mlp       = fit_reg_tab(mlp,       Xtr, ytr, Xv, yv, epochs=80, lr=2e-3); tp1 = time.time()\n",
    "yhat_ps = predict_regressor(psann_tab, Xte)\n",
    "yhat_wr = predict_regressor(wave_tab, Xte)\n",
    "yhat_ml = predict_regressor(mlp, Xte)\n",
    "\n",
    "rec = pd.DataFrame([\n",
    "    dict(dataset=\"EAF_PROXY\", probe=\"DELTA_TEMP\", split=\"test\", model=\"ResPSANN_tabular\",\n",
    "         params=param_count(psann_tab), train_wall_seconds=t1-t0, **eval_regression(yte, yhat_ps)),\n",
    "    dict(dataset=\"EAF_PROXY\", probe=\"DELTA_TEMP\", split=\"test\", model=\"WaveResNet_tabular\",\n",
    "         params=param_count(wave_tab), train_wall_seconds=tw1-tw0, **eval_regression(yte, yhat_wr)),\n",
    "    dict(dataset=\"EAF_PROXY\", probe=\"DELTA_TEMP\", split=\"test\", model=\"MLP_baseline\",\n",
    "         params=param_count(mlp), train_wall_seconds=tp1-tp0, **eval_regression(yte, yhat_ml)),\n",
    "])\n",
    "save_csv(rec, \"synthetic_experiment_metrics.csv\")\n",
    "rec[[\"model\",\"r2\",\"mae\",\"rmse\",\"params\",\"train_wall_seconds\"]].round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a84feb95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fMj62ie4TjZ7",
    "outputId": "a3e97457-63a7-44e4-a4ee-07b885411401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment metrics rows: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"    print(open(os\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AIR_BEIJING_PROXY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"probe\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"HELDOUT+MISS_0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8255779474818964,\n        \"min\": 7.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LSTM_baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30700,\n        \"min\": 36868,\n        \"max\": 108961,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          106401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_wall_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.0086300211911485,\n        \"min\": 41.52487421035767,\n        \"max\": 58.60875058174133,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          41.52487421035767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008187540528149545,\n        \"min\": 0.9425557851791382,\n        \"max\": 0.9761683940887452,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.9668839573860168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01028647520032752,\n        \"min\": 0.0833498388528823,\n        \"max\": 0.125168040394783,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.0980485305190086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012680224025771882,\n        \"min\": 0.1044845655560493,\n        \"max\": 0.1550253927707672,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.1231670454144477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smape\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.966262908110942,\n        \"min\": 13.16061782836914,\n        \"max\": 16.9312801361084,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          14.319148063659668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06287400680627676,\n        \"min\": 0.4517921805381775,\n        \"max\": 0.7107141613960266,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.531465470790863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4e3e01c7-ec62-4d21-ab76-d574f7ea487f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>probe</th>\n",
       "      <th>split</th>\n",
       "      <th>seed</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>train_wall_seconds</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "      <th>mase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>106401</td>\n",
       "      <td>41.524874</td>\n",
       "      <td>0.966884</td>\n",
       "      <td>0.098049</td>\n",
       "      <td>0.123167</td>\n",
       "      <td>14.319148</td>\n",
       "      <td>0.531465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>106401</td>\n",
       "      <td>41.716242</td>\n",
       "      <td>0.963445</td>\n",
       "      <td>0.102644</td>\n",
       "      <td>0.129404</td>\n",
       "      <td>14.929571</td>\n",
       "      <td>0.556373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>106401</td>\n",
       "      <td>41.803740</td>\n",
       "      <td>0.960139</td>\n",
       "      <td>0.106705</td>\n",
       "      <td>0.135129</td>\n",
       "      <td>16.259560</td>\n",
       "      <td>0.578387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>36868</td>\n",
       "      <td>58.247009</td>\n",
       "      <td>0.968087</td>\n",
       "      <td>0.095834</td>\n",
       "      <td>0.120908</td>\n",
       "      <td>14.547373</td>\n",
       "      <td>0.519461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>36868</td>\n",
       "      <td>57.968974</td>\n",
       "      <td>0.970053</td>\n",
       "      <td>0.092577</td>\n",
       "      <td>0.117125</td>\n",
       "      <td>14.569326</td>\n",
       "      <td>0.501808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>36868</td>\n",
       "      <td>57.654462</td>\n",
       "      <td>0.968290</td>\n",
       "      <td>0.096014</td>\n",
       "      <td>0.120524</td>\n",
       "      <td>14.819717</td>\n",
       "      <td>0.520436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>63361</td>\n",
       "      <td>45.600390</td>\n",
       "      <td>0.976168</td>\n",
       "      <td>0.083350</td>\n",
       "      <td>0.104485</td>\n",
       "      <td>13.160618</td>\n",
       "      <td>0.451792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>63361</td>\n",
       "      <td>45.590491</td>\n",
       "      <td>0.974812</td>\n",
       "      <td>0.085392</td>\n",
       "      <td>0.107418</td>\n",
       "      <td>13.489844</td>\n",
       "      <td>0.462860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_0</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>63361</td>\n",
       "      <td>45.708496</td>\n",
       "      <td>0.973368</td>\n",
       "      <td>0.087999</td>\n",
       "      <td>0.110452</td>\n",
       "      <td>14.183676</td>\n",
       "      <td>0.476995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>108961</td>\n",
       "      <td>42.478026</td>\n",
       "      <td>0.957508</td>\n",
       "      <td>0.106708</td>\n",
       "      <td>0.133331</td>\n",
       "      <td>15.894076</td>\n",
       "      <td>0.605897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>108961</td>\n",
       "      <td>42.134304</td>\n",
       "      <td>0.942556</td>\n",
       "      <td>0.125168</td>\n",
       "      <td>0.155025</td>\n",
       "      <td>16.931280</td>\n",
       "      <td>0.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>108961</td>\n",
       "      <td>42.242739</td>\n",
       "      <td>0.963320</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>0.123878</td>\n",
       "      <td>16.039009</td>\n",
       "      <td>0.550720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>37828</td>\n",
       "      <td>58.608751</td>\n",
       "      <td>0.963288</td>\n",
       "      <td>0.098965</td>\n",
       "      <td>0.123933</td>\n",
       "      <td>14.966591</td>\n",
       "      <td>0.561928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>37828</td>\n",
       "      <td>58.458384</td>\n",
       "      <td>0.966147</td>\n",
       "      <td>0.095124</td>\n",
       "      <td>0.119008</td>\n",
       "      <td>14.716990</td>\n",
       "      <td>0.540123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>37828</td>\n",
       "      <td>58.475555</td>\n",
       "      <td>0.964144</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>0.122479</td>\n",
       "      <td>14.681841</td>\n",
       "      <td>0.555221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>64897</td>\n",
       "      <td>46.591415</td>\n",
       "      <td>0.970497</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.111099</td>\n",
       "      <td>14.488158</td>\n",
       "      <td>0.501005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>64897</td>\n",
       "      <td>46.429520</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.090679</td>\n",
       "      <td>0.113363</td>\n",
       "      <td>14.585592</td>\n",
       "      <td>0.514882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_10</td>\n",
       "      <td>test</td>\n",
       "      <td>9.0</td>\n",
       "      <td>TCN_baseline</td>\n",
       "      <td>64897</td>\n",
       "      <td>46.577246</td>\n",
       "      <td>0.971255</td>\n",
       "      <td>0.087255</td>\n",
       "      <td>0.109664</td>\n",
       "      <td>13.727432</td>\n",
       "      <td>0.495438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_30</td>\n",
       "      <td>test</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>108961</td>\n",
       "      <td>42.217518</td>\n",
       "      <td>0.952576</td>\n",
       "      <td>0.112213</td>\n",
       "      <td>0.140857</td>\n",
       "      <td>15.666063</td>\n",
       "      <td>0.637152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>HELDOUT+MISS_30</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LSTM_baseline</td>\n",
       "      <td>108961</td>\n",
       "      <td>42.541215</td>\n",
       "      <td>0.955104</td>\n",
       "      <td>0.108560</td>\n",
       "      <td>0.137052</td>\n",
       "      <td>15.928967</td>\n",
       "      <td>0.616413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e3e01c7-ec62-4d21-ab76-d574f7ea487f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4e3e01c7-ec62-4d21-ab76-d574f7ea487f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4e3e01c7-ec62-4d21-ab76-d574f7ea487f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-b812998c-cafb-446c-ba22-af5c7f011ce8\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b812998c-cafb-446c-ba22-af5c7f011ce8')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-b812998c-cafb-446c-ba22-af5c7f011ce8 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              dataset            probe split  seed                model  \\\n",
       "11  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   7.0        LSTM_baseline   \n",
       "14  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   8.0        LSTM_baseline   \n",
       "17  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   9.0        LSTM_baseline   \n",
       "9   AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   7.0  ResPSANN_conv_spine   \n",
       "12  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   8.0  ResPSANN_conv_spine   \n",
       "15  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   9.0  ResPSANN_conv_spine   \n",
       "10  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   7.0         TCN_baseline   \n",
       "13  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   8.0         TCN_baseline   \n",
       "16  AIR_BEIJING_PROXY   HELDOUT+MISS_0  test   9.0         TCN_baseline   \n",
       "20  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   7.0        LSTM_baseline   \n",
       "23  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   8.0        LSTM_baseline   \n",
       "26  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   9.0        LSTM_baseline   \n",
       "18  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   7.0  ResPSANN_conv_spine   \n",
       "21  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   8.0  ResPSANN_conv_spine   \n",
       "24  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   9.0  ResPSANN_conv_spine   \n",
       "19  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   7.0         TCN_baseline   \n",
       "22  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   8.0         TCN_baseline   \n",
       "25  AIR_BEIJING_PROXY  HELDOUT+MISS_10  test   9.0         TCN_baseline   \n",
       "29  AIR_BEIJING_PROXY  HELDOUT+MISS_30  test   7.0        LSTM_baseline   \n",
       "32  AIR_BEIJING_PROXY  HELDOUT+MISS_30  test   8.0        LSTM_baseline   \n",
       "\n",
       "    params  train_wall_seconds        r2       mae      rmse      smape  \\\n",
       "11  106401           41.524874  0.966884  0.098049  0.123167  14.319148   \n",
       "14  106401           41.716242  0.963445  0.102644  0.129404  14.929571   \n",
       "17  106401           41.803740  0.960139  0.106705  0.135129  16.259560   \n",
       "9    36868           58.247009  0.968087  0.095834  0.120908  14.547373   \n",
       "12   36868           57.968974  0.970053  0.092577  0.117125  14.569326   \n",
       "15   36868           57.654462  0.968290  0.096014  0.120524  14.819717   \n",
       "10   63361           45.600390  0.976168  0.083350  0.104485  13.160618   \n",
       "13   63361           45.590491  0.974812  0.085392  0.107418  13.489844   \n",
       "16   63361           45.708496  0.973368  0.087999  0.110452  14.183676   \n",
       "20  108961           42.478026  0.957508  0.106708  0.133331  15.894076   \n",
       "23  108961           42.134304  0.942556  0.125168  0.155025  16.931280   \n",
       "26  108961           42.242739  0.963320  0.096990  0.123878  16.039009   \n",
       "18   37828           58.608751  0.963288  0.098965  0.123933  14.966591   \n",
       "21   37828           58.458384  0.966147  0.095124  0.119008  14.716990   \n",
       "24   37828           58.475555  0.964144  0.097783  0.122479  14.681841   \n",
       "19   64897           46.591415  0.970497  0.088235  0.111099  14.488158   \n",
       "22   64897           46.429520  0.969282  0.090679  0.113363  14.585592   \n",
       "25   64897           46.577246  0.971255  0.087255  0.109664  13.727432   \n",
       "29  108961           42.217518  0.952576  0.112213  0.140857  15.666063   \n",
       "32  108961           42.541215  0.955104  0.108560  0.137052  15.928967   \n",
       "\n",
       "        mase  \n",
       "11  0.531465  \n",
       "14  0.556373  \n",
       "17  0.578387  \n",
       "9   0.519461  \n",
       "12  0.501808  \n",
       "15  0.520436  \n",
       "10  0.451792  \n",
       "13  0.462860  \n",
       "16  0.476995  \n",
       "20  0.605897  \n",
       "23  0.710714  \n",
       "26  0.550720  \n",
       "18  0.561928  \n",
       "21  0.540123  \n",
       "24  0.555221  \n",
       "19  0.501005  \n",
       "22  0.514882  \n",
       "25  0.495438  \n",
       "29  0.637152  \n",
       "32  0.616413  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ablation results rows: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"ab\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AIR_BEIJING_PROXY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"probe\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ABLATE_GROUPS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ResPSANN_conv_spine\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"history\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.984804093837738,\n        \"max\": 0.984804093837738,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.984804093837738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ablated_r2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0253813566330807,\n        \"min\": -0.8238558769226074,\n        \"max\": 0.984804093837738,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.8238558769226074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0253813566330805,\n        \"min\": -1.8086599707603452,\n        \"max\": 0.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1.8086599707603452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "ab"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ee17dc43-2c00-4107-83f7-20b16aa40a4a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>probe</th>\n",
       "      <th>model</th>\n",
       "      <th>group</th>\n",
       "      <th>base_r2</th>\n",
       "      <th>ablated_r2</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>history</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>-0.823856</td>\n",
       "      <td>-1.808660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>meteorology</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.917602</td>\n",
       "      <td>-0.067202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIR_BEIJING_PROXY</td>\n",
       "      <td>ABLATE_GROUPS</td>\n",
       "      <td>ResPSANN_conv_spine</td>\n",
       "      <td>calendar</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.984804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee17dc43-2c00-4107-83f7-20b16aa40a4a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ee17dc43-2c00-4107-83f7-20b16aa40a4a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ee17dc43-2c00-4107-83f7-20b16aa40a4a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-86ffeeec-ce28-4cd8-8231-9d498df5725e\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86ffeeec-ce28-4cd8-8231-9d498df5725e')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-86ffeeec-ce28-4cd8-8231-9d498df5725e button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_f232964d-f6a5-4b43-8064-207152c7fa8b\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ab')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_f232964d-f6a5-4b43-8064-207152c7fa8b button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('ab');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             dataset          probe                model        group  \\\n",
       "0  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine      history   \n",
       "1  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine  meteorology   \n",
       "2  AIR_BEIJING_PROXY  ABLATE_GROUPS  ResPSANN_conv_spine     calendar   \n",
       "\n",
       "    base_r2  ablated_r2     delta  \n",
       "0  0.984804   -0.823856 -1.808660  \n",
       "1  0.984804    0.917602 -0.067202  \n",
       "2  0.984804    0.984804  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spectral results: /content/psann_synth_results/synthetic_spectral_results.json\n",
      "[\n",
      "  {\n",
      "    \"dataset\": \"SEASONAL_JENA_PROXY\",\n",
      "    \"probe\": \"SPECTRAL\",\n",
      "    \"model\": \"ResPSANN_conv_spine\",\n",
      "    \"top_sv\": 4.814483165740967,\n",
      "    \"sum_sv\": 6.343472957611084,\n",
      "    \"pr\": 1.770914912223816\n",
      "  },\n",
      "  {\n",
      "    \"dataset\": \"SEASONAL_JENA_PROXY\",\n",
      "    \"probe\": \"SPECTRAL\",\n",
      "    \"model\": \"MLP_laststep\",\n",
      "    \"top_sv\": 4.128472328186035,\n",
      "    \"sum_sv\": 5.6605544090271,\n",
      "    \"pr\": 2.7963361740112305\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# @title Load and preview all CSV outputs\n",
    "em_path = os.path.join(RESULTS_DIR, \"synthetic_experiment_metrics.csv\")\n",
    "ab_path = os.path.join(RESULTS_DIR, \"synthetic_ablation_results.csv\")\n",
    "\n",
    "em = pd.read_csv(em_path) if os.path.exists(em_path) else pd.DataFrame()\n",
    "ab = pd.read_csv(ab_path) if os.path.exists(ab_path) else pd.DataFrame()\n",
    "\n",
    "print(\"Experiment metrics rows:\", len(em))\n",
    "display(em.sort_values([\"dataset\",\"probe\",\"model\"]).head(20))\n",
    "print(\"\\nAblation results rows:\", len(ab))\n",
    "display(ab)\n",
    "print(\"\\nSpectral results:\", os.path.join(RESULTS_DIR,\"synthetic_spectral_results.json\"))\n",
    "if os.path.exists(os.path.join(RESULTS_DIR,\"synthetic_spectral_results.json\")):\n",
    "    print(open(os.path.join(RESULTS_DIR,\"synthetic_spectral_results.json\")).read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea53ec4",
   "metadata": {
    "id": "Og38SkeJTlQn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "def zip_folder(folder_path: str | Path, output_path: str | Path | None = None, *, include_hidden: bool = True) -> Path:\n",
    "    \"\"\"\n",
    "    Compresses an entire folder (recursively) into a .zip archive.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str or Path\n",
    "        Path to the folder to zip.\n",
    "    output_path : str or Path or None, optional\n",
    "        Output .zip file path. Defaults to \"<folder_name>.zip\" in the same directory.\n",
    "    include_hidden : bool, optional\n",
    "        Whether to include hidden files (those starting with '.').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Path to the created .zip file.\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path).resolve()\n",
    "    if not folder_path.is_dir():\n",
    "        raise ValueError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = folder_path.with_suffix(\".zip\")\n",
    "    else:\n",
    "        output_path = Path(output_path).resolve()\n",
    "\n",
    "    with zipfile.ZipFile(output_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            # skip hidden dirs/files if requested\n",
    "            if not include_hidden:\n",
    "                dirs[:] = [d for d in dirs if not d.startswith(\".\")]\n",
    "                files = [f for f in files if not f.startswith(\".\")]\n",
    "\n",
    "            for file in files:\n",
    "                abs_path = Path(root) / file\n",
    "                # relative path inside the zip\n",
    "                rel_path = abs_path.relative_to(folder_path)\n",
    "                zf.write(abs_path, arcname=rel_path)\n",
    "\n",
    "    print(f\"Zipped {folder_path} â†’ {output_path}\")\n",
    "    return output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805dacf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5U5n6-TgfJff",
    "outputId": "45954c6a-23d3-4f6f-c827-5930f2c5e5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped /content/psann_synth_results â†’ /content/psann_synth_results.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/psann_synth_results.zip')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_folder(folder_path = '/content/psann_synth_results', output_path = '/content/psann_synth_results.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
