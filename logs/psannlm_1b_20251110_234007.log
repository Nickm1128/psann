[2025-11-10T23:40:28+00:00] Starting 1B run





[tokenizer] Trained tokenizer saved to runs/tokenizer_1b/tokenizer.json

[tokenizer] Trained tokenizer saved to runs/tokenizer_1b/tokenizer.json



[tokenizer] Trained tokenizer saved to runs/tokenizer_1b/tokenizer.json
[W1110 23:54:57.362772602 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 23:54:58.885798601 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[trainer] FSDP requested but not available (size_based_auto_wrap_policy() missing 3 required positional arguments: 'module', 'recurse', and 'nonwrapped_numel'); falling back to DDP/model-only.
[trainer] FSDP requested but not available (size_based_auto_wrap_policy() missing 3 required positional arguments: 'module', 'recurse', and 'nonwrapped_numel'); falling back to DDP/model-only.
[W1110 23:55:04.724934277 Utils.hpp:137] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[trainer] FSDP requested but not available (size_based_auto_wrap_policy() missing 3 required positional arguments: 'module', 'recurse', and 'nonwrapped_numel'); falling back to DDP/model-only.
[rank1]:[W1110 23:55:13.607892071 Utils.hpp:112] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[trainer] Gradient checkpointing: enabled via model.enable_gradient_checkpointing()
[rank0]:[W1110 23:55:13.614950619 Utils.hpp:112] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[trainer] Gradient checkpointing: enabled via model.enable_gradient_checkpointing()
[rank2]:[W1110 23:55:13.615748506 Utils.hpp:112] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[trainer] Gradient checkpointing: enabled via model.enable_gradient_checkpointing()
[rank0]: Traceback (most recent call last):
[rank0]:   File "/workspace/psann/scripts/train_psann_lm.py", line 483, in <module>
[rank0]:     raise SystemExit(main())
[rank0]:                      ^^^^^^
[rank0]:   File "/workspace/psann/scripts/train_psann_lm.py", line 459, in main
[rank0]:     trainer.train(model, dataset, max_length=int(args.max_length), val_dataset=None)
[rank0]:   File "/workspace/psann/src/psann/lm/train/trainer.py", line 296, in train
[rank0]:     logits = wrapped(input_ids)  # type: ignore[operator]
[rank0]:              ^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1661, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1487, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/src/psann/lm/models/transformer_waveresnet.py", line 129, in forward
[rank0]:     x = _cp(blk, x, use_reentrant=False)
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/_compile.py", line 53, in inner
[rank0]:     return disable_fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py", line 503, in checkpoint
[rank0]:     ret = function(*args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/src/psann/lm/models/transformer_waveresnet.py", line 308, in forward
[rank0]:     attn_out = self.attn(h, past_kv=past_kv, use_cache=use_cache)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/psann/src/psann/lm/models/transformer_respsann.py", line 218, in forward
[rank0]:     att = torch.softmax(att, dim=-1)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacity of 22.06 GiB of which 1.70 GiB is free. Process 1464185 has 20.36 GiB memory in use. Of the allocated memory 19.89 GiB is allocated by PyTorch, and 140.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/workspace/psann/scripts/train_psann_lm.py", line 483, in <module>
[rank1]:     raise SystemExit(main())
[rank1]:                      ^^^^^^
[rank1]:   File "/workspace/psann/scripts/train_psann_lm.py", line 459, in main
[rank1]:     trainer.train(model, dataset, max_length=int(args.max_length), val_dataset=None)
[rank1]:   File "/workspace/psann/src/psann/lm/train/trainer.py", line 296, in train
[rank1]:     logits = wrapped(input_ids)  # type: ignore[operator]
[rank1]:              ^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1661, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/parallel/distributed.py", line 1487, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/src/psann/lm/models/transformer_waveresnet.py", line 129, in forward
[rank1]:     x = _cp(blk, x, use_reentrant=False)
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/_compile.py", line 53, in inner
[rank1]:     return disable_fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[rank1]:     return fn(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py", line 503, in checkpoint
[rank1]:     ret = function(*args, **kwargs)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/src/psann/lm/models/transformer_waveresnet.py", line 308, in forward
[rank1]:     attn_out = self.attn(h, past_kv=past_kv, use_cache=use_cache)
[rank1]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/workspace/psann/src/psann/lm/models/transformer_respsann.py", line 218, in forward
[rank1]:     att = torch.softmax(att, dim=-1)
[rank1]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 1 has a total capacity of 22.06 GiB of which 1.70 GiB is free. Process 1464186 has 20.36 GiB memory in use. Of the allocated memory 19.89 GiB is allocated by PyTorch, and 140.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1110 23:55:23.625778841 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1110 23:55:23.992798348 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[rank1]:[W1110 23:55:23.313774591 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
W1110 23:55:24.415000 2973 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 2980 closing signal SIGTERM
W1110 23:55:24.422000 2973 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 2981 closing signal SIGTERM
E1110 23:55:25.055000 2973 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 0 (pid: 2979) of binary: /workspace/psann/.venv/bin/python
Traceback (most recent call last):
  File "/workspace/psann/.venv/bin/torchrun", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 936, in main
    run(args)
  File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/distributed/run.py", line 927, in run
    elastic_launch(
  File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 156, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/psann/.venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 293, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
scripts/train_psann_lm.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-10_23:55:24
  host      : 27eb2793a45e
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2979)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
[W1110 23:55:25.625943301 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
