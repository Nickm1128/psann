  * Added RoPE attention and absolute PE fallback in both bases.
  * Implemented generate() with top-k/top-p/temperature and repetition penalty.
  * Added trainer checkpointing + best-val and wired CLI YAML flow.
  * Added GELU toggle in MLP and wired sine params from API.
  * Implemented validation split in DataPrep and trainer uses it.


