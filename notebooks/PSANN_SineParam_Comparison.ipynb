{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveResNet vs ResPSANN on Synthetic Data\n",
    "\n",
    "This notebook constructs a simple decaying sine dataset, then fits `ResPSANNRegressor` and `WaveResNetRegressor` with and without trainable sine parameters (amplitude, frequency, decay). Results highlight how allowing these parameters to learn can impact accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be076b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from psann.sklearn import ResPSANNRegressor, WaveResNetRegressor\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic(\n",
    "    n_samples=2000,\n",
    "    noise=0.05,\n",
    "    seed=0,\n",
    "    shape='sine',\n",
    "    shape_kwargs=None,\n",
    "):\n",
    "    \"\"\"Generate 1D regression data following several waveform families.\n",
    "\n",
    "    Args:\n",
    "        n_samples: Total samples to draw uniformly from [-2π, 2π].\n",
    "        noise: Standard deviation of additive Gaussian noise.\n",
    "        seed: Seed for the NumPy RNG.\n",
    "        shape: Name of the target pattern (\"sine\", \"sawtooth\", \"chirp\", \"polynomial\").\n",
    "        shape_kwargs: Optional dict with extra parameters per shape variant.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = rng.uniform(-2 * np.pi, 2 * np.pi, size=(n_samples, 1)).astype(np.float32)\n",
    "    base = x[:, 0]\n",
    "    shape_kwargs = dict(shape_kwargs or {})\n",
    "\n",
    "    if shape == 'sine':\n",
    "        amplitude = 1.0 + 0.5 * np.sin(0.5 * base)\n",
    "        frequency = 1.5 + 0.3 * np.cos(0.25 * base)\n",
    "        damping = 0.03 + 0.01 * base**2\n",
    "        signal = amplitude * np.exp(-damping * np.abs(base)) * np.sin(frequency * base)\n",
    "    elif shape == 'sawtooth':\n",
    "        freq = float(shape_kwargs.get('frequency', 0.8))\n",
    "        slope = float(shape_kwargs.get('slope', 1.0))\n",
    "        period = (2 * np.pi) / max(freq, 1e-3)\n",
    "        phase = (base / period) + float(shape_kwargs.get('phase', 0.0))\n",
    "        ramp = 2.0 * (phase - np.floor(phase + 0.5))\n",
    "        amplitude = 1.0 + 0.4 * np.sin(0.3 * base)\n",
    "        signal = slope * amplitude * ramp\n",
    "    elif shape == 'chirp':\n",
    "        freq0 = float(shape_kwargs.get('freq0', 0.5))\n",
    "        freq1 = float(shape_kwargs.get('freq1', 2.0))\n",
    "        base_min, base_max = float(base.min()), float(base.max())\n",
    "        norm = (base - base_min) / (base_max - base_min + 1e-6)\n",
    "        freq = freq0 + (freq1 - freq0) * norm\n",
    "        signal = np.sin(freq * base**2)\n",
    "    elif shape == 'polynomial':\n",
    "        coeffs = shape_kwargs.get('coeffs', (0.6, -0.3, 0.05))\n",
    "        signal = np.zeros_like(base)\n",
    "        for power, coeff in enumerate(coeffs, start=1):\n",
    "            signal += float(coeff) * base**power\n",
    "        signal = np.tanh(signal)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unsupported shape '{shape}'. Choose from 'sine', 'sawtooth', 'chirp', or 'polynomial'.\"\n",
    "        )\n",
    "\n",
    "    noise_term = rng.normal(scale=noise, size=signal.shape).astype(np.float32)\n",
    "    y = (signal + noise_term).astype(np.float32)\n",
    "    return x, y.reshape(-1, 1)\n",
    "\n",
    "DATA_SHAPE = 'sine'  # Try: 'sawtooth', 'chirp', 'polynomial'\n",
    "SHAPE_KWARGS = {}\n",
    "\n",
    "X, y = generate_synthetic(\n",
    "    n_samples=3000,\n",
    "    noise=0.05,\n",
    "    seed=42,\n",
    "    shape=DATA_SHAPE,\n",
    "    shape_kwargs=SHAPE_KWARGS,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape} (pattern: {DATA_SHAPE})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.scatter(X_train[:, 0], y_train[:, 0], s=8, alpha=0.35, label='train')\n",
    "ax.scatter(X_test[:, 0], y_test[:, 0], s=12, alpha=0.6, label='test')\n",
    "ax.set_title(f\"Synthetic target pattern: {DATA_SHAPE}\")\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec068c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_psann(label, factory):\n",
    "    model = factory()\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    duration = time.time() - start\n",
    "    preds = np.asarray(model.predict(X_test), dtype=np.float32).reshape(-1, 1)\n",
    "    y_true = y_test.reshape(-1)\n",
    "    y_pred = preds.reshape(-1)\n",
    "    metrics = {\n",
    "        'model': label,\n",
    "        'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "        'r2': float(r2_score(y_true, y_pred)),\n",
    "        'time_sec': duration,\n",
    "    }\n",
    "\n",
    "    def predictor(x):\n",
    "        arr = np.asarray(x, dtype=np.float32)\n",
    "        out = np.asarray(model.predict(arr), dtype=np.float32).reshape(-1, 1)\n",
    "        return out\n",
    "\n",
    "    return metrics, predictor, model\n",
    "\n",
    "\n",
    "def evaluate_mlp(label, *, hidden_layers=(128,) * 4, max_iter=400):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPRegressor(\n",
    "        hidden_layer_sizes=hidden_layers,\n",
    "        activation='tanh',\n",
    "        solver='adam',\n",
    "        learning_rate_init=5e-4,\n",
    "        batch_size=256,\n",
    "        max_iter=max_iter,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=20,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    mlp.fit(X_train_scaled, y_train[:, 0])\n",
    "    duration = time.time() - start\n",
    "\n",
    "    preds = mlp.predict(X_test_scaled).reshape(-1, 1).astype(np.float32)\n",
    "    y_true = y_test.reshape(-1)\n",
    "    y_pred = preds.reshape(-1)\n",
    "\n",
    "    metrics = {\n",
    "        'model': label,\n",
    "        'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "        'r2': float(r2_score(y_true, y_pred)),\n",
    "        'time_sec': duration,\n",
    "    }\n",
    "\n",
    "    def predictor(x):\n",
    "        arr = scaler.transform(np.asarray(x, dtype=np.float32))\n",
    "        out = mlp.predict(arr).reshape(-1, 1).astype(np.float32)\n",
    "        return out\n",
    "\n",
    "    return metrics, predictor, {'scaler': scaler, 'model': mlp}\n",
    "\n",
    "\n",
    "class SimpleLSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.head(out[:, -1, :])\n",
    "\n",
    "\n",
    "def evaluate_lstm(\n",
    "    label,\n",
    "    *,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    epochs=60,\n",
    "    lr=5e-4,\n",
    "    batch_size=256,\n",
    "    dropout=0.1,\n",
    "):\n",
    "    model = SimpleLSTMRegressor(\n",
    "        input_dim=1,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    def _to_dataset(X, y):\n",
    "        features = torch.from_numpy(np.asarray(X, dtype=np.float32)).view(-1, 1, 1)\n",
    "        targets = torch.from_numpy(np.asarray(y, dtype=np.float32)).view(-1, 1)\n",
    "        return TensorDataset(features, targets)\n",
    "\n",
    "    train_loader = DataLoader(_to_dataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    duration = time.time() - start\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_tensor = torch.from_numpy(np.asarray(X_test, dtype=np.float32)).view(-1, 1, 1)\n",
    "        preds = model(test_tensor).detach().numpy().astype(np.float32)\n",
    "\n",
    "    y_true = y_test.reshape(-1)\n",
    "    y_pred = preds.reshape(-1)\n",
    "    metrics = {\n",
    "        'model': label,\n",
    "        'mse': float(mean_squared_error(y_true, y_pred)),\n",
    "        'r2': float(r2_score(y_true, y_pred)),\n",
    "        'time_sec': duration,\n",
    "    }\n",
    "\n",
    "    def predictor(x):\n",
    "        arr = torch.from_numpy(np.asarray(x, dtype=np.float32)).view(-1, 1, 1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(arr).detach().numpy().astype(np.float32)\n",
    "        return out\n",
    "\n",
    "    return metrics, predictor, model\n",
    "\n",
    "\n",
    "activation_trainable = {'learnable': ('amplitude', 'frequency', 'decay')}\n",
    "activation_frozen = {'learnable': ()}\n",
    "\n",
    "respsann_common = dict(\n",
    "    hidden_layers=6,\n",
    "    hidden_units=128,\n",
    "    epochs=60,\n",
    "    batch_size=256,\n",
    "    lr=5e-4,\n",
    "    optimizer='adam',\n",
    "    device='cpu',\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "wave_common = dict(\n",
    "    hidden_layers=6,\n",
    "    hidden_units=128,\n",
    "    epochs=60,\n",
    "    batch_size=256,\n",
    "    lr=5e-4,\n",
    "    optimizer='adam',\n",
    "    device='cpu',\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "psann_experiments = [\n",
    "    ('ResPSANN (trainable)', lambda: ResPSANNRegressor(activation=activation_trainable, activation_type='psann', **respsann_common)),\n",
    "    ('ResPSANN (frozen)', lambda: ResPSANNRegressor(activation=activation_frozen, activation_type='psann', **respsann_common)),\n",
    "    ('WaveResNet (trainable)', lambda: WaveResNetRegressor(activation=activation_trainable, activation_type='psann', **wave_common)),\n",
    "    ('WaveResNet (frozen)', lambda: WaveResNetRegressor(activation=activation_frozen, activation_type='psann', **wave_common)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "trained_models = []\n",
    "raw_models = {}\n",
    "\n",
    "for label, factory in psann_experiments:\n",
    "    metrics, predictor, model = evaluate_psann(label, factory)\n",
    "    results.append(metrics)\n",
    "    trained_models.append((label, predictor))\n",
    "    raw_models[label] = model\n",
    "\n",
    "mlp_metrics, mlp_predictor, mlp_components = evaluate_mlp('MLP (tanh, 4x128)')\n",
    "results.append(mlp_metrics)\n",
    "trained_models.append((mlp_metrics['model'], mlp_predictor))\n",
    "raw_models[mlp_metrics['model']] = mlp_components\n",
    "\n",
    "lstm_metrics, lstm_predictor, lstm_model = evaluate_lstm('LSTM (2x128)')\n",
    "results.append(lstm_metrics)\n",
    "trained_models.append((lstm_metrics['model'], lstm_predictor))\n",
    "raw_models[lstm_metrics['model']] = lstm_model\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('mse').reset_index(drop=True)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(X_train[:, 0].min(), X_train[:, 0].max(), 600, dtype=np.float32).reshape(-1, 1)\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "ax.scatter(X_test[:, 0], y_test[:, 0], s=12, alpha=0.4, label='test')\n",
    "for label, predictor in trained_models:\n",
    "    preds = predictor(grid)\n",
    "    ax.plot(grid[:, 0], preds[:, 0], label=label)\n",
    "ax.set_title('Model fits across settings')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('prediction')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
