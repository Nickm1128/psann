{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe52922",
   "metadata": {},
   "source": [
    "# HISSO Logging CLI \u00c3\u0192\u00c2\u00a2\u00c3\u00a2\u00e2\u20ac\u0161\u00c2\u00ac\u00c3\u00a2\u00e2\u201a\u00ac\u00c5\u201c GPU Colab Run\n",
    "\n",
    "Execute this notebook in Google Colab (GPU runtime) after the refreshed `psann` package is published to PyPI. It installs the released wheel, prepares synthetic datasets/configs, and runs the logging CLI on CUDA to produce shareable metrics, event logs, and checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d13b4",
   "metadata": {},
   "source": [
    "## 0. Release checklist\n",
    "\n",
    "1. Publish the new `psann` version to PyPI.\n",
    "2. Update `PSANN_VERSION` below to match the release (e.g., `\"0.10.4\"`).\n",
    "3. (Optional) Adjust run tags/epochs to fit the available GPU budget.\n",
    "4. Switch Colab to **Runtime \u00c3\u0192\u00c2\u00a2\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a0\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2 Change runtime type \u00c3\u0192\u00c2\u00a2\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a0\u00c3\u00a2\u00e2\u201a\u00ac\u00e2\u201e\u00a2 GPU** before executing the remaining cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92aa3a7a",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Configure versions and run metadata\n",
    "PSANN_PACKAGE_SPEC = \"\"  #@param {type:\"string\"}  # e.g. \"psann==0.10.10\" or \"git+https://github.com/Nickm1128/psann.git@main\"\n",
    "TORCH_VERSION = \"2.5.1+cu121\"  #@param {type:\"string\"}\n",
    "TORCHVISION_VERSION = \"0.20.1+cu121\"  #@param {type:\"string\"}\n",
    "TORCHAUDIO_VERSION = \"2.5.1+cu121\"  #@param {type:\"string\"}\n",
    "TORCH_INDEX_URL = \"https://download.pytorch.org/whl/cu121\"  #@param {type:\"string\"}\n",
    "\n",
    "RUN_TAG = \"colab_gpu\"  #@param {type:\"string\"}\n",
    "OUTPUT_ROOT = \"/content/hisso_runs\"  #@param {type:\"string\"}\n",
    "CONFIG_ROOT = \"/content/hisso_configs\"  #@param {type:\"string\"}\n",
    "DATA_ROOT = \"/content/hisso_data\"  #@param {type:\"string\"}\n",
    "\n",
    "DENSE_EPOCHS = 8  #@param {type:\"integer\"}\n",
    "WAVE_EPOCHS = 10  #@param {type:\"integer\"}\n",
    "USE_MIXED_PRECISION = True  #@param {type:\"boolean\"}\n",
    "INSTALL_DEPENDENCIES = False  #@param {type:\"boolean\"}\n",
    "FORCE_DEVICE = \"auto\"  #@param [\"auto\", \"cpu\", \"cuda\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c668c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing psann installation.\n"
     ]
    }
   ],
   "source": [
    "# Install CUDA-enabled PyTorch wheels and the published psann package.\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def _pip_install(*args: str) -> None:\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *args]\n",
    "    print(\"$\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "if INSTALL_DEPENDENCIES:\n",
    "    _pip_install(\n",
    "        f\"torch=={TORCH_VERSION}\",\n",
    "        f\"torchvision=={TORCHVISION_VERSION}\",\n",
    "        f\"torchaudio=={TORCHAUDIO_VERSION}\",\n",
    "        \"--extra-index-url\",\n",
    "        TORCH_INDEX_URL,\n",
    "    )\n",
    "    _pip_install(\"pyyaml>=6.0\")\n",
    "    if PSANN_PACKAGE_SPEC:\n",
    "        _pip_install(PSANN_PACKAGE_SPEC)\n",
    "    else:\n",
    "        _pip_install(\"psann\")\n",
    "else:\n",
    "    try:\n",
    "        importlib.import_module(\"yaml\")\n",
    "    except ModuleNotFoundError:\n",
    "        _pip_install(\"pyyaml>=6.0\")\n",
    "    try:\n",
    "        importlib.import_module(\"psann.scripts.hisso_log_run\")\n",
    "        print(\"Using existing psann installation.\")\n",
    "    except ModuleNotFoundError:\n",
    "        raise RuntimeError(\"psann installation is missing scripts. Set INSTALL_DEPENDENCIES=True and provide PSANN_PACKAGE_SPEC (PyPI version or git URL) that includes psann.scripts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d94a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Using device: cpu\n",
      "Mixed precision: False\n",
      "Torch version: 2.7.1+cu118, CUDA runtime: 11.8\n"
     ]
    }
   ],
   "source": [
    "# Verify CUDA availability and pick a device.\n",
    "import torch\n",
    "\n",
    "def _resolve_device(force: str) -> str:\n",
    "    force = force.lower()\n",
    "    if force == \"auto\":\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if force.startswith(\"cuda\") and not torch.cuda.is_available():\n",
    "        print(\"Requested CUDA but no device is available; falling back to CPU.\")\n",
    "        return \"cpu\"\n",
    "    return force\n",
    "\n",
    "TARGET_DEVICE = _resolve_device(FORCE_DEVICE)\n",
    "USE_AMP = bool(USE_MIXED_PRECISION and TARGET_DEVICE.startswith(\"cuda\") and torch.cuda.is_available())\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Using device: {TARGET_DEVICE}\")\n",
    "print(f\"Mixed precision: {USE_AMP}\")\n",
    "print(f\"Torch version: {torch.__version__}, CUDA runtime: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22787e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output root: /content/hisso_runs\n",
      "Config root: /content/hisso_configs\n",
      "Data root: /content/hisso_data\n"
     ]
    }
   ],
   "source": [
    "# Prepare directories for configs, data, and run artefacts.\n",
    "from pathlib import Path\n",
    "\n",
    "for path in (Path(OUTPUT_ROOT), Path(CONFIG_ROOT), Path(DATA_ROOT)):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Output root:\", OUTPUT_ROOT)\n",
    "print(\"Config root:\", CONFIG_ROOT)\n",
    "print(\"Data root:\", DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb0d306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic dataset written to \\content\\hisso_data\\wave_resnet_synth.npz\n"
     ]
    }
   ],
   "source": [
    "# Synthesise a WaveResNet-style dataset (channels-first sequences).\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "def _make_split(num_samples: int, channels: int, steps: int, targets: int):\n",
    "    X = rng.normal(size=(num_samples, channels, steps)).astype(np.float32)\n",
    "    y = rng.normal(size=(num_samples, targets)).astype(np.float32)\n",
    "    prices = np.clip(1.0 + rng.normal(scale=0.01, size=(num_samples, targets)), 1e-3, None).astype(np.float32)\n",
    "    return X, y, prices\n",
    "\n",
    "train_X, train_y, train_prices = _make_split(320, 4, 128, 3)\n",
    "val_X, val_y, val_prices = _make_split(96, 4, 128, 3)\n",
    "test_X, test_y, test_prices = _make_split(96, 4, 128, 3)\n",
    "\n",
    "wave_npz_path = Path(DATA_ROOT) / \"wave_resnet_synth.npz\"\n",
    "np.savez_compressed(\n",
    "    wave_npz_path,\n",
    "    X_train=train_X,\n",
    "    y_train=train_y,\n",
    "    prices_train=train_prices,\n",
    "    X_val=val_X,\n",
    "    y_val=val_y,\n",
    "    prices_val=val_prices,\n",
    "    X_test=test_X,\n",
    "    y_test=test_y,\n",
    "    prices_test=test_prices,\n",
    ")\n",
    "print(\"Synthetic dataset written to\", wave_npz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536cd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense config: \\content\\hisso_configs\\dense_run.yaml\n",
      "WaveResNet config: \\content\\hisso_configs\\wave_resnet_run.yaml\n"
     ]
    }
   ],
   "source": [
    "# Emit HISSO config files targeting the selected device.\n",
    "import textwrap\n",
    "\n",
    "dense_config_path = Path(CONFIG_ROOT) / \"dense_run.yaml\"\n",
    "dense_config = f\"\"\"\n",
    "estimator:\n",
    "  target: psann.PSANNRegressor\n",
    "  params:\n",
    "    hidden_layers: 2\n",
    "    hidden_units: 64\n",
    "    epochs: {DENSE_EPOCHS}\n",
    "    batch_size: 128\n",
    "    lr: 0.0008\n",
    "    random_state: 7\n",
    "    device: {TARGET_DEVICE}\n",
    "hisso:\n",
    "  enabled: true\n",
    "  window: 32\n",
    "  primary_transform: softmax\n",
    "  transition_penalty: 0.0\n",
    "  mixed_precision: {str(USE_AMP).lower()}\n",
    "data:\n",
    "  loader: psann.scripts.hisso_log_run.toy_hisso_dataset\n",
    "  kwargs:\n",
    "    steps: 256\n",
    "    features: 6\n",
    "    seed: 13\n",
    "    train_fraction: 0.6\n",
    "    val_fraction: 0.2\n",
    "training:\n",
    "  verbose: 1\n",
    "evaluation:\n",
    "  portfolio_prices_key: prices_test\n",
    "  trans_cost: 0.001\n",
    "\"\"\"\n",
    "\n",
    "dense_config_path.write_text(textwrap.dedent(dense_config).strip() + \"\", encoding=\"utf-8\")\n",
    "\n",
    "wave_config_path = Path(CONFIG_ROOT) / \"wave_resnet_run.yaml\"\n",
    "wave_config = f\"\"\"\n",
    "estimator:\n",
    "  target: psann.WaveResNetRegressor\n",
    "  params:\n",
    "    hidden_layers: 3\n",
    "    hidden_units: 64\n",
    "    epochs: {WAVE_EPOCHS}\n",
    "    batch_size: 24\n",
    "    lr: 0.0005\n",
    "    random_state: 11\n",
    "    device: {TARGET_DEVICE}\n",
    "    preserve_shape: false\n",
    "    data_format: channels_first\n",
    "    w0_warmup_epochs: 5\n",
    "    progressive_depth_initial: 2\n",
    "    progressive_depth_interval: 5\n",
    "hisso:\n",
    "  enabled: true\n",
    "  window: 32\n",
    "  primary_transform: softmax\n",
    "  transition_penalty: 0.01\n",
    "  mixed_precision: {str(USE_AMP).lower()}\n",
    "  supervised:\n",
    "    y_key: y_train\n",
    "    epochs: 2\n",
    "    batch_size: 64\n",
    "data:\n",
    "  npz: {wave_npz_path}\n",
    "training:\n",
    "  verbose: 1\n",
    "evaluation:\n",
    "  portfolio_prices_key: prices_test\n",
    "  trans_cost: 0.001\n",
    "\"\"\"\n",
    "\n",
    "wave_config_path.write_text(textwrap.dedent(wave_config).strip() + \"\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Dense config:\", dense_config_path)\n",
    "print(\"WaveResNet config:\", wave_config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c7cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching dense run: dense_cpu_colab_gpu_20251030_204233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the dense HISSO config.\n",
    "import datetime as _dt\n",
    "\n",
    "timestamp = _dt.datetime.now(_dt.timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "dense_run_name = f\"dense_{TARGET_DEVICE}_{RUN_TAG}_{timestamp}\"\n",
    "print(\"Launching dense run:\", dense_run_name)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"-m\",\n",
    "    \"psann.scripts.hisso_log_run\",\n",
    "    \"--config\",\n",
    "    str(dense_config_path),\n",
    "    \"--output-dir\",\n",
    "    str(Path(OUTPUT_ROOT) / \"dense\"),\n",
    "    \"--device\",\n",
    "    TARGET_DEVICE,\n",
    "    \"--run-name\",\n",
    "    dense_run_name,\n",
    "    \"--seed\",\n",
    "    \"7\",\n",
    "    \"--verbose\",\n",
    "]\n",
    "print(\"$\", \" \".join(cmd))\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "if result.stdout:\n",
    "    print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(result.stderr, file=sys.stderr)\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"Dense run failed with exit code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "505aaa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching wave-resnet run: wave_resnet_cpu_colab_gpu_20251030_204242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the WaveResNet HISSO config.\n",
    "import datetime as _dt\n",
    "\n",
    "timestamp_wave = _dt.datetime.now(_dt.timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n",
    "wave_run_name = f\"wave_resnet_{TARGET_DEVICE}_{RUN_TAG}_{timestamp_wave}\"\n",
    "print(\"Launching wave-resnet run:\", wave_run_name)\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    \"-m\",\n",
    "    \"psann.scripts.hisso_log_run\",\n",
    "    \"--config\",\n",
    "    str(wave_config_path),\n",
    "    \"--output-dir\",\n",
    "    str(Path(OUTPUT_ROOT) / \"wave_resnet\"),\n",
    "    \"--device\",\n",
    "    TARGET_DEVICE,\n",
    "    \"--run-name\",\n",
    "    wave_run_name,\n",
    "    \"--seed\",\n",
    "    \"11\",\n",
    "    \"--verbose\",\n",
    "]\n",
    "print(\"$\", \" \".join(cmd))\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "if result.stdout:\n",
    "    print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(result.stderr, file=sys.stderr)\n",
    "if result.returncode != 0:\n",
    "    raise RuntimeError(f\"WaveResNet run failed with exit code {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d4cd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense metrics: \\content\\hisso_runs\\dense\\dense_cpu_colab_gpu_20251030_204233\\metrics.json\n",
      "{'device': 'cpu',\n",
      " 'duration_seconds': 1.9047843001317233,\n",
      " 'hisso': {'best_epoch': 6,\n",
      "           'episodes': 256,\n",
      "           'profile': {'amp_dtype': None,\n",
      "                       'amp_enabled': False,\n",
      "                       'batch_episodes': 32,\n",
      "                       'dataset_bytes': 3672,\n",
      "                       'dataset_numpy_to_tensor_time_s': 4.220008850097656e-05,\n",
      "                       'dataset_transfer_batches': 1,\n",
      "                       'dataset_transfer_time_s': 7.4999406933784485e-06,\n",
      "                       'device': 'cpu',\n",
      "                       'episode_length': 32,\n",
      "                       'episode_time_s_total': 0.5841135994996876,\n",
      "                       'episode_view_is_shared': True,\n",
      "                       'episodes_sampled': 256,\n",
      "                       'epochs': 8,\n",
      "                       'total_time_s': 0.5872145998291671},\n",
      "           'reward_mean': -0.11111112657818012,\n",
      "           'reward_std': 4.959080062845201e-08,\n",
      "           'throughput_eps_per_sec': 435.9564630621849,\n",
      "           'transition_penalty': 0.0},\n",
      " 'history_length': 8,\n",
      " 'portfolio_metrics': {'cum_return': -1.0,\n",
      "                       'log_return': -27.631021115928547,\n",
      "                       'max_drawdown': -1.0,\n",
      "                       'sharpe': -207.1023943195077,\n",
      "                       'turnover': 0.00011512584180808535},\n",
      " 'start_time': '2025-10-30T15:42:36.202145',\n",
      " 'status': 'success',\n",
      " 'test_loss': 0.2312530130147934,\n",
      " 'timestamp': '2025-10-30T15:42:38.127577',\n",
      " 'train_loss': 0.24508312344551086,\n",
      " 'val_loss': 0.3035309612751007}\n",
      "\n",
      "WaveResNet metrics: \\content\\hisso_runs\\wave_resnet\\wave_resnet_cpu_colab_gpu_20251030_204242\\metrics.json\n",
      "{'device': 'cpu',\n",
      " 'duration_seconds': 2.745829900028184,\n",
      " 'hisso': {'best_epoch': 10,\n",
      "           'episodes': 320,\n",
      "           'profile': {'amp_dtype': None,\n",
      "                       'amp_enabled': False,\n",
      "                       'batch_episodes': 32,\n",
      "                       'dataset_bytes': 655360,\n",
      "                       'dataset_numpy_to_tensor_time_s': 9.699957445263863e-06,\n",
      "                       'dataset_transfer_batches': 1,\n",
      "                       'dataset_transfer_time_s': 3.8000289350748062e-06,\n",
      "                       'device': 'cpu',\n",
      "                       'episode_length': 32,\n",
      "                       'episode_time_s_total': 1.465929802507162,\n",
      "                       'episode_view_is_shared': True,\n",
      "                       'episodes_sampled': 320,\n",
      "                       'epochs': 10,\n",
      "                       'total_time_s': 1.470300399698317},\n",
      "           'reward_mean': -0.1811729593668133,\n",
      "           'reward_std': 0.06770107781927974,\n",
      "           'throughput_eps_per_sec': 217.64259879522515,\n",
      "           'transition_penalty': 0.01},\n",
      " 'history_length': 10,\n",
      " 'portfolio_metrics': {'cum_return': -1.0,\n",
      "                       'log_return': -27.631021115928547,\n",
      "                       'max_drawdown': -1.0,\n",
      "                       'sharpe': -2.9289464702178134,\n",
      "                       'turnover': 2.682363523268386},\n",
      " 'start_time': '2025-10-30T15:42:44.400497',\n",
      " 'status': 'success',\n",
      " 'test_loss': 1.534475326538086,\n",
      " 'timestamp': '2025-10-30T15:42:47.209700',\n",
      " 'train_loss': 1.3618218898773193,\n",
      " 'val_loss': 1.5973421335220337}\n"
     ]
    }
   ],
   "source": [
    "# Summarise generated artefacts.\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "def _collect_latest(run_dir: Path) -> Path:\n",
    "    candidates = sorted(run_dir.glob(\"*/metrics.json\"), key=lambda p: p.stat().st_mtime)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No metrics.json under {run_dir}\")\n",
    "    return candidates[-1]\n",
    "\n",
    "dense_metrics_path = _collect_latest(Path(OUTPUT_ROOT) / \"dense\")\n",
    "wave_metrics_path = _collect_latest(Path(OUTPUT_ROOT) / \"wave_resnet\")\n",
    "\n",
    "print(\"Dense metrics:\", dense_metrics_path)\n",
    "with dense_metrics_path.open() as fh:\n",
    "    dense_metrics = json.load(fh)\n",
    "pprint(dense_metrics)\n",
    "\n",
    "print(\"\\nWaveResNet metrics:\", wave_metrics_path)\n",
    "with wave_metrics_path.open() as fh:\n",
    "    wave_metrics = json.load(fh)\n",
    "pprint(wave_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export artefacts\n",
    "\n",
    "Optionally archive the run directory for download (uncomment the cell below when needed).\n",
    "\n",
    "```python\n",
    "# import shutil\n",
    "# shutil.make_archive(\"hisso_runs\", \"zip\", OUTPUT_ROOT)\n",
    "```\n",
    "\n",
    "Mounting Google Drive (`from google.colab import drive`) is also recommended if you want the metrics and checkpoints to persist automatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
